<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Science on </title>
    <link>http://estebanmoro.org/categories/science/</link>
    <description>Recent content in Science on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 20 Sep 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="http://estebanmoro.org/categories/science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Social Urban Networks at NetSI (Northeastern)</title>
      <link>http://estebanmoro.org/post/2023-09-20-social-urban-networks-at-netsi-northeastern/</link>
      <pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2023-09-20-social-urban-networks-at-netsi-northeastern/</guid>
      <description>&lt;p&gt;I am thrilled to announce that I will be joining the &lt;a href=&#34;https://www.networkscienceinstitute.org&#34;&gt;Network Science Institute&lt;/a&gt; at &lt;a href=&#34;https://www.northeastern.edu&#34;&gt;Northeastern University&lt;/a&gt; as a Professor starting January 2024! As a researcher in Social Urban Networks (SUN) it is a dream come true.&lt;/p&gt;
&lt;p&gt;My group will focus on developing computational social science &lt;a href=&#34;https://inequality.media.mit.edu&#34;&gt;tools&lt;/a&gt; to address urban challenges, from &lt;a href=&#34;http://estebanmoro.org/&#34;&gt;climate change&lt;/a&gt;, &lt;a href=&#34;http://estebanmoro.org/post/2019-02-02-behavioral-fundations-of-inequality/&#34;&gt;inequality&lt;/a&gt; to &lt;a href=&#34;http://estebanmoro.org/post/2022-10-25-behavioral-network-determinants-of-health-outcomes/&#34;&gt;health&lt;/a&gt; and &lt;a href=&#34;http://estebanmoro.org/post/2022-10-25-creating-resilient-urban-labor-economies/&#34;&gt;economic development&lt;/a&gt;. By using large datasets of human behavior, tools and ideas from physics, applied mathematics, complex systems or network science, and collaborations with industry, government, and local communities, we seek not only to advance the understanding of the temporal dynamics of social systems to unprecedented levels but also to transform our findings into tools and policies to help achieve resilient and equitable adaptation of our societies.&lt;/p&gt;
&lt;p&gt;I am recruiting graduate students and postdocs to join my SUN group. We offer fully-funded PhD and postdoc positions and we are seeking highly motivated researchers to explore the following subjects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/post/2019-02-02-behavioral-fundations-of-inequality/&#34;&gt;Fighting inequality in urban areas&lt;/a&gt;: mapping the inequality in the social fabric of cities at an unprecedented scale using high-resolution mobility and activity data.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/post/2022-10-25-creating-resilient-urban-labor-economies/&#34;&gt;Creating resilient labor and urban economies&lt;/a&gt;: detecting economic resilience encoded in the dependency networks of agents, business, cities, or jobs.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/post/2022-10-25-behavioral-network-determinants-of-health-outcomes/&#34;&gt;Understanding behavioral-network determinants of health outcomes in our cities&lt;/a&gt;, by modeling physical exposure between people and healthy environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are interested, contact me at &lt;a href=&#34;mailto:esteban.moroegido@gmail.com&#34;&gt;esteban.moroegido@gmail.com&lt;/a&gt; to get more information about those positions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Factors Improving Labor Resiliency in U.S. Cities.</title>
      <link>http://estebanmoro.org/post/2021-03-29-factors-improving-job-resiliency-in-u-s-cities/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2021-03-29-factors-improving-job-resiliency-in-u-s-cities/</guid>
      <description>&lt;p&gt;What makes urban labor markets more resilient? This is the question at the heart of a &lt;a href=&#34;http://estebanmoro.org/post/2021-03-30-universal-resilience-patterns-in-labor-markets/&#34;&gt;new study we have published in Nature Communications&lt;/a&gt;. We drew on prior network modeling research to map the job landscapes in cities across the United States, and showed that job “connectedness” is a key determinant of the resilience of local economies.&lt;/p&gt;
&lt;p&gt;Economists, policy makers, city planners, and companies have a strong interest in determining what factors contribute to healthy job markets, including what factors can help promote faster recovery after a shock, such as a major recession or the current COVID pandemic. Traditional modeling approaches in this realm have treated workers as narrowly linked to specific jobs. In the real world, however, jobs and sectors are linked. Displaced workers can often transition to another job or sector requiring similar skills. In this way, job markets are much like ecosystems, where organisms are linked in a complex web of relationships.&lt;/p&gt;
&lt;p&gt;In ecology and other domains where complex networks are present, resilience has been closely linked to the “connectedness” of the networks. In nature, for example, ecosystems with many mutualistic connections have proven more resistant to shocks, such as changes in acidity or temperature, than those with fewer connections. By drawing on ecosystem-inspired network models and extending the Noble-prize-winning Pissarides-Mortensen job matching framework, the authors of the Nature study modeled the relationships between jobs in cities across the United States. Just as connectedness in nature fosters resilience, they predicted that cities with jobs connected by overlapping skills and geography would fare better in the face of economic shock than those without such networks.&lt;/p&gt;
&lt;p&gt;To validate this, the researchers examined data from the Bureau of Labor Statistics for all metropolitan areas in the country from the onset to the end of the Great Recession. They were able to create job landscape maps for each area, including not just the numbers of specific jobs, but also their geographical distribution and the extent to which the skills they required overlapped with other jobs in the area. The size of a given city, as well as its employment diversity, played a role in resilience, with bigger, more diverse cities faring better than smaller and less-diverse ones. However, controlling for size and diversity, factoring in job connectivity significantly improved predictions of peak unemployment rates during the recession. Cities where job connectivity was highest leading up to the crash were significantly more resilient and recovered faster than those with less-connected markets.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/labormarket.png&#34; alt=&#34;Figure: Workers can transition from one job to another one that requires similar skills. This defines a network between occupations where job matching occurs and shows a clear structure by sectors. In some cities that network is very connected (Burlington, VT) and there are many possibilities for a worker to find another job. In some other cities (Bloomington, IN) the network is sparser. The network connectivity encodes how resilient is the city’s labor market to unemployment shocks&#34;&gt;&lt;/p&gt;
&lt;p&gt;Even in the absence of temporary crises like the Great Recession or the COVID pandemic, automation promises to upend the employment landscapes of many areas in coming years. How can cities prepare for this disruption? The researchers in this study extended their model to predict how job markets would behave when facing job loss due to automation. They found that while cities of similar sizes would be affected similarly in the beginning phases of automation shocks, those with well-connected job networks would provide better opportunities for displaced workers to find other jobs. This provides a buffer against widespread unemployment, and in some cases even leads to more jobs being created in the aftermath of the initial automation shock. A city like Burlington, VT, where job connectivity is high, would fare much better than Bloomington Indiana, a similar-sized city where job connectivity is low.&lt;/p&gt;
&lt;p&gt;The findings of the study suggest that policy-makers should consider job connectivity when planning for the future of work in their regions, especially where automation is expected to replace large numbers of jobs. Not only does increased connectivity result in lower unemployment – it also contributes to a rise in overall wages. Furthermore, in individual occupations, workers in jobs that are more “embedded” (connected to other jobs) in a region, earn higher wages than similar workers in areas where those jobs are not as connected.&lt;/p&gt;
&lt;p&gt;These results offer fresh insight to help steer discussions about the Future of Work and may help guide and complement current decisions about where to invest in job creation and training programs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Links&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To read the full article, visit &lt;a href=&#34;http://estebanmoro.org/post/2021-03-30-universal-resilience-patterns-in-labor-markets/&#34;&gt;this link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Explore the data and nice visualizations &lt;a href=&#34;http://pitt.edu/~labornet/&#34;&gt;in our interactive tool&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The Atlas of Inequality</title>
      <link>http://estebanmoro.org/post/2019-03-02-the-atlas-of-segregation/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2019-03-02-the-atlas-of-segregation/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Segregation is hurting our societies and specially our cities. But economic inequality isn&amp;rsquo;t just limited to neighborhoods. The restaurants, stores, and other places we visit in cities are all unequal in their own way.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Atlas of Inequality  shows the income inequality of people who visit different places in the Boston metro area. It uses aggregated anonymous location data from digital devices to estimate people&amp;rsquo;s incomes and where they spend their time. Using that data, we&amp;rsquo;ve made our own place inequality metric to capture how unequal the incomes of visitors to each place are. Economic inequality isn&amp;rsquo;t just limited to neighborhoods; it&amp;rsquo;s part of the places you visit every day.&lt;/p&gt;
&lt;p&gt;Try it yourself here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://inequality.media.mit.edu&#34;&gt;The Atlas of Inequality&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Atlas of Inequality is a project from the Human Dynamics group at the &lt;a href=&#34;http://media.mit.edu&#34;&gt;MIT Media Lab&lt;/a&gt; and the Department of Mathematics at &lt;a href=&#34;http://www.uc3m.es&#34;&gt;Universidad Carlos III de Madrid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is part of a broader initiative to understand human behavior in our cities and how large-scale problems like transportation, housing, segregation, or inequality depend in part on the emergent patterns of people’s individual opportunities and choices.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Netmob 2019</title>
      <link>http://estebanmoro.org/post/2019-02-01-netmob-2019/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2019-02-01-netmob-2019/</guid>
      <description>&lt;p&gt;Another edition of Netmob is happening this year 2019. NetMob is the primary conference in the analysis of mobile phone datasets in social, urban, societal and industrial problems. Previous editions in Boston and Milano brought together more than 250 researchers, practitioners and decision-makers from more 140 institutions and 30 countries. I had the pleasure to organize the &lt;a href=&#34;http://estebanmoro.org/post/2015-04-14-netmob-2015&#34;&gt;2015 edition&lt;/a&gt; and it was a blast to put together so much interesting talks, people, projects.
Any contribution about mobile phone data is welcome, not only CDRs (call detail records). This includes, mobile location data, wifi usage, app-generated data, Twitter, Facebook, etc. The format of the conference is also flexibel: one track of short contributed talks and a simplified submission procedure (1-page abstracts).&lt;/p&gt;
&lt;p&gt;This time is happening at another special place for me: the Mathematical Institute or University of Oxford (UK) from July 8-10 2019 and the local organizer is Renaud Lambiotte. Join us there.&lt;/p&gt;
&lt;p&gt;More info:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Submission deadline: 15 March 2019&lt;/li&gt;
&lt;li&gt;Notification of acceptance: 30 March 2019&lt;/li&gt;
&lt;li&gt;Registration opening: 30 March 2019&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href=&#34;http://netmob.org&#34;&gt;http://netmob.org&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Growing old in Twitter</title>
      <link>http://estebanmoro.org/post/2018-12-14-growing-old-in-twitter/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2018-12-14-growing-old-in-twitter/</guid>
      <description>&lt;script src=&#34;http://estebanmoro.org/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/wordcloud2/wordcloud.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;http://estebanmoro.org/rmarkdown-libs/wordcloud2/wordcloud2-all.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://estebanmoro.org/rmarkdown-libs/wordcloud2/hover.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;http://estebanmoro.org/rmarkdown-libs/wordcloud2-binding/wordcloud2.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;I started using Twitter more than 10 years ago (!). I open an account in this social network in 2008 and although I was not using it too much for the first year, I become a frequent user after that. It has helped me to get news, information both for my personal and professional interests. But not only that, Twitter has been also the data source for our research, that helped us to investigate the relationship between human behavior in the social platform and paramount problems in our society as &lt;a href=&#34;http://estebanmoro.org/post/2014-04-09-using-friends-as-sensors&#34;&gt;information propagation&lt;/a&gt;, &lt;a href=&#34;http://estebanmoro.org/post/2014-11-13-social-media-fingerprints-of-unemployment&#34;&gt;unemployment&lt;/a&gt;, &lt;a href=&#34;http://estebanmoro.org/post/2016-03-14-rapid-assessment-of-disaster-damage&#34;&gt;disaster damage&lt;/a&gt;, &lt;a href=&#34;http://estebanmoro.org/post/2014-04-22-comunidades-de-partidarios-en-redes-sociales-estudio-de-las-elecciones-catalanas-de-2010-y-2012&#34;&gt;political opinion&lt;/a&gt;. As we keep on working on those subjects we have also recently extended our research to other problems like health, or &lt;a href=&#34;http://estebanmoro.org/post/2018-04-28-weather-impacts-expressed-sentiment&#34;&gt;climate change&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Most of the research in human behavior is constrained either by time or by population covered, so we can’t have both. Large longitudinal databases, extending tens of years, are relatively small in the number of participants or users, while data from millions of users is usually obtained for a very short period of time (months or years). One of the good things about &lt;em&gt;growing old&lt;/em&gt; in those social networks is that we are starting to see tens of years of data to analyze.&lt;/p&gt;
&lt;p&gt;Here I want to analyze by Twitter activity during those last 10 years. First thing is to download all our account activity, something that is explain in the &lt;a href=&#34;https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive&#34;&gt;How to download and view your Twitter archive&lt;/a&gt; help page at Twitter. Basically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connect to your &lt;a href=&#34;https://twitter.com/settings/account&#34;&gt;Account Settings&lt;/a&gt; at Twitter.&lt;/li&gt;
&lt;li&gt;On the left sidebar you will see a link to &lt;a href=&#34;https://twitter.com/settings/your_twitter_data&#34;&gt;Your Twitter data&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;At this step you will probably have to confirm your password, but on the bottom of the next page you have a link to &lt;em&gt;Request data&lt;/em&gt; of your Twitter account.&lt;/li&gt;
&lt;li&gt;When the data is ready to download you will receive an notification at your email with the a link to download it.&lt;/li&gt;
&lt;li&gt;The data comes as a series of JSON files. The file &lt;code&gt;tweets.js&lt;/code&gt; contains all tweets, retweets and metions, but it comes with a &lt;code&gt;window.YTD.tweet.part0 =&lt;/code&gt; header at the beggining. &lt;a href=&#34;https://kyleconroy.com/your-twitter-data&#34;&gt;Remove it&lt;/a&gt; to make it a readable JSON file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s load the tweets&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(jsonlite)
tweets &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; jsonlite&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;fromJSON&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;tweets.js&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The table contains many fields, including the tweet id (&lt;code&gt;id&lt;/code&gt;), timestamp when it was created &lt;code&gt;created_at&lt;/code&gt;, if it is a reply to a status &lt;code&gt;in_reply_to_status_id&lt;/code&gt; or a user &lt;code&gt;in_reply_to_user_id&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;more-or-less-active&#34;&gt;More or less active?&lt;/h3&gt;
&lt;p&gt;The first thing we can investigate is if my behavior in Twitter has changed in these 10 years. My feeling is that people spend less time in the platform when we get older. One reason is that, compared to 2009, it is really difficult to keep tract of what is happening in the platform. I also have less and less time. But it is true that twitter has changed their app to engage users more with the converstation, so that might counterbalance it.&lt;/p&gt;
&lt;p&gt;To analyze it, let’s add the formated timestamp to the dataset&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;timestamp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;as.POSIXct&lt;/span&gt;(tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;created_at,format&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%a %b %d %H:%M:%S %z %Y&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and plot the number of tweets by month.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(ggplot2)
&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(zoo)
&lt;span style=&#34;color:#a6e22e&#34;&gt;ggplot&lt;/span&gt;(tweets,&lt;span style=&#34;color:#a6e22e&#34;&gt;aes&lt;/span&gt;(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;as.yearmon&lt;/span&gt;(timestamp))) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
  &lt;span style=&#34;color:#a6e22e&#34;&gt;geom_bar&lt;/span&gt;(binwidth&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.09&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;scale_x_yearmon&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
  &lt;span style=&#34;color:#a6e22e&#34;&gt;theme_bw&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
  &lt;span style=&#34;color:#a6e22e&#34;&gt;ylab&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Number of tweets per month&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xlab&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;http://estebanmoro.org/post/2018-12-14-growing-old-in-twitter_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;As we can see, the most active years were from 2011 to 2015 (around 100 tweets per month). From then on I am tweeting less, corroborating my feeling that I spent less time in the platform (at least tweeting :) )&lt;/p&gt;
&lt;h3 id=&#34;tweeting-or-retweeting-more&#34;&gt;Tweeting or retweeting more?&lt;/h3&gt;
&lt;p&gt;Have I changed the way I use Twitter? Our research in &lt;a href=&#34;2017-03-07-twitter-session-analytics-profiling-users-short-term-behavioral-changes/&#34;&gt;Twitter sessions&lt;/a&gt; and social networks using mobile phone data shows that because of our limited atention and cognitive capacities people tend to perform simpler tasks with time and age. For example we found that in long sessions in Twitter (two or more hours), users start composing less messages (which require more effort) and use more retweets or mentions (replies) within the session, that require less effort.&lt;/p&gt;
&lt;p&gt;Let’s see what happened in ten years of data. We classify tweets as &lt;code&gt;composed&lt;/code&gt;, &lt;code&gt;mention&lt;/code&gt; or &lt;code&gt;retweets&lt;/code&gt; using the fields in the dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;class &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;normal&amp;#34;&lt;/span&gt;
tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;class[&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;is.na&lt;/span&gt;(tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;in_reply_to_status_id)] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mention&amp;#34;&lt;/span&gt;
tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;class[&lt;span style=&#34;color:#f92672&#34;&gt;!&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;is.na&lt;/span&gt;(tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;retweeted_status_id)] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RT&amp;#34;&lt;/span&gt;
tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;class&lt;span style=&#34;color:#a6e22e&#34;&gt;[grep&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RT @&amp;#34;&lt;/span&gt;,tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;full_text)] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RT&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and show the fraction of tweets per month in each class&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(ggplot2)
&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(zoo)
&lt;span style=&#34;color:#a6e22e&#34;&gt;ggplot&lt;/span&gt;(tweets,&lt;span style=&#34;color:#a6e22e&#34;&gt;aes&lt;/span&gt;(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;as.yearmon&lt;/span&gt;(timestamp), fill&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;class)) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
  &lt;span style=&#34;color:#a6e22e&#34;&gt;geom_bar&lt;/span&gt;(position&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;fill&amp;#34;&lt;/span&gt;,binwidth&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.09&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;scale_x_yearmon&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;theme_bw&lt;/span&gt;() &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; 
  &lt;span style=&#34;color:#a6e22e&#34;&gt;ylab&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Fraction of tweets of each class&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;xlab&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;http://estebanmoro.org/post/2018-12-14-growing-old-in-twitter_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Similar to our research for Twitter sessions, I can see that I compose less original tweets with time: while in 2010 almost 50% of my tweets were composed, now only 20% are original and more than 50% of the tweets in my account are retweets.&lt;/p&gt;
&lt;h3 id=&#34;tweeting-about-what&#34;&gt;Tweeting about what?&lt;/h3&gt;
&lt;p&gt;Finally, let’s see what I tweeted about. Although we could probably do much elaborated analysis, a simple wordcloud will do here. We clean up the text of the tweets (including mentions and retweets) and produce a wordcloud&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(tm)
&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(wordcloud2)
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; tweets&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;full_text
&lt;span style=&#34;color:#75715e&#34;&gt;#cleanup remove mentions and url&lt;/span&gt;
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tolower&lt;/span&gt;(texts)
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gsub&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\\b+rt&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, texts)
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gsub&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;@\\S+&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;, texts)
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gsub&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http\\S+\\s*&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, texts)
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;gsub&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;[[:punct:]]&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, texts) 
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;removeWords&lt;/span&gt;(texts, &lt;span style=&#34;color:#a6e22e&#34;&gt;stopwords&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;english&amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#75715e&#34;&gt;#get rid of stopwords in english&lt;/span&gt;
texts &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;removeWords&lt;/span&gt;(texts, &lt;span style=&#34;color:#a6e22e&#34;&gt;stopwords&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;spanish&amp;#34;&lt;/span&gt;)) &lt;span style=&#34;color:#75715e&#34;&gt;#get rid of stopwords in spanish&lt;/span&gt;
corpus.texts.all &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Corpus&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;VectorSource&lt;/span&gt;(texts))
dtm &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;TermDocumentMatrix&lt;/span&gt;(corpus.texts.all)
m &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;as.matrix&lt;/span&gt;(dtm)
v &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sort&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;rowSums&lt;/span&gt;(m),decreasing&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;TRUE&lt;/span&gt;)
d &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;data.frame&lt;/span&gt;(word &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;names&lt;/span&gt;(v),freq&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v)
&lt;span style=&#34;color:#a6e22e&#34;&gt;wordcloud2&lt;/span&gt;(d[d&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;freq&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,],fontFamily&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Loma&amp;#34;&lt;/span&gt;,rotateRatio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;wordcloud2 html-widget html-fill-item-overflow-hidden html-fill-item&#34; id=&#34;htmlwidget-1&#34; style=&#34;width:960px;height:480px;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;word&#34;:[&#34;gracias&#34;,&#34;twitter&#34;,&#34;data&#34;,&#34;social&#34;,&#34;thanks&#34;,&#34;new&#34;,&#34;networks&#34;,&#34;via&#34;,&#34;great&#34;,&#34;nice&#34;,&#34;work&#34;,&#34;science&#34;,&#34;network&#34;,&#34;paper&#34;,&#34;madrid&#34;,&#34;hoy&#34;,&#34;redes&#34;,&#34;amp&#34;,&#34;talk&#34;,&#34;datos&#34;,&#34;congrats&#34;,&#34;will&#34;,&#34;big&#34;,&#34;just&#34;,&#34;google&#34;,&#34;bien&#34;,&#34;can&#34;,&#34;good&#34;,&#34;ver&#34;,&#34;uc3m&#34;,&#34;research&#34;,&#34;sociales&#34;,&#34;españa&#34;,&#34;bigdata&#34;,&#34;time&#34;,&#34;facebook&#34;,&#34;now&#34;,&#34;aquí&#34;,&#34;mejor&#34;,&#34;enhorabuena&#34;,&#34;thank&#34;,&#34;tweetsandbeersuc3m&#34;,&#34;using&#34;,&#34;one&#34;,&#34;people&#34;,&#34;ahora&#34;,&#34;like&#34;,&#34;see&#34;,&#34;nuevo&#34;,&#34;complex&#34;,&#34;años&#34;,&#34;spain&#34;,&#34;media&#34;,&#34;interesante&#34;,&#34;analysis&#34;,&#34;tweets&#34;,&#34;use&#34;,&#34;mañana&#34;,&#34;know&#34;,&#34;día&#34;,&#34;post&#34;,&#34;amazing&#34;,&#34;first&#34;,&#34;cómo&#34;,&#34;rstats&#34;,&#34;trabajo&#34;,&#34;ciencia&#34;,&#34;blog&#34;,&#34;human&#34;,&#34;gente&#34;,&#34;vía&#34;,&#34;creo&#34;,&#34;charla&#34;,&#34;buena&#34;,&#34;año&#34;,&#34;artículo&#34;,&#34;muchas&#34;,&#34;today&#34;,&#34;bueno&#34;,&#34;ser&#34;,&#34;pues&#34;,&#34;day&#34;,&#34;vez&#34;,&#34;next&#34;,&#34;looking&#34;,&#34;interesting&#34;,&#34;cuenta&#34;,&#34;mobile&#34;,&#34;video&#34;,&#34;gran&#34;,&#34;solo&#34;,&#34;puede&#34;,&#34;conference&#34;,&#34;mit&#34;,&#34;dont&#34;,&#34;estudio&#34;,&#34;menos&#34;,&#34;app&#34;,&#34;ipad&#34;,&#34;papers&#34;,&#34;ready&#34;,&#34;buen&#34;,&#34;help&#34;,&#34;hace&#34;,&#34;parece&#34;,&#34;way&#34;,&#34;spanish&#34;,&#34;iic&#34;,&#34;hecho&#34;,&#34;link&#34;,&#34;open&#34;,&#34;tweet&#34;,&#34;project&#34;,&#34;país&#34;,&#34;mismo&#34;,&#34;get&#34;,&#34;got&#34;,&#34;study&#34;,&#34;iphone&#34;,&#34;online&#34;,&#34;así&#34;,&#34;hacer&#34;,&#34;world&#34;,&#34;communication&#34;,&#34;temporal&#34;,&#34;web&#34;,&#34;really&#34;,&#34;please&#34;,&#34;análisis&#34;,&#34;check&#34;,&#34;real&#34;,&#34;dynamics&#34;,&#34;friends&#34;,&#34;information&#34;,&#34;investigación&#34;,&#34;mundo&#34;,&#34;tiempo&#34;,&#34;challenge&#34;,&#34;working&#34;,&#34;voy&#34;,&#34;dice&#34;,&#34;phone&#34;,&#34;final&#34;,&#34;also&#34;,&#34;cada&#34;,&#34;curso&#34;,&#34;sorry&#34;,&#34;systems&#34;,&#34;last&#34;,&#34;red&#34;,&#34;barcelona&#34;,&#34;suerte&#34;,&#34;yes&#34;,&#34;carlos&#34;,&#34;phd&#34;,&#34;boston&#34;,&#34;universidad&#34;,&#34;best&#34;,&#34;siempre&#34;,&#34;mas&#34;,&#34;year&#34;,&#34;2012&#34;,&#34;dos&#34;,&#34;días&#34;,&#34;make&#34;,&#34;school&#34;,&#34;talks&#34;,&#34;manuel&#34;,&#34;find&#34;,&#34;vamos&#34;,&#34;habla&#34;,&#34;salamanca&#34;,&#34;eccs11&#34;,&#34;want&#34;,&#34;unemployment&#34;,&#34;primer&#34;,&#34;información&#34;,&#34;behavior&#34;,&#34;available&#34;,&#34;info&#34;,&#34;team&#34;,&#34;idea&#34;,&#34;article&#34;,&#34;map&#34;,&#34;feliz&#34;,&#34;years&#34;,&#34;bad&#34;,&#34;visualization&#34;,&#34;cities&#34;,&#34;right&#34;,&#34;mobility&#34;,&#34;etc&#34;,&#34;databeers&#34;,&#34;review&#34;,&#34;sólo&#34;,&#34;join&#34;,&#34;society&#34;,&#34;veo&#34;,&#34;fin&#34;,&#34;made&#34;,&#34;innovachallenge&#34;,&#34;apple&#34;,&#34;email&#34;,&#34;mac&#34;,&#34;learning&#34;,&#34;around&#34;,&#34;well&#34;,&#34;scientific&#34;,&#34;satellite&#34;,&#34;news&#34;,&#34;verdad&#34;,&#34;problema&#34;,&#34;mira&#34;,&#34;proyecto&#34;,&#34;tomorrow&#34;,&#34;machine&#34;,&#34;free&#34;,&#34;forward&#34;,&#34;problem&#34;,&#34;matemáticas&#34;,&#34;book&#34;,&#34;job&#34;,&#34;según&#34;,&#34;vaya&#34;,&#34;graph&#34;,&#34;hola&#34;,&#34;internet&#34;,&#34;viral&#34;,&#34;read&#34;,&#34;two&#34;,&#34;espero&#34;,&#34;hablar&#34;,&#34;pena&#34;,&#34;entrevista&#34;,&#34;hablando&#34;,&#34;mucha&#34;,&#34;talking&#34;,&#34;think&#34;,&#34;another&#34;,&#34;deadline&#34;,&#34;future&#34;,&#34;researchers&#34;,&#34;supuesto&#34;,&#34;published&#34;,&#34;ayer&#34;,&#34;funciona&#34;,&#34;cierto&#34;,&#34;come&#34;,&#34;program&#34;,&#34;done&#34;,&#34;htt&#34;,&#34;many&#34;,&#34;group&#34;,&#34;parte&#34;,&#34;vemos&#34;,&#34;better&#34;,&#34;change&#34;,&#34;mention&#34;,&#34;puedes&#34;,&#34;después&#34;,&#34;ingeniería&#34;,&#34;users&#34;,&#34;netmob15&#34;,&#34;sna&#34;,&#34;need&#34;,&#34;tool&#34;,&#34;ties&#34;,&#34;comunicación&#34;,&#34;aunque&#34;,&#34;let&#34;,&#34;predict&#34;,&#34;call&#34;,&#34;innovación&#34;,&#34;number&#34;,&#34;hombre&#34;,&#34;digital&#34;,&#34;netsci13&#34;,&#34;try&#34;,&#34;jornada&#34;,&#34;tan&#34;,&#34;may&#34;,&#34;workshop&#34;,&#34;still&#34;,&#34;place&#34;,&#34;siento&#34;,&#34;netmob&#34;,&#34;scientists&#34;,&#34;cosas&#34;,&#34;mención&#34;,&#34;puedo&#34;,&#34;allí&#34;,&#34;speakers&#34;,&#34;casa&#34;,&#34;week&#34;,&#34;quieres&#34;,&#34;days&#34;,&#34;2014&#34;,&#34;2010&#34;,&#34;interested&#34;,&#34;shows&#34;,&#34;impresionante&#34;,&#34;happy&#34;,&#34;mining&#34;,&#34;conocimiento&#34;,&#34;igraph&#34;,&#34;pasado&#34;,&#34;marketing&#34;,&#34;sharing&#34;,&#34;100&#34;,&#34;different&#34;,&#34;seguir&#34;,&#34;nature&#34;,&#34;primera&#34;,&#34;personas&#34;,&#34;hablamos&#34;,&#34;math&#34;,&#34;luis&#34;,&#34;patterns&#34;,&#34;back&#34;,&#34;physics&#34;,&#34;genial&#34;,&#34;podemos&#34;,&#34;top&#34;,&#34;others&#34;,&#34;grande&#34;,&#34;game&#34;,&#34;pablo&#34;,&#34;política&#34;,&#34;viernes&#34;,&#34;visto&#34;,&#34;welcome&#34;,&#34;tarde&#34;,&#34;business&#34;,&#34;scientist&#34;,&#34;datascience&#34;,&#34;elecciones&#34;,&#34;semana&#34;,&#34;felicidades&#34;,&#34;alguien&#34;,&#34;sensors&#34;,&#34;much&#34;,&#34;mal&#34;,&#34;punto&#34;,&#34;followers&#34;,&#34;hope&#34;,&#34;hijo&#34;,&#34;nueva&#34;,&#34;things&#34;,&#34;take&#34;,&#34;part&#34;,&#34;academic&#34;,&#34;foto&#34;,&#34;going&#34;,&#34;instituto&#34;,&#34;2015&#34;,&#34;impact&#34;,&#34;spread&#34;,&#34;wow&#34;,&#34;acabo&#34;,&#34;puesto&#34;,&#34;luego&#34;,&#34;hora&#34;,&#34;stop&#34;,&#34;biblioteca&#34;,&#34;jornadaiic12&#34;,&#34;structure&#34;,&#34;list&#34;,&#34;todavía&#34;,&#34;code&#34;,&#34;per&#34;,&#34;search&#34;,&#34;ever&#34;,&#34;caso&#34;,&#34;ello&#34;,&#34;usuarios&#34;,&#34;global&#34;,&#34;everything&#34;,&#34;gobierno&#34;,&#34;mathematics&#34;,&#34;applied&#34;,&#34;lab&#34;,&#34;netsci&#34;,&#34;recent&#34;,&#34;españoles&#34;,&#34;course&#34;,&#34;crisis&#34;,&#34;android&#34;,&#34;millones&#34;,&#34;visualización&#34;,&#34;point&#34;,&#34;strength&#34;,&#34;start&#34;,&#34;empresa&#34;,&#34;grandes&#34;,&#34;iii&#34;,&#34;found&#34;,&#34;sistema&#34;,&#34;café&#34;,&#34;decir&#34;,&#34;mariluz&#34;,&#34;josé&#34;,&#34;python&#34;,&#34;students&#34;,&#34;important&#34;,&#34;results&#34;,&#34;cool&#34;,&#34;influencia&#34;,&#34;university&#34;,&#34;español&#34;,&#34;interesa&#34;,&#34;abrazo&#34;,&#34;city&#34;,&#34;statistics&#34;,&#34;speaker&#34;,&#34;falta&#34;,&#34;making&#34;,&#34;model&#34;,&#34;personal&#34;,&#34;sale&#34;,&#34;necesitas&#34;,&#34;alguna&#34;,&#34;award&#34;,&#34;session&#34;,&#34;profesor&#34;,&#34;models&#34;,&#34;thing&#34;,&#34;tener&#34;,&#34;mayor&#34;,&#34;futuro&#34;],&#34;freq&#34;:[583,463,440,396,261,256,232,215,212,206,189,180,179,171,167,163,160,158,155,153,153,146,144,143,132,132,130,121,120,112,111,108,107,103,103,101,99,95,93,93,92,92,91,91,90,90,89,88,87,86,85,85,82,82,81,80,80,80,78,78,77,77,77,74,74,73,73,73,72,72,71,71,70,69,69,68,67,66,66,65,65,64,63,62,62,62,62,60,60,59,59,58,57,57,57,57,57,57,57,56,56,56,55,55,55,54,54,54,54,54,53,52,52,52,52,52,52,51,51,51,51,51,50,50,50,50,49,48,48,48,48,47,47,47,46,46,46,46,45,45,45,44,44,44,44,44,44,43,43,43,43,43,42,42,42,42,42,42,42,42,42,42,42,42,41,41,41,41,41,41,41,41,41,40,40,40,40,40,39,39,39,39,39,39,39,38,38,38,38,38,38,38,37,37,37,36,36,36,36,36,36,36,36,36,35,35,35,35,35,35,35,35,35,35,35,34,34,34,34,34,34,34,34,34,34,34,34,34,33,33,33,33,33,33,33,33,33,32,32,32,32,32,32,32,32,32,32,31,31,31,31,31,31,31,31,31,31,31,31,31,31,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,29,29,29,29,28,28,28,28,28,28,28,28,28,28,28,28,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21],&#34;fontFamily&#34;:&#34;Loma&#34;,&#34;fontWeight&#34;:&#34;bold&#34;,&#34;color&#34;:&#34;random-dark&#34;,&#34;minSize&#34;:0,&#34;weightFactor&#34;:0.3087478559176672,&#34;backgroundColor&#34;:&#34;white&#34;,&#34;gridSize&#34;:0,&#34;minRotation&#34;:-0.7853981633974483,&#34;maxRotation&#34;:0.7853981633974483,&#34;shuffle&#34;:true,&#34;rotateRatio&#34;:0,&#34;shape&#34;:&#34;circle&#34;,&#34;ellipticity&#34;:0.65,&#34;figBase64&#34;:null,&#34;hover&#34;:null},&#34;evals&#34;:[],&#34;jsHooks&#34;:{&#34;render&#34;:[{&#34;code&#34;:&#34;function(el,x){\n                        console.log(123);\n                        if(!iii){\n                          window.location.reload();\n                          iii = False;\n\n                        }\n  }&#34;,&#34;data&#34;:null}]}}&lt;/script&gt;
&lt;p&gt;As you can see, the word I used more is &lt;em&gt;thanks&lt;/em&gt; (“gracias” in spanish), together with other related to my field of research (&lt;em&gt;networks&lt;/em&gt;, &lt;em&gt;data&lt;/em&gt;, &lt;em&gt;social&lt;/em&gt;, etc.).&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;So, yes I am growing older in Twitter and the way I use the platform is different. I probably spend more time reading that engaging in new conversations, new tweets or creating hashtags for events or conferences. This exercise proves that not only Twitter is a good platform to understand timely events like elections, sports, natural disasters or unemployment, but also to understand how people change in the course of a lifetime (or at least tens of years) with and outside the platform.&lt;/p&gt;
&lt;p&gt;And as my wordcloud shows, I am thankful for those 10 years of sharing the platform with friends, colleagues and other familiar strangers!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Important relationships are not bursty</title>
      <link>http://estebanmoro.org/2017/12/important-relationships-are-not-bursty/</link>
      <pubDate>Tue, 19 Dec 2017 15:32:05 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2017/12/important-relationships-are-not-bursty/</guid>
      <description>&lt;p&gt;What are the properties of a long-lasting relationship? This important question as intrigued the social scientists during the last decades and has triggered numerous publications, surveys and experiments to detect what patterns are behind social relationships that persist. Probably the most famous finding is that of Granovetter who &lt;a href=&#34;https://en.wikipedia.org/wiki/Interpersonal_ties&#34;&gt;proposed&lt;/a&gt; that strong relationships are the ones more likely to persist in the future. And what is a strong relationship? According to Granovetter, a strong relationship is that with high intensity (a lot of interactions), intimacy (mutual confiding) and large structural redundancy (lots of common friends).&lt;/p&gt;
&lt;p&gt;But even strong relationships decay and we don&amp;rsquo;t understand why relationships break apart despite they have a lot of common friends, talk or meet quite often. In a &lt;a href=&#34;http://estebanmoro.org/post/temporal-patterns-behind-the-strength-of-persistent-ties/&#34;&gt;recent paper&lt;/a&gt; we tried to study this problem from another point of view: the temporal style of social interactions. Our research is based on the finding by Barábasi that &lt;a href=&#34;https://www.amazon.com/Bursts-Patterns-Everything-mail-Crusades/dp/0452297184&#34;&gt;human activities are bursty:&lt;/a&gt; short burst of activity (work, communication, going to the library, etc.) are followed by large periods of inactivity. And we have also seen that this happens also for relationships [&lt;a href=&#34;http://estebanmoro.org/2010/11/the-dynamical-strength-of-social-ties-in-information-spreading/&#34;&gt;link&lt;/a&gt;], were interactions (talk, meetings) between people follow also that bursty pattern. &lt;strong&gt;Burstiness is the default&lt;/strong&gt; in human interactions and there are theories that explain its prevalence based on how humans manage their attention and priorities: since we have many tasks to perform, we prioritize them resulting in bursts of events in one activity followed by large inactivity periods in which we are doing some other tasks.&lt;/p&gt;
&lt;p&gt;Thus, if burstiness is the default, &lt;strong&gt;what does a regular activity pattern tell us about the importance of that activity&lt;/strong&gt;? Look at the following plot in which we show four different activities (A to D) performed by the same person (each vertical line is an event).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/bursty.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Each vertical line corresponds to an event in that activity, which for example could be talking or meeting a given friend. As we can see C) and D) are very bursty patterns of activity, while A) and B) are more regular. Note that all activities have the same number of events (8). By looking at these patterns, can you tell which activity/relationship is more important to this person? Maybe A) and B) were more important because they require more attention and regularity in the interaction, while C) and D) are the unexceptional bursty patterns we all have. &lt;a href=&#34;http://estebanmoro.org/2017/06/temporal-patterns-behind-the-strength-of-persistent-ties/&#34;&gt;Our results of our research&lt;/a&gt; corroborate that intuition: in particular we have found that social relationships that look like A) and B) are stronger and are more likely to persist in the future than those like C) or D).&lt;/p&gt;
&lt;p&gt;Thus, &lt;strong&gt;burstiness makes relationships weaker&lt;/strong&gt;, while regularity reveals strong more persistent social ties.  If you really care about a relationship, you have to maintain a regular interaction. Stop what you are doing and call that old friend of yours to let her/him know you really care about them and resume your non-bursty interaction. Pretty much can happen to your New Year&amp;rsquo;s resolutions: if you register for the gym to get fit, try to find a time every week rather than go every now and them when you have free time. This is probably a good way to bit the odds that after 15th of January &lt;a href=&#34;https://www.usatoday.com/story/money/personalfinance/2013/01/16/gyms-new-years-resolution-rush/1779651/&#34;&gt;95% new gym memberships will never come back&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Find our research here:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Temporal patterns behind the strength of persistent ties&lt;/em&gt;
Henry Navarro, Giovanna Miritello, Arturo Canales, Esteban Moro
EPJ Data Science (2017) &lt;strong&gt;6&lt;/strong&gt;:31 [&lt;strong&gt;&lt;a href=&#34;https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0127-3&#34;&gt;LINK&lt;/a&gt;&lt;/strong&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Network Science for kids!</title>
      <link>http://estebanmoro.org/2017/03/network-science-for-kids/</link>
      <pubDate>Tue, 28 Mar 2017 13:58:43 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2017/03/network-science-for-kids/</guid>
      <description>&lt;p&gt;One of my favorite activities is to teach my field or research (network science) to high-schoolers. We (together with my colleague &lt;a href=&#34;https://scholar.google.es/citations?user=gljsfm4AAAAJ&amp;amp;hl=en&#34;&gt;Cristina Brändle&lt;/a&gt;) have been doing that from our university to the local high schools in Madrid. Since they know concepts like equations, probability or geometry, it is somehow easy to show them concepts like what is a network, small world, friendship paradox or centrality. We usually have transparencies and allow them to work on Excel to perform some calculations which works well to understand the basic concepts of networks. At that level, there are a number of resources on the internet, including the &lt;a href=&#34;https://sites.google.com/a/binghamton.edu/netscied/teaching-learning/network-concepts&#34;&gt;Network Literacy Project&lt;/a&gt; lead by Mason Porter and collaborators, which also has some reflections about teaching &lt;a href=&#34;http://www.math.ucla.edu/~mason/papers/teach-final.pdf&#34;&gt;Network Science to teenagers&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/dib3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;But, I was invited by the Math League at my kid&amp;rsquo;s school (&lt;a href=&#34;http://lawrenceschoolbrookline.org&#34;&gt;Lawrence Amos at Brookline&lt;/a&gt;) to talk about networks to 4th, 5th and 6th graders, so I was forced to prepared the most difficult talk in my life: Network Science for kids! The idea was one hour around 3 worksheets in which I wanted to introduce the idea of why Network Science is useful to understand (and solve!) problems, including the six degrees of separation and the Krönigsberg bridges problems. Here are the different worksheets I prepared&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/pdf/netsci_for_kids/networks_ahoy.pdf&#34;&gt;Networks ahoy!&lt;/a&gt; (Concepts: what is a network, how to map a problem into a network)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/pdf/netsci_for_kids/6_degrees_of_separation.pdf&#34;&gt;6 degrees of separation&lt;/a&gt; (Concepts: connectivity, distance in the graph, cascades)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://estebanmoro.org/pdf/netsci_for_kids/the_konisberg_bridges.pdf&#34;&gt;The Krönigsberg bridges&lt;/a&gt; (Concepts: eulerian paths)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The feedback was really positive and I think kids really enjoyed it. Interestingly, they spend some time in the first question in &amp;ldquo;Networks ahoy!&amp;rdquo; worksheet discussing the different results depending on whether the &amp;ldquo;who wants to go with whom&amp;rdquo; was a directed or undirected graph.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/dib2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I was also amazed that they understood very quickly the &amp;ldquo;6 degrees of separation&amp;rdquo; problem and its solution using cascades like the one above. At the end of this worksheet I asked them if they could come up with an idea to use the &amp;ldquo;6 degrees of separation&amp;rdquo; to organize an event and several kids propose to use cascades of invitations to do that. So yes, kids are ready for social mobilization techniques as the one we studied for the &lt;a href=&#34;http://estebanmoro.org/2013/04/limits-of-social-mobilization/&#34;&gt;DARPA Red Balloon Challenge&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The last one has a little bit more difficulty that the rest, but kids love the analogy with drawing shapes without lifting the pencil. We spent some time there drawing shapes like the ones in the figure below and although in the worksheet I only use part of the Euler&amp;rsquo;s solution to the problem, they understood the concept that we can only draw the shapes if there are only two nodes with odd number of lines.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/dib1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;It was a great experience. There were other ideas I had to try with kids but didn&amp;rsquo;t have time to prepare a worksheet. For example, coloring graphs, friendship paradox, etc. My final impression is that kids understood very well the concept of networks and they got how useful they are to analyze some difficult problems. Or just to know how they are connected with other friends and the potential implications in their life. My plan is to use this material for other talks, but you are free to use it as well. As always, comments are welcomed and if you use this material, please let me know what was your feedback!&lt;/p&gt;
&lt;p&gt;PS: there are other places in which you can find material to teach graph theory to kids. I really enjoyed  &lt;a href=&#34;http://jdh.hamkins.org/math-for-seven-year-olds-graph-coloring-chromatic-numbers-eulerian-paths/&#34;&gt;this one&lt;/a&gt; which served me as an inspiration to the last worksheet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Searching for someone</title>
      <link>http://estebanmoro.org/post/2016-02-19-searching-for-someone/</link>
      <pubDate>Fri, 19 Feb 2016 11:52:48 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2016-02-19-searching-for-someone/</guid>
      <description>&lt;p&gt;&lt;strong&gt;From the “Small World Experiment” to the “Red Balloon Challenge,” and beyond&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We live in a small world, right? But the cost and fragility of navigating it could harm any potential strategy to leverage the power of social networks. Read this fascinating story of the research, experiments, and failures in the quest for using social networks to search information/people:&lt;/p&gt;
&lt;p&gt;[Excerpt of the article] Our ability to search social networks for people and information is fundamental to our success. We use our personal connections to look for new job opportunities, to seek advice about what products to buy, to match with romantic partners, to find a good physician, to identify business partners, and so on.&lt;/p&gt;
&lt;p&gt;Despite living in a world populated by seven billion people, we are able to navigate our contacts efficiently, only needing a handful of personal introductions before finding the answer to our question, or the person we are seeking. How does this come to be? In folk culture, the answer to this question is that we live in a “small world.” The catch-phrase was coined in 1929 by the visionary author &lt;a href=&#34;http://en.wikipedia.org/wiki/Frigyes_Karinthy&#34;&gt;Frigyes Karinthy&lt;/a&gt; in his &lt;a href=&#34;https://djjr-courses.wdfiles.com/local--files/soc180%3Akarinthy-chain-links/Karinthy-Chain-Links_1929.pdf&#34;&gt;Chain-Links essay&lt;/a&gt;, where these ideas are put forward for the first time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://medium.com/mit-media-lab/searching-for-someone-688f6c12ff42#.b7aj7mdf0&#34;&gt;Keep reading at MIT Media Lab Medium&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More people, more fun: The scaling of events in cities</title>
      <link>http://estebanmoro.org/2016/02/more-people-more-fun-the-scaling-of-events-in-cities/</link>
      <pubDate>Mon, 08 Feb 2016 09:25:35 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2016/02/more-people-more-fun-the-scaling-of-events-in-cities/</guid>
      <description>&lt;p&gt;This is a recent article publish in Medium.com by David Martín-Corral, Manuel Cebrián and myself in which we analyze the super-scaling of touristic attraction (number of events) with population. Amazingly we found that the number of events (music/theater/sports/etc.) scales super-linearly with the population of the city.&lt;/p&gt;
&lt;p&gt;So yes! more people means more fun!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://medium.com/snsores-lab/more-people-more-fun-the-scaling-of-events-in-cities-f82d3072eb63#.ycvw10mvt&#34;&gt;Read the article in Medium&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2015 year in review</title>
      <link>http://estebanmoro.org/2015/12/2015-year-in-review/</link>
      <pubDate>Wed, 30 Dec 2015 22:05:58 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2015/12/2015-year-in-review/</guid>
      <description>&lt;p&gt;2015 has been an amazing year both on the professional and personal grounds. Here are some of the main things that happened this year:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I helped to build up the &amp;ldquo;&lt;a href=&#34;http://www.afiescueladefinanzas.es/efa/comun/master-data-science-big-data-finanzas.html&#34;&gt;Master in Data Science and Big Data in Finance&lt;/a&gt;&amp;rdquo; at the &lt;a href=&#34;http://www.afiescueladefinanzas.es&#34;&gt;Afi School of Finance&lt;/a&gt;. In this first edition we had 18 incredible students and the support from most of the big financial companies in Spain and the best researchers, practitioners and data scientist in the financial industry.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/afi2015.jpg&#34; alt=&#34;2015 class of Master in Data Science and Big Data&#34;&gt;
2015 class of Master in Data Science and Big Data at AFI Escuela&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Co-organization of &lt;a href=&#34;http://netmob.org&#34;&gt;NetMob&#39;15&lt;/a&gt; at the MIT Media Lab. In this edition the international conference of analysis of mobile databases had ~250 participants from the main universities, United Nations, telecomm operators and many more institutions and agencies.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My review article about &amp;ldquo;Network Analysis&amp;rdquo; appeared in the &lt;a href=&#34;http://press.princeton.edu/titles/10592.html&#34;&gt;Princeton Companion to Applied Mathematics&lt;/a&gt;, the single-volume (and huge!) reference book on applied mathematics. Edited by the brilliant &lt;a href=&#34;http://www.maths.manchester.ac.uk/~higham/&#34;&gt;Nicholas J. Higham&lt;/a&gt;. The email network of my university was used to illustrate some concepts :)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/princeton.png&#34; alt=&#34;princeton&#34;&gt;Email Network at my University showing degree heterogeneity[/caption]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Program chair of &lt;a href=&#34;http://www.netsci2015.net&#34;&gt;Netsci2015&lt;/a&gt;, the largest conference of network science which took place in Zaragoza this year. Thanks to the program committee we were able to sort out more than 400 abstracts received. So thankful to Yamir Moreno and Sandro Meloni (organizers) for making it possible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I gave around 20 talks in many scientific institutions, companies and conferences. From the short (and most stressful) 6min talk at &lt;a href=&#34;http://databeers.tumblr.com/post/114580792956/meetup-april-23rd-2015-1900-medialab-prado&#34;&gt;Databeers Madrid&lt;/a&gt; to the one in the largest screen I ever have seen (20m wide) at the presentation of the new &lt;a href=&#34;http://www.sngular.team&#34;&gt;Sngular company&lt;/a&gt;
* 5 talks at different high-schools in Madrid about the importance of mathematics to understand our daily life: from the lottery to social networks. This was an great project made possible by the outreach program of our university and a huge and tough responsibility to teach to teenagers.
* We have published 7 papers in different journals, including Physical Review Letters, Physical Review E and PLoS One. Including a &lt;a href=&#34;http://estebanmoro.org/2015/05/from-seconds-to-months-multi-scale-dynamics-of-mobile-telephone-calls/&#34;&gt;mini-review&lt;/a&gt; on temporal networks in mobile phone calls with &lt;a href=&#34;http://www.lce.hut.fi/~jsaramak/&#34;&gt;Jari Saramaki&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/sngular.jpg&#34; alt=&#34;Talk at Sngular event&#34;&gt; That small person in front of the screen is me :)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This year a number a number of students who I advised defended their works:
* One PhD Thesis (by Svetozar Nesic) on &lt;a href=&#34;http://e-archivo.uc3m.es/handle/10016/21858&#34;&gt;&amp;ldquo;Stochastic Dynamics of Substrate-confined Systems: Fisher Fronts and Thin Liquid Films&amp;rdquo;&lt;/a&gt;,
* Two Master thesis on &amp;ldquo;The tie decay problem in social networks: Why do people stop calling?&amp;rdquo; by Henry Navarro, and on &amp;ldquo;Non-negativity preserving numerical algorithms for problems in mathematical finance&amp;rdquo; by Yuan Yuan
* One Degree Final Project on &lt;a href=&#34;https://repositorio.uam.es/xmlui/bitstream/handle/10486/668988/Medina_Perez_Maria_tfg.pdf?sequence=1&#34;&gt;&amp;ldquo;Estimation of Socio-Economical indicators based on Online Social Networks digital traces&amp;rdquo;&lt;/a&gt; by María Medina.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/mariamedina.jpg&#34; alt=&#34;Maria Medina presenting her Degree Final project&#34;&gt;
Maria Medina presenting her Degree Final project[/caption]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;We had a number of projects with different companies (and many more coming!). For example this year we collaborated with Twitter Spain to understand the dynamics of political opinion during 2015 and the different elections (&lt;a href=&#34;http://portal.uc3m.es/portal/page/portal/actualidad_cientifica/noticias/Twitter&#34;&gt;local, regional&lt;/a&gt;, &lt;a href=&#34;http://prnoticias.com/comunicacion/20147102-conversacion-politica-en-twitter?tmpl=component&amp;amp;print=1&#34;&gt;national&lt;/a&gt;) that took place.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This year I started to serve as editor in the &lt;a href=&#34;http://www.epjdatascience.com&#34;&gt;EPJ Data Science journal &lt;/a&gt;which focuses on the publication of data-driven research. Together with my work as editor in JSTAT, I edited 15 papers and was referee in around 20 papers during 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My university (UC3M) gave me the &amp;ldquo;Excellence in Research&amp;rdquo; award for the second time in a row. I am really honoured and grateful. I also become a member the UC3M-BS Institute of Financial Big Data, a joint institute between our university UC3M and Banco Santander to promote interdisciplinary research in analyzing Big Data with emphasis on financial applications. I also participated in many committees in my university, but you don&amp;rsquo;t want to know about it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/2015award.jpg&#34; alt=&#34;My university gave me the &amp;ldquo;Excellence in Research&amp;rdquo; award for the second time. So proud!&#34;&gt; My university gave me the &amp;ldquo;Excellence in Research&amp;rdquo; award for the second time. So proud!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some data: my blog received more than 20k visits, and I published 7 posts. I also wrote 909 tweets and this is the tweet that got more views (impressions)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Our paper about social media behaviors and unemployment is finally out!! &lt;a href=&#34;http://t.co/SeuHmJRaMZ&#34;&gt;http://t.co/SeuHmJRaMZ&lt;/a&gt; &lt;a href=&#34;http://t.co/DmLBMMs9Y5&#34;&gt;pic.twitter.com/DmLBMMs9Y5&lt;/a&gt;&lt;/p&gt;&amp;mdash; Esteban Moro (@estebanmoro) &lt;a href=&#34;https://twitter.com/estebanmoro/status/604193706288238592?ref_src=twsrc%5Etfw&#34;&gt;May 29, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;ul&gt;
&lt;li&gt;Finally, all these was possible due to the collaborations, discussions, coffees, slacks, emails, skypes, hangouts, google docs, lunchs and dinners with my collaborators/friends. I am really lucky to collaborate with people like &lt;a href=&#34;https://about.me/mcebrian&#34;&gt;Manuel Cebrián&lt;/a&gt; (at CSIRO Data61 Australia), &lt;a href=&#34;http://www.mit.edu/~irahwan/&#34;&gt;Iyad Rahwan&lt;/a&gt; (who recently joined MIT Media Lab), &lt;a href=&#34;https://mherranz.wordpress.com&#34;&gt;Manuel García-Herranz&lt;/a&gt; (at UNICEF Innovation Unit), &lt;a href=&#34;https://www.linkedin.com/in/giovanna-miritello-a6675919&#34;&gt;Giovanna Miritello&lt;/a&gt; (at ZED Spain), &lt;a href=&#34;https://www.linkedin.com/in/alejandro-llorente-pinto-07011230&#34;&gt;Alejandro Llorente&lt;/a&gt; (who founded the start-up &lt;a href=&#34;http://piperlab.es&#34;&gt;PiperLab&lt;/a&gt; this year), &lt;a href=&#34;https://www.linkedin.com/in/davidmartincorralcalvo&#34;&gt;David Martín-Corral&lt;/a&gt; (who decided to start a PhD with me this year), Moisés Morales and Borja Foncillas (at AFI), &lt;a href=&#34;http://victoriano.me&#34;&gt;Victoriano Izquierdo&lt;/a&gt; (at Graphext) and many other.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/IMG_2378.jpg&#34; alt=&#34;Nice dinner with friends&#34;&gt;Nice dinner with friends&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temporal networks with R and igraph (updated)</title>
      <link>http://estebanmoro.org/post/2015-12-21-temporal-networks-with-r-and-igraph-updated/</link>
      <pubDate>Mon, 21 Dec 2015 21:17:18 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2015-12-21-temporal-networks-with-r-and-igraph-updated/</guid>
      <description>&lt;p&gt;A while ago, I wrote &lt;a href=&#34;http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/&#34;&gt;a post&lt;/a&gt; about how to create animations of temporal networks using R and the amazing package &lt;a href=&#34;http://igraph.org&#34;&gt;igraph package&lt;/a&gt;. The post was written in 2012 and the code does not work with the most recent versions (1.0) of &lt;code&gt;igraph&lt;/code&gt;. Here I revisited that post, improving its performance and also making it consistent with the new versions of the package and R.&lt;/p&gt;
&lt;p&gt;First of all, let me remind you the basic idea: we want to get an animated evolution of a network in which nodes/edges appear (and/or disappear) dynamically. We also want a &amp;ldquo;dynamical layout&amp;rdquo; for the temporal network in which the arrangement of the nodes and edges changes accordingly to the dynamics of the temporal network. In this post I will show you how to render the network at each time step and how to encode all snapshots into a video file using the &lt;code&gt;igraph&lt;/code&gt; package in R and &lt;code&gt;ffmpeg&lt;/code&gt;. The idea is very simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;generate a number of snapshots of the network at different times using R and &lt;code&gt;igraph&lt;/code&gt;, and&lt;/li&gt;
&lt;li&gt;then put them together in a video file using the &lt;code&gt;ffmpeg&lt;/code&gt; encoding tool&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the first part we need to draw the temporal network at each snapshot. Given the set of nodes and edges present at a given time, we have to find a layout for that instantaneous graph and plot the graph using that layout. There are many algorithms in &lt;code&gt;igraph&lt;/code&gt; to do that, mainly, &lt;a href=&#34;http://en.wikipedia.org/wiki/Force-based_algorithms_(graph_drawing)&#34;&gt;force based algorithms&lt;/a&gt;, which try to find the best disposition of nodes and edges for a given graph, typically starting from a random position. The problem is that from one snapshot to the following, the layout could vary significantly, producing a swarm-of-bees kind of motion when we put the snapshots together&lt;/p&gt;
&lt;p&gt;The solution is then to evolve smoothly the layout from one snapshot to the following, by allowing only small changes to accommodate the changes in edges and nodes. To do that we need layout algorithms in which we can specify the initial positions of the nodes and let the algorithm evolve smoothly from that initial position. In &lt;code&gt;igraph&lt;/code&gt;, this can be done for the Graphopt (&lt;code&gt;layout_with_graphopt&lt;/code&gt;), Kamada-Kawai (&lt;code&gt;layout_with_kk&lt;/code&gt;) and Fruchterman-reingold (&lt;code&gt;layout_with_fr&lt;/code&gt;) algorithms using the &lt;code&gt;coords&lt;/code&gt; or &lt;code&gt;start&lt;/code&gt; argument:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(igraph)
&lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt;(mfrow&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),mar&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), oma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;watts.strogatz.game&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
layout.old &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout_with_fr&lt;/span&gt;(g)
&lt;span style=&#34;color:#a6e22e&#34;&gt;for&lt;/span&gt;(i in &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;){
  layout.new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout_with_fr&lt;/span&gt;(g,niter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,coords&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.old,
                              start.temp&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;,grid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nogrid&amp;#34;&lt;/span&gt;)
  &lt;span style=&#34;color:#a6e22e&#34;&gt;plot&lt;/span&gt;(g,layout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.new)
  layout.old &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layout.new
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;http://estebanmoro.org/post/2015-12-21-temporal-networks-with-r-and-igraph-updated_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;As you can see the layouts are similar. There are three parameters passed to the layout function: &lt;code&gt;niter = 10&lt;/code&gt; which specifies the number of iterations (10) of energy minimization procedure in the forced based algorithm. This number should be small, otherwise the final result will be very different from the initial condition. The argument &lt;code&gt;start.temp&lt;/code&gt; is the maximum amount of movement allowed along one axis, within one step, for a vertex and it should be kept small for the same reason. Finally, for performance issues, the Fruchterman-reingold algorithm might be implemented in a grid, something we prevent by using the &lt;code&gt;grid=&amp;ldquo;nogrid&amp;rdquo;&lt;/code&gt; setting.&lt;/p&gt;
&lt;p&gt;The second problem is that in a temporal network nodes and/or edges appear and disappear dynamically. Thus the time dependent graph might have different number of nodes and/or edges from one snapshot to the next one. This means that the layout at a given snapshot cannot be used as the initial condition to generate next time layout, since the number of nodes can be different. My approach here is very simple: consider all (past/present/future) nodes/edges and calculate the layout for all of them in each step, but considering only those edges which are present at a given time and displaying only nodes with at least one edge. This trick allows the reutilization of the layouts between steps. Furthermore, it will produce a layout in which present nodes are tightly connected, while past/future nodes are repelled from them. This effect dramatically highlights the appearance and disappearance of nodes, but could create too much confusion if there are many of those events.&lt;/p&gt;
&lt;p&gt;To test this ideas, we will again work an important example in the theory of complex networks: the preferential attachment mechanism to generate scale-free networks, i.e. the &lt;a href=&#34;http://en.wikipedia.org/wiki/BA_model&#34;&gt;Barabási-Albert model&lt;/a&gt;. In our implementation, we keep the mechanism very simple: starting from an initial core of nodes, at each time step we add a single node that connects to m existing nodes which are selected proportionally to the number of links that the existing nodes already have. This mechanism leads to heavily linked nodes (“hubs”) together with a large fraction of poorly connected nodes. A particular realization of this model can be found in the file &lt;code&gt;edges.csv&lt;/code&gt; below. The structure of the file is simple&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;ff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read.table&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://raw.githubusercontent.com/emoro/temporal_networks/master/edges.csv&amp;#34;&lt;/span&gt;,header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;T)
&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt;(ff)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;##   id1 id2 time
## 1   1   2    1
## 2   1   3    1
## 3   2   3    1
## 4   5   3    2
## 5   6   2    3
## 6   7   2    4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;each line of the form &lt;code&gt;id1 | id2 | time &lt;/code&gt; indicates that a link between id1 and id2 appears at a particular time. Depending on the context this might represent that the tie was activated at that particular instant (for example if it is a RT between two twitter accounts) or that it was the time in which the edge appeared first (like in our Barabási-Albert model).&lt;/p&gt;
&lt;p&gt;Here is the code to generate the snapshots and producing a PNG picture for each of them&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#this version of the script has been tested on igraph 1.0.1&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#load libraries&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;require&lt;/span&gt;(igraph,RcolorBrewer)

&lt;span style=&#34;color:#75715e&#34;&gt;#load the edges with time stamp&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#there are three columns in edges: id1,id2,time&lt;/span&gt;
edges &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read.table&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;edges.csv&amp;#34;&lt;/span&gt;,header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;T)

&lt;span style=&#34;color:#75715e&#34;&gt;#generate the full graph&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;graph.data.frame&lt;/span&gt;(edges,directed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;F)

&lt;span style=&#34;color:#75715e&#34;&gt;#generate a cool palette for the graph (darker colors = older nodes)&lt;/span&gt;
YlOrBr.pal &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;colorRampPalette&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;brewer.pal&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;YlOrRd&amp;#34;&lt;/span&gt;))
&lt;span style=&#34;color:#75715e&#34;&gt;#colors for the nodes are chosen from the very beginning&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;V&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rev&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;YlOrBr.pal&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;vcount&lt;/span&gt;(g)))&lt;span style=&#34;color:#a6e22e&#34;&gt;[as.numeric&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;V&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;name)]

&lt;span style=&#34;color:#75715e&#34;&gt;#time in the edges goes from 1 to 300. We kick off at time 3&lt;/span&gt;
ti &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#remove edges which are not present&lt;/span&gt;
gt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_edges&lt;/span&gt;(g,&lt;span style=&#34;color:#a6e22e&#34;&gt;which&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; ti))
&lt;span style=&#34;color:#75715e&#34;&gt;#generate first layout using graphopt with normalized coordinates. This places the initially connected set of nodes in the middle. If you use fruchterman.reingold it will place that initial set in the outer ring.&lt;/span&gt;
layout.old &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;norm_coords&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;layout.graphopt&lt;/span&gt;(gt), xmin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, xmax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, ymin &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;-1&lt;/span&gt;, ymax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;#total time of the dynamics&lt;/span&gt;
total_time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time)
&lt;span style=&#34;color:#75715e&#34;&gt;#This is the time interval for the animation. In this case is taken to be 1/10&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#of the time (i.e. 10 snapshots) between adding two consecutive nodes&lt;/span&gt;
dt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#Output for each frame will be a png with HD size 1600x900 :)&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;png&lt;/span&gt;(file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;animation/example%03d.png&amp;#34;&lt;/span&gt;, width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1600&lt;/span&gt;,height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;900&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;#Time loop starts&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;for&lt;/span&gt;(time in &lt;span style=&#34;color:#a6e22e&#34;&gt;seq&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,total_time,dt)){
  &lt;span style=&#34;color:#75715e&#34;&gt;#remove edges which are not present&lt;/span&gt;
  gt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;delete_edges&lt;/span&gt;(g,&lt;span style=&#34;color:#a6e22e&#34;&gt;which&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; time))
  &lt;span style=&#34;color:#75715e&#34;&gt;#with the new graph, we update the layout a little bit&lt;/span&gt;
  layout.new &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout_with_fr&lt;/span&gt;(gt,coords&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.old,niter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,start.temp&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;,grid&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nogrid&amp;#34;&lt;/span&gt;)
  &lt;span style=&#34;color:#75715e&#34;&gt;#plot the new graph&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;plot&lt;/span&gt;(gt,layout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.new,
       vertex.label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,vertex.size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1+2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;degree&lt;/span&gt;(gt)),
       vertex.frame.color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;V&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;color,edge.width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;,
       asp&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,margin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;-0.15&lt;/span&gt;)
  &lt;span style=&#34;color:#75715e&#34;&gt;#use the new layout in the next round&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;#use the new layout in the next round&lt;/span&gt;
  layout.old &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; layout.new
}
&lt;span style=&#34;color:#a6e22e&#34;&gt;dev.off&lt;/span&gt;()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you can see the edges present before time &lt;code&gt;ti=3&lt;/code&gt; are considered as the initial seed for the animation. The rest of the edges are removed from the graph and the layout is calculated. At each time step in the loop the same procedure is followed: delete all edges with function &lt;code&gt;delete_edges&lt;/code&gt; which are not present at time &lt;code&gt;time&lt;/code&gt;, update the layout a little bit and plot the corresponding graph. Note that the size of the vertices is log-proportional to their &lt;code&gt;degree&lt;/code&gt;, which means that if there is no edge incident to a node, the size of the node is &lt;code&gt;-Inf&lt;/code&gt; and it is not displayed. This way of hiding nodes can be change to be more elegant, but it does the trick here.&lt;/p&gt;
&lt;p&gt;After running the script above you will end up with a number of files named &lt;code&gt;example001.png&lt;/code&gt;, &lt;code&gt;example002.png&lt;/code&gt; and so on. To encode these images into a video format you can use the &lt;a href=&#34;http://ffmpeg.org&#34;&gt;ffmpeg&lt;/a&gt;  tool which can be install in linux, windows or mac. The following command line in a terminal shell produces a video file &lt;code&gt;output.mp4&lt;/code&gt; in the mpeg format:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;ffmpeg &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;r &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;i example%&lt;span style=&#34;color:#ae81ff&#34;&gt;03&lt;/span&gt;d.png &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;v &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;M output.mp4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first &lt;code&gt;-r 10&lt;/code&gt; flag controls the rate of frames per second (fps), 10 in this case, while the &lt;code&gt;-b:v 20M&lt;/code&gt; sets the bitrate in the output (set to a large value here, 20M). The result is the following video&lt;/p&gt;
&lt;iframe class=&#34;vimeo-embed embed-responsive-item&#34; src=&#34;https://player.vimeo.com/video/149633952&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;This is it! Done with 17 lines in R and updated to the last version of igraph (1.0). I am eager to know your comments. Please!&lt;/p&gt;
&lt;p&gt;The scripts and data can also be found at &lt;a href=&#34;https://github.com/emoro/temporal_networks&#34;&gt;https://github.com/emoro/temporal_networks&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Netmob 2015</title>
      <link>http://estebanmoro.org/post/2015-04-14-netmob-2015/</link>
      <pubDate>Tue, 14 Apr 2015 09:26:11 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2015-04-14-netmob-2015/</guid>
      <description>&lt;p&gt;I had the pleasure to organize last edition of &lt;a href=&#34;http://netmob.org&#34;&gt;Netmob&lt;/a&gt; at MIT Media Lab (together with &lt;a href=&#34;http://web.media.mit.edu/~sandy/&#34;&gt;Sandy Pentland&lt;/a&gt;, &lt;a href=&#34;http://perso.uclouvain.be/vincent.blondel/&#34;&gt;Vincent Blondel&lt;/a&gt; and &lt;a href=&#34;http://www.demontjoye.com&#34;&gt;Yves-Alexandre de Montjoye&lt;/a&gt;). Netmob is the primary conference in the analysis of those datasets in social, urban, societal and industrial problems. Netmob 2015 also hosted the final part of the&lt;a href=&#34;http://www.d4d.orange.com/en/home&#34;&gt; D4D Challenge&lt;/a&gt; by Orange. They were 3 amazing days of applications and analysis of mobile phone datasets, preceded by one-day school and 3 days Hackathon. More than 60 talks and 40 posters were presented. Around 250 participants from 140 institutions, 32 countries (5 continents!) participated, showing the international and wide interest in Netmob.&lt;/p&gt;
&lt;p&gt;Here is some information about the event:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://netmob.org&#34;&gt;Homepage of Netmob&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://netmob.org/#abstracts&#34;&gt;Books of abstracts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/netmob15&#34;&gt;Twitter account&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And some pictures&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/FullSizeRender-1024x803.jpg&#34; alt=&#34;Conference chairs: Yves-Alexandre de Montjoye, Esteban Moro, Alex &amp;lsquo;Sandy&amp;rsquo; Pentland and Vincent Blondel&#34;&gt;Conference chairs: Yves-Alexandre de Montjoye, Esteban Moro, Alex &amp;lsquo;Sandy&amp;rsquo; Pentland and Vincent Blondel&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/mapanetmob.jpg&#34; alt=&#34;Map of the different countries of the Netmob 2015 participants&#34;&gt;Map of the different countries of the Netmob 2015 participants&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/CCQOkDXUgAA1dxp.jpg-large.jpg&#34; alt=&#34;Giving the farewell speech at Netmob 2015&#34;&gt;
Giving the farewell speech at Netmob 2015&lt;/p&gt;
&lt;p&gt;Media coverage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Por tu móvil te conocerán [&lt;a href=&#34;http://www.elbuzon.es/por-tu-movil-te-conoceran-10540&#34;&gt;Elbuzón.es&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;El móvil permitirá estudiar el comportamiento humano a un nivel espacial, temporal y social “sin precedentes” [&lt;a href=&#34;http://noticias.lainformacion.com/economia-negocios-y-finanzas/equipos-de-telecomunicaciones/el-movil-permitira-estudiar-el-comportamiento-humano-a-un-nivel-espacial-temporal-y-social-sin-precedentes_E3an5tt8AK01oV8FjC3Qi7/&#34;&gt;LaInformación.com&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Analysis of mobile phone data applied to economic and social problems [&lt;a href=&#34;http://phys.org/news/2015-04-analysis-mobile-economic-social-problems.html&#34;&gt;Phys.org&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Best papers of the 2013. What is privacy? </title>
      <link>http://estebanmoro.org/2014/01/best-papers-of-the-2013-what-is-privacy/</link>
      <pubDate>Wed, 01 Jan 2014 12:40:44 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2014/01/best-papers-of-the-2013-what-is-privacy/</guid>
      <description>&lt;p&gt;I have read around 200 papers this year. A large fraction of them were very technical, some reviews and other very fashionable. But among them, I would like to highlight the ones that for me are the best. This is a personal selection and it is based not only on the technical aspects, but more on their impact. Specifically, these two papers change the way we look at privacy and how our actions reveal important information about us which was not obvious in the first place. These are the two papers I consider to be the best of 2013&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * [Private traits and attributes are predictable from digital records of human behavior](http://www.pnas.org/content/early/2013/03/06/1218772110)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;by Michal Kosinski, David Stillwell, and Thore Graepel, published in PNAS
* &lt;a href=&#34;http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html&#34;&gt;Unique in the crowd: the privacy bounds of human mobility&lt;/a&gt; by Yves-Alexandre de Montjoye, César A. Hidalgo, Michel Verleysen &amp;amp; Vincent D. Blondel, published in Scientific Reports&lt;/p&gt;
&lt;p&gt;The first paper reveals how Facebook &amp;ldquo;likes&amp;rdquo; can reveal important information about people like where we live, our sexual orientation, ethnicity, religious or political views, intelligence, happiness. But more worrisome is the potential prediction of use of addictive substances, parental separation, personality traits, etc. This has important implications for online personalization and privacy. Not only commercial companies can access information that individuals may not have intended to share. But one can imagine situations in which such predictions could pose a threat to individual&amp;rsquo;s freedom. You can check what your likes and friends reveal about you in the webpage app that the authors build up as a demonstration &lt;a href=&#34;http://youarewhatyoulike.com&#34;&gt;http://youarewhatyoulike.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The second paper addresses the important question in BigData applications, and also scientific research: how many data is needed to identify a particular individual? That is, how much level of anonymity is there in the data we leave behind in our everyday life? Most people (including me) think that a large volume of anonymous data might be needed to identify us. Thus our privacy is secured if we do not reveal a lot of information about us. But the researchers found that just 4 geolocalized phone calls can uniquely identify us. Just 4 calls! the reason behind is that our mobility is highly predictable and thus just 4 points in the dataset unveil that personal mobility pattern. Given the amount of geolocalized data that can be access from social networks, mobile phone data, etc. these results show that there is a growing concern that little information can be used to identify a targeted individual even in a completely anonymous dataset.&lt;/p&gt;
&lt;p&gt;Most probably 2014 will reveal more privacy bounds and breaches in our online social life. For now, 2013 has shown us that privacy was not what is written in the Terms of Use or what we thought from our everyday life experience.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Via Catalana from the Twittersphere</title>
      <link>http://estebanmoro.org/2013/11/via-catalana-from-the-twittersphere/</link>
      <pubDate>Sun, 10 Nov 2013 10:10:14 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2013/11/via-catalana-from-the-twittersphere/</guid>
      <description>&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;p&gt;&lt;em&gt;Joint work by&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manuel García-Herranz, Department of Computer Science, Universidad Autonóma de Madrid&lt;/li&gt;
&lt;li&gt;Manuel Cebrián, National Information and Communications Technology Australia, University of Melbourne&lt;/li&gt;
&lt;li&gt;Esteban Moro, Department of Mathematics, Universidad Carlos III de Madrid&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While public demonstrations are Social Science’s most important and studied phenomena, they are also the most mysterious and poorly understood ones. Demonstrations trigger new social movements, change countries attitudes, and have the potential to overthrow governments. Despite these social expressions being people’s most powerful force, very little is known about how they form, why the form, and most importantly, who they are formed by.&lt;/p&gt;
&lt;p&gt;Via Catalana, Catalonia’s 250-mile human chain, is no exception to this mystery. As the human chain formed between the south of France and Valencia, many of the old questions popped up again in debates among journalists, politicians, and pretty much every café around Spain: was Via Catalana a grass-roots movement, or was it organized by a political central party? Did it represent the whole Catalonian society, or just a niche of society? Is there a “silent majority” of Catalans that disagree with the chain, or is the silence a way of showing support? The central question regarding the ultimate fate of the region: is there a fundamental social divide between members of the human chain and the rest of Spain? All of these questions were left unanswered by political analysts at the time, a fact clearly illustrated by official estimates of participation, which varied several orders of magnitude.&lt;/p&gt;
&lt;p&gt;Yet Via Catalana is different, especially in the age of Big Data. Because Via Catalana is a a physical human-chain positioned across Catalonia at a concrete time and date, data scientists can study it through the hundreds of thousands of digital traces in Twitter, or as we like to call it, the Twittersphere.&lt;/p&gt;
&lt;p&gt;For this study, we collected 97,405 geo-located Twitter messages in Spain during the day of Via Catalana, September 11th 2013, 21,237 of which were located in Catalonia. We collected a similar number of messages in the previous two days on September 10th and 9th. These days serve as a reference to study how message information, social connections, language use, sentiment, and human mobility, changed as a result of this powerful social demonstration. Without these “normal day” references, we run into the risk of underestimating or overestimating the impact of Via Catalana.&lt;/p&gt;
&lt;p&gt;The best way to gain insight into the change with respect to human mobility is to visualize the dynamics of human mobility of the days, 9th (light blue), 10th (dark blue), and 11th(red), and overlay them on top of each other. The study comprises the full day, from midnight to midnight, iterated hour by hour (see video)&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/74914370&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The difference between the previous two days and the Via Catalan day is striking. The peak in divergence in mobility patterns emerges around 14:00 hours, more than three hours before the “all-arms-linked” programmed time. The most patent manifestation of the chain happens well outside the Barcelona urban center, where normally there are no clear mobility patterns (just the commuting patterns of people traveling in and out of Barcelona) and the chain is easily identifiable. Interestingly, we observe that not all the fragments of the chain form at the same speed. There are two particular fragments: 1) from El Vendrell to the outskirts of Barcelona, and 2) the one comprising Blanes and Perpinyà, which required an additional two hours to form. We conjecture that this may be due to the fact that these fragments are special – they are the only fragments of Via Catalan that do not follow the coast line. The absence of a clear geographical reference may induce additional coordination costs for the mobilization; this is something that should be taken into account by practitioners when programming future demonstrations.&lt;/p&gt;
&lt;p&gt;We also see that, at a much earlier time than the peak of the chain, an abnormal influx of individuals towards the pre-arranged location of the chain occurs around 10:00am, seven hours prior to the “all-arms-linked” programmed time. This indicates that most of the individuals decided to take advantage of the day-long holiday in Catalonia (National Day of Catalonia), which displaced them from distant regions of Catalonia and kept them from participating. It serves as an excellent way to quantify the effort, as a proxy for interest, that this movement marshaled.&lt;/p&gt;
&lt;p&gt;The chains remain stable until approximately 22:00, where they start to disintegrate uniformly along the whole length of the chain. Twitter activity diminishes significantly after that time, and therefore more work is needed to reconstruct the traveling patterns after Via Catalana is dissolved.&lt;/p&gt;
&lt;p&gt;Our findings illustrate the importance of the clear geographical patterns of this &lt;a href=&#34;http://estebanmoro.org/post/2013-04-01-limits-of-social-mobilization/&#34;&gt;social mobilization&lt;/a&gt; – absent from other types of demonstrations, where, despite having a pre-arranged plan (e.g. marching along the downtown area of a city), the human mobility patterns are difficult to distinguish from the normal day ones. The clear geographical pattern unleashes the potential of Twitter (and other types of publicly available digital traces) to distinguish participants from non-participants, and open avenues for the behavioral analysis of these groups. Without this strong geographical pattern, the possibilities of Big Data cannot be fully exploited.&lt;/p&gt;
&lt;p&gt;The next step of our investigation is studying how Via Catalana shaped the participants’ behavior, as measured by the information Catalonians inputted in their Twitter messages. A clear avenue to look at is the use of Catalan vs. Spanish language in the messages, given that Catalonia enjoys a bilingual society. A significant proportion of foreigners live in Catalonia, and Barcelona is a huge touristic attraction.&lt;/p&gt;
&lt;p&gt;A snapshot of on September 10th at 17:00 vs. the same 17:00 on Via Catalana day (picture below) allows us to study how the demonstration shaped use of the language. Dots indicate geo-located Twitter messages using Spanish (Red), Catalan (blue) and Other/Unidentified (green) languages.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/viacatalana.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see a striking difference between September 10th and September 11th. September 10th displays a well-mixed used of Catalan, Spanish, and others; whereas September 11th shows a unifying use of Catalan along the human chain, as well as a marked increase of the use of Catalan in the whole Catalan Region.&lt;/p&gt;
&lt;p&gt;Simple counting further illustrates this phenomenon. The number of geo-located tweets on September 10th is 14,711, with 5654 (38%) in Spanish and 3356 (23%) in Catalan. These numbers are dramatically reversed on the Via Catalana day, with 21,237 geo-located Twitter messages logged, 6074 (28%) in Spanish, and 8599 (40%) in Catalan.&lt;/p&gt;
&lt;p&gt;It is particularly interesting to see that at both extremes of the chain, the one touching Valencia and the one touching the south of France, the use of mixed languages is more pronounced, whereas a pure Catalan use is patent in between these extremes and downtown Barcelona. We also observe two hotspots of the use of Spanish along the chain, in Mataro and Villafranca del Penedes. Further investigation into the demographics of these two regions is required to uncover the origin of their outlier nature.&lt;/p&gt;
&lt;p&gt;Barcelona also emerges as an aggregator of languages and cultures, with high levels of language mixing even during Via Catalana. The capacity of urban centers to be exceptional engines for diversity has been known for quite some time in urban planning literature; however, the fact that diversity is resilient to undergoing social events such as Via Catalan is remarkable and a novel insight in Social Science.&lt;/p&gt;
&lt;p&gt;These two insights, the dynamics in the human mobility undergoing the formation of Via Catalana, as well as how it dramatically affected the use of language, as just “low-hanging fruits,” can be uncovered looking at Via Catalana from the Twittersphere. Many other investigations follow, namely 1) how sentiment, as inferred from the text contained in the Twitter messages, changed as a result of Via Catalana, and 2) how sentiment from the rest of Catalonia and Spain was affected by Via Catalana.&lt;/p&gt;
&lt;p&gt;Inference of the social connections between the Twitter users, both participants and non-participants in Via Catalana, will likely shed the most interesting insights. Algorithmic detection of communities from the social connections will uncover – perhaps for the first time ever at this scale – whether the participants in Via Catalana form one differentiated social group, or, on the other hand, &lt;a href=&#34;http://estebanmoro.org/post/2011-06-17-twitter-y-politica-informacion-opinion-y-prediccion&#34;&gt;are embedded into the larger Catalonian society&lt;/a&gt;. This is a matter of debate that has haunted local and state politicians for over a century.&lt;/p&gt;
&lt;p&gt;We not only will look at how Via Catalana differed from the immediate past, but also, most importantly, how the movement is going to change the future social structure of the region. We are logging the daily dynamics of all Twitter users since the movement began, which will enable us to understand whether Via Catalana brought &lt;a href=&#34;http://estebanmoro.org/post/2011-07-21-social-features-of-online-networks-the-strength-of-weak-ties-in-online-social-media/&#34;&gt;social ties from inside and outside Catalonia farther or closer&lt;/a&gt;, and at &lt;a href=&#34;http://estebanmoro.org/post/2014-04-09-using-friends-as-sensors/&#34;&gt;which pace these social changes are happening&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We truly believe that the digital traces emergent from Via Catalana provide the most exciting social laboratory for understanding how public demonstrations at super fast time scales shape social structure over the long term. It is an exhilarating time for us data scientists, and we can barely stop to write these words, as we go back into deep into the data. Every new line of code we type uncovers a hidden social reality that we want to share with the larger society.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are you a social keeper or a social explorer?</title>
      <link>http://estebanmoro.org/post/2013-05-03-are-you-a-social-keeper-or-a-social-explorer/</link>
      <pubDate>Fri, 03 May 2013 13:16:38 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2013-05-03-are-you-a-social-keeper-or-a-social-explorer/</guid>
      <description>&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;p&gt;In our last (just accepted) paper “Limited communication capacity unveils strategies for human interaction” [&lt;a href=&#34;http://www.nature.com/srep/2013/130606/srep01950/full/srep01950.html&#34;&gt;link&lt;/a&gt;] we have found that we humans have different social strategies when we communicate/interact with people. Specifically, the sociability of a person (the total number of contacts in a time interval) which is usually taken as the connectivity in the social network is actually the result of two different human features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Social capacity:&lt;/strong&gt; the number of relationships humans can maintain opened and which is limited&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social activity&lt;/strong&gt;: the number of relationships human form and destroy as a consequence of their daily tasks, family, events, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Social capacity and activity are very heterogenous and while most individuals have small capacity and activity, some might have large values for those characteristics. The ratio between these characteristics of human interaction determines the &lt;strong&gt;social strategy:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Social keepers&lt;/strong&gt;: these people have a small social activity compared to their social capacity, that is, they interact mostly with the same people in a time interval and form/destroy a small number of ties.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social explorers&lt;/strong&gt;: the opposite strategy, meaning that most of the interactions of these people are form and destroyed rapidly while keeping a very small number of stable connections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Social balanced&lt;/strong&gt;: most of the people have a balance social strategy in which the number of form/destroy interactions is proportional to their capacity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To show how these strategies look like, we have produce the following videos where you can see the tie dynamics around a social explorer and a social keeper (red nodes) for a period of 7 months. Note that if you aggregate the activity of these two people over those 7 months, the will have the same connectivity. But clearly their instantaneous network is very different!&lt;/p&gt;
&lt;p&gt;So, what do you think is your social strategy? Are you a social explorer or a social keeper?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Social explorer&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/63664066&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Social keeper&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/65257905&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note: these videos are produced using R and the igraph library. Learn how to make them in &lt;a href=&#34;http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/&#34;&gt;my post here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>La ciencia de la caballería andante</title>
      <link>http://estebanmoro.org/2013/04/la-ciencia-de-la-caballeria-andante/</link>
      <pubDate>Tue, 23 Apr 2013 07:15:28 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2013/04/la-ciencia-de-la-caballeria-andante/</guid>
      <description>&lt;p&gt;Happy World Book Day&lt;/p&gt;
&lt;blockquote&gt;La Caballería andante (...) es una ciencia, dijo Don Quijote (...) que encierra en sí todas o las más ciencias del mundo (...) el que la profesa ha de ser jurisperito, y saber las leyes de la justicia distributiva y conmutativa (...) ha de ser teólogo, para saber dar razón de la cristiana ley que profesa (...); ha de ser médico, principalmente herbolario, parara conocer (...) las yerbas que tienen virtud de sanar las heridas (...); ha de ser astrólogo, para conocer por las estrellas cuántas horas son pasadas la noche (...); **ha de saber las matemáticas, porque a cada paso se le ofrecerá tener necesidad de ellas (...).**
&lt;p&gt;Knight-errantry (&amp;hellip;) is a science, said Don Quixote (&amp;hellip;) that comprehends in itself all or most of the sciences of the world, for he who professes it must be a jurist, and must know the rules of justice, distributive and equitable (&amp;hellip;) he must be a theologian, so as to be able to give a clear and distinctive reason for the Christian faith he professes (&amp;hellip;); must be a physician, and above all a herbalist, so as (&amp;hellip;) to know the herbs that have the property of healing wounds (&amp;hellip;); he must be an astronomer, so as to know by the stars how many hours of the night have passed (&amp;hellip;) ** He must know mathematics for at every turn some occasion for them will present itself to him (&amp;hellip;) **&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Miguel de Cervantes Saavedra
El Ingenioso Hidalgo Don Quijote de La Mancha
Second part, Chapter XVIII, Madrid 1615&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>when does emulation count as explanation?</title>
      <link>http://estebanmoro.org/2013/03/when-does-emulation-count-as-explanation/</link>
      <pubDate>Mon, 25 Mar 2013 18:58:09 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2013/03/when-does-emulation-count-as-explanation/</guid>
      <description>&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;To me, the main question when modeling a process in the social sciences is &amp;quot;when does emulation count as explanation?&amp;quot;&lt;/p&gt;&amp;mdash; John Myles White (@johnmyleswhite) &lt;a href=&#34;https://twitter.com/johnmyleswhite/status/316256250327334913?ref_src=twsrc%5Etfw&#34;&gt;March 25, 2013&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;Interesting question. I guess the problem is that sometimes in science a model does not pretend to make any prediction, neither is supported by any relevant data. It simply emulates reality.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temporal networks with igraph and R (with 20 lines of code!)</title>
      <link>http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/</link>
      <pubDate>Sat, 10 Nov 2012 23:55:46 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/</guid>
      <description>&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;blockquote&gt;
**UPDATE**: the version of the R code in this post does not work with newer versions of the igraph package (\&gt; 1.0). I have posted an updated version of this post here: [Temporal networks with R and igraph (updated)](/post/2015-12-21-temporal-networks-with-r-and-igraph-updated/). Please visit the new post to use the new code and follow the discussion there.
&lt;/blockquote&gt;
&lt;p&gt;In my &lt;a href=&#34;http://estebanmoro.org/post/2012-10-29-temporal-network-of-information-diffusion-in-twitter/&#34;&gt;last post&lt;/a&gt; about how a twitter conversation unfolds in time on Twitter, the dynamical nature of information diffusion in twitter was illustrated with a video of the temporal network of interactions (RTs) between accounts. The temporal evolution of the network yields to another perspective of social structure and, in some cases, aggregating the data in a time window might blur out important temporal structures on information diffusion, community or opinion formation, etc. Although many of the commercial and free &lt;a href=&#34;http://en.wikipedia.org/wiki/Social_network_analysis_software&#34;&gt;Social Network Analysis software&lt;/a&gt; have tools to visualize static networks, there are no so many options out there for dynamical networks. And in some cases they have very limited options for their “dynamical layout”. A notable exception is &lt;a href=&#34;http://www.stanford.edu/group/sonia/documentation/install.html&#34;&gt;SoNIA&lt;/a&gt;, the Java-based package, which unfortunately is &lt;a href=&#34;http://sourceforge.net/projects/sonia/files/sonia/sonia_1_2_2_unstable/&#34;&gt;not updated frequently&lt;/a&gt;. Another possibility is to work with the &lt;a href=&#34;http://gephi.org/2011/gsoc-mid-term-a-new-timeline/&#34;&gt;Timeline plugin&lt;/a&gt; in Gephi. However there is no video recording possibility for the animations. In this post I will show you how to render the network at each time step and how to encode all snapshots into a video file using the &lt;a href=&#34;http://igraph.sourceforge.net&#34;&gt;igraph package&lt;/a&gt; in R and ffmpeg. The idea is very simple&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;generate a number of snapshots of the network at different times using R and igraph, and&lt;/li&gt;
&lt;li&gt;then put them together in a video file using ffmpeg.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For 1. we need to draw the temporal network at each snapshot. Given the set of nodes and edges present at a given time, we have to find a layout for that instantaneous graph. The layout is a two-dimensional visualization of the nodes and edges in the plane and there are &lt;a href=&#34;http://en.wikipedia.org/wiki/Graph_drawing&#34;&gt;many algorithms&lt;/a&gt; to produce it. The package igraph contains mainly &lt;a href=&#34;http://en.wikipedia.org/wiki/Force-based_algorithms_(graph_drawing)&#34;&gt;Force based algorithms&lt;/a&gt; like for example the Kamada-Kawai or Fruchterman-Reingold ones. Your millage may vary from one algorithm to another since visualizations depend on the number of nodes, clustering and/or community structure of the network. Sounds easy, but there two big problems with this approach:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Force based layout algorithms consist on performing a number of iterations aimed to minimize the energy of physical forces between nodes, and starting from an initial configuration which is typically a &lt;em&gt;random initial condition&lt;/em&gt;. This means that even if your network does not evolve in time, successive calls to the layout algorithm will produce different results. In our temporal network case it means that the layout from one snapshot to the next one will be very different producing a swarm-of-bees kind of motion. For example, if you run this script you will see that the four layouts are very different:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;library&lt;/span&gt;(igraph)
&lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt;(mfrow&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),mar&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), oma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;watts.strogatz.game&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
&lt;span style=&#34;color:#a6e22e&#34;&gt;for&lt;/span&gt;(i in &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;) &lt;span style=&#34;color:#a6e22e&#34;&gt;plot&lt;/span&gt;(g,layout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.fruchterman.reingold,margin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Luckily, in igraph 0.6 we can specify the initial position of the nodes for some layout functions: &lt;code&gt;layout.graphopt&lt;/code&gt;, &lt;code&gt;layout.kamada.kawai&lt;/code&gt; and &lt;code&gt;layout.fruchterman.reingold&lt;/code&gt;. My personal experience is that &lt;code&gt;layout.graphopt&lt;/code&gt; crashes in this 0.6 version (although it works on 0.5), so we are left with the other two algorithms. The plan (taken from &lt;a href=&#34;https://vimeo.com/14922587&#34;&gt;this original idea&lt;/a&gt; of Tamás Nepusz, one of the developers of igraph) is to use the layout of the previous snapshot as the initial condition for the next snapshot layout so we have a smooth transtion from one to the other. In the example above, the implementation will be the following using the &lt;code&gt;start&lt;/code&gt; parameter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;par&lt;/span&gt;(mfrow&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;),mar&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;), oma&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
g &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;watts.strogatz.game&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.4&lt;/span&gt;)
layout.old &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout.fruchterman.reingold&lt;/span&gt;(g)
&lt;span style=&#34;color:#a6e22e&#34;&gt;for&lt;/span&gt;(i in &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;){
  layout.new &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout.fruchterman.reingold&lt;/span&gt;(g,params&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;list&lt;/span&gt;(niter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,maxdelta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,start&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.old))
  &lt;span style=&#34;color:#a6e22e&#34;&gt;plot&lt;/span&gt;(g,layout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.new)
  layout.old &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layout.new
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/igraph_old4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now you can see that the layouts are similar. There are two new parameters passed to the layout function: &lt;code&gt;niter = 10&lt;/code&gt; specify the number of iterations (10) of the minimization of energy procedure in the force based algorithm. This number should be small, otherwise the final result will be very different from the initial condition. The same happens for the other parameter &lt;code&gt;maxdelta=2&lt;/code&gt; which controls the maximum change in the position of the nodes allowed in the minimization procedure.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The other problem is that in a temporal network nodes and/or edges appear and disappear dynamically. Thus the time dependent graph might have different number of nodes and/or edges from one snapshot to the next one. This means that the layout at a given snapshot cannot be used as the initial condition to generate next time layout, since the number of nodes can be different. My solution to this problem is to consider all (past/present/future) nodes/edges when calculating the layout but to display only present nodes/edges in the plot by making past and future nodes/edges transparent. This trick allows the reutilization of the layouts between steps, but it will produce a more or less steady visualization in which the layout at any given time is not related to the instantaneous structure of the temporal graph. To overcome this problem we take advantage of another property of force based algorithms: nodes which are connected attract each other along the edge. At a given instant, we could then modify the attraction between nodes along edges depending on whether the the edge is not present. In igraph 0.6, only the &lt;code&gt;layout.fruchterman.reingold&lt;/code&gt; has this possibility through the parameter &lt;code&gt;weights&lt;/code&gt;, a vector giving edge weights which are use to multiply the attraction along the edge. For example we could set weight equal to one if the edge is present and use zero weight for the rest. This will produce a layout in which present nodes are tightly connected while the past/future nodes are repelled from them. This effect dramatically highlights the appearance and disappearance of nodes, but could create too much confusion if there are many of those events.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To test this ideas, we will work an important example in the theory of complex networks: the preferential attachment mechanism to generate scale-free networks, i.e. the &lt;a href=&#34;http://en.wikipedia.org/wiki/BA_model&#34;&gt;Barabási-Albert model&lt;/a&gt;. In our implementation, we keep the mechanism very simple: starting from an initial core of nodes, at each time step we add a single node that connects to m existing nodes which are selected proportionally to the number of links that the existing nodes already have. This mechanism leads to heavily linked nodes (“hubs”) together with a large fraction of poorly connected nodes. A particular realization of this model can be found in the file &lt;a href=&#34;https://%20github.com/emoro/temporal_networks/blob/master/edges.csv&#34;&gt;edges.csv&lt;/a&gt; below. The structure of the file is simple&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   id1 id2 time
## 1   1   2    1
## 2   1   3    1
## 3   2   3    1
## 4   5   3    2
## 5   6   2    3
## 6   7   2    4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;each line of the form &lt;code&gt;id1 | id2 | time&lt;/code&gt; indicates that a link between id1 and id2 appears at a particular time. Depending on the context this might represent that the tie was activated at that particular instant (for example if it is a RT between two twitter accounts) or that it was the time in which the edge appeared first (like in our Barabási-Albert model). Here is the code to generate the snapshots and producing a PNG picture for each of them:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;library&lt;/span&gt;(igraph)

&lt;span style=&#34;color:#75715e&#34;&gt;#load the edges with time stamp&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#there are three columns in edges: id1,id2,time&lt;/span&gt;
edges &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read.table&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;edges.csv&amp;#34;&lt;/span&gt;,header&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;T)

&lt;span style=&#34;color:#75715e&#34;&gt;#generate the full graph&lt;/span&gt;
g &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;graph.edgelist&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;as.matrix&lt;/span&gt;(edges[,&lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)]),directed&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;F)
&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; edges[,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]

&lt;span style=&#34;color:#75715e&#34;&gt;#generate a cool palette for the graph&lt;/span&gt;
YlOrBr &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;c&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#FFFFD4&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#FED98E&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#FE9929&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#D95F0E&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#993404&amp;#34;&lt;/span&gt;)
YlOrBr.Lab &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;colorRampPalette&lt;/span&gt;(YlOrBr, space &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Lab&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;#colors for the nodes are chosen from the very beginning&lt;/span&gt;
vcolor &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;rev&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;YlOrBr.Lab&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;vcount&lt;/span&gt;(g)))

&lt;span style=&#34;color:#75715e&#34;&gt;#time in the edges goes from 1 to 300. We kick off at time 3&lt;/span&gt;
ti &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#weights of edges formed up to time ti is 1. Future edges are weighted 0&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ifelse&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; ti,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;#generate first layout using weights.&lt;/span&gt;
layout.old &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout.fruchterman.reingold&lt;/span&gt;(g,params&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;list&lt;/span&gt;(weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;weight))


&lt;span style=&#34;color:#75715e&#34;&gt;#total time of the dynamics&lt;/span&gt;
total_time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time)
&lt;span style=&#34;color:#75715e&#34;&gt;#This is the time interval for the animation. In this case is taken to be 1/10 &lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#of the time (i.e. 10 snapshots) between adding two consecutive nodes &lt;/span&gt;
dt &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;#Output for each frame will be a png with HD size 1600x900 :)&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;png&lt;/span&gt;(file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;example%03d.png&amp;#34;&lt;/span&gt;, width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1600&lt;/span&gt;,height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;900&lt;/span&gt;)
nsteps &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;max&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time)
&lt;span style=&#34;color:#75715e&#34;&gt;#Time loop starts&lt;/span&gt;
&lt;span style=&#34;color:#a6e22e&#34;&gt;for&lt;/span&gt;(ti in &lt;span style=&#34;color:#a6e22e&#34;&gt;seq&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,total_time,dt)){
  &lt;span style=&#34;color:#75715e&#34;&gt;#define weight for edges present up to time ti.&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;weight &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ifelse&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; ti,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) 
  &lt;span style=&#34;color:#75715e&#34;&gt;#Edges with non-zero weight are in gray. The rest are transparent&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ifelse&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;time &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; ti,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gray&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#a6e22e&#34;&gt;rgb&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))
  &lt;span style=&#34;color:#75715e&#34;&gt;#Nodes with at least a non-zero weighted edge are in color. The rest are transparent&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;V&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;color &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ifelse&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;graph.strength&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#a6e22e&#34;&gt;rgb&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;),vcolor)
  &lt;span style=&#34;color:#75715e&#34;&gt;#given the new weights, we update the layout a little bit&lt;/span&gt;
  layout.new &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;layout.fruchterman.reingold&lt;/span&gt;(g,params&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;list&lt;/span&gt;(niter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,start&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.old,weights&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;E&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;weight,maxdelta&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
  &lt;span style=&#34;color:#75715e&#34;&gt;#plot the new graph&lt;/span&gt;
  &lt;span style=&#34;color:#a6e22e&#34;&gt;plot&lt;/span&gt;(g,layout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layout.new,vertex.label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;,vertex.size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1+2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;log&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;graph.strength&lt;/span&gt;(g)),vertex.frame.color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;V&lt;/span&gt;(g)&lt;span style=&#34;color:#f92672&#34;&gt;$&lt;/span&gt;color,edge.width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.5&lt;/span&gt;,asp&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,margin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;-0.15&lt;/span&gt;)
  &lt;span style=&#34;color:#75715e&#34;&gt;#use the new layout in the next round&lt;/span&gt;
  layout.old &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;-&lt;/span&gt; layout.new 
}
&lt;span style=&#34;color:#a6e22e&#34;&gt;dev.off&lt;/span&gt;()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you can see the edges present before time &lt;code&gt;ti&lt;/code&gt; are colored in “gray” and weighted 1 while the rest are transparent &lt;code&gt;rgb(0,0,0,0)&lt;/code&gt; and weighted 0. For the nodes we have used the function &lt;code&gt;graph.strength&lt;/code&gt; that calculate the sum of weights of adjacent edges of a node: note that if at a given instant a node has no active adjacent edges, its graph strength is zero and thus the node is transparent. Otherwise it is colored as in the &lt;code&gt;vcolor&lt;/code&gt; vector. Final step is to encode this images into a video format. To that end I have used &lt;a href=&#34;http://ffmpeg.org&#34;&gt;ffmpeg&lt;/a&gt; which can be install in linux, windows or mac. The following command line in a terminal shell produces a video file &lt;code&gt;output.mp4&lt;/code&gt; in the mpeg format:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;ffmpeg &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;r &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;b &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;M &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;i example%&lt;span style=&#34;color:#ae81ff&#34;&gt;03&lt;/span&gt;d.png output.mp4`
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first &lt;code&gt;-r 10&lt;/code&gt; flag controls the rate of frames per second (fps), 10 in this case, while the &lt;code&gt;-b 20M&lt;/code&gt; sets the bitrate in the output (set to a large value here, 20M). The result is the following video&lt;/p&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/53071346&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;
&lt;/iframe&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/53071346&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Done with 20 lines in R! I’m sure you can beat me with some other R tricks and many ways to improve this visualization. I am eager to know your comments. Please!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Preferential attachment: be first</title>
      <link>http://estebanmoro.org/2012/11/preferential-attachment-be-first/</link>
      <pubDate>Fri, 09 Nov 2012 00:29:58 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2012/11/preferential-attachment-be-first/</guid>
      <description>&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Preferential_attachment&#34;&gt;Preferential attachment&lt;/a&gt; is a key process governing the dynamics of many economic, social and biological process. It is the “The rich get richer” mechanism by which a quantity is distributed among individuals according to how much they already have. It also happens in social networks and the ones that have more social connectivity (the “hubs”) receive more new connections than the poorly connected. In a &lt;a href=&#34;http://www.nd.edu/~networks/Publication%20Categories/03%20Journal%20Articles/Physics/EmergenceRandom_Science%20286,%20509-512%20(1999).pdf&#34;&gt;famous paper&lt;/a&gt;, Laszlo Barabási and Reka Albert encoded this mechanics in the so called &lt;a href=&#34;http://en.wikipedia.org/wiki/BA_model&#34;&gt;Barabasi-Albert model&lt;/a&gt; to generate random scale free-networks.&lt;/p&gt;
&lt;p&gt;The model is dynamical since new nodes and edges are created in time. Although the model is analytical tractable and many properties of the networks produced are known, I show you here a video illustrating the temporal network of the model (the details of how this video was done are in &lt;a href=&#34;http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/&#34;&gt;this other post&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/53071346&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In my implementation of the model a node is created at regular time intervals and it connects to a (random) number of existing nodes which are chosen randomly but proportionally to their number of existing links. Colors correspond to the “age” of the node in the simulation. Darker means older nodes. Size is log-proportional to the node’s connectivity. The result is a heterogeneous network in which some nodes (most of the times the initial nodes) are highly connected while the rest have a small connectivity.&lt;/p&gt;
&lt;p&gt;The video (and model) shows you that under this preferential attachment mechanism the real important thing is to be there first: darker/older nodes are more connected. That’s life experience, or as John Tuld says in the &lt;a href=&#34;http://www.imdb.com/title/tt1615147/quotes&#34;&gt;&lt;em&gt;Margin Call&lt;/em&gt;&lt;/a&gt; movie: “There are three ways to make a living in this business: be first, be smarter, or cheat.”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temporal network of information diffusion in Twitter</title>
      <link>http://estebanmoro.org/post/2012-10-29-temporal-network-of-information-diffusion-in-twitter/</link>
      <pubDate>Mon, 29 Oct 2012 21:58:29 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2012-10-29-temporal-network-of-information-diffusion-in-twitter/</guid>
      <description>&lt;link href=&#34;http://estebanmoro.org/rmarkdown-libs/vembedr/css/vembedr.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;p&gt;Millions of tweets, retweets and mentions are exchanged in Twitter everyday about very different subjects, events, opinions, etc. While aggregating this data over a time window might help to understand some properties of those processes in online social networks, the speed of information diffusion around particular time-bound events requires a temporal analysis of them. To show that (and with the help of the &lt;a href=&#34;http://www.iic.uam.es/en/solutions-and-services/text-a-opinion-mining&#34;&gt;Text &amp;amp; Opinion Mining Group&lt;/a&gt; at IIC) we collected all tweets (750k) of the vibrant conversation around the disputed subject of the &lt;a href=&#34;http://www.guardian.co.uk/business/2012/mar/29/spain-general-strike-rebellion-austerity&#34;&gt;general strike of March 29th&lt;/a&gt; in Spain. The data spans 10 days from 03/27 to 04/04 and using the RTs related to the general strike between twitter accounts we build up the following temporal network of information diffusion in Twitter.&lt;/p&gt;
&lt;div class=&#34;vembedr&#34;&gt;
&lt;div&gt;
&lt;iframe class=&#34;vimeo-embed&#34; src=&#34;https://player.vimeo.com/video/52390053&#34; width=&#34;800&#34; height=&#34;600&#34; frameborder=&#34;0&#34; webkitallowfullscreen=&#34;&#34; mozallowfullscreen=&#34;&#34; allowfullscreen=&#34;&#34; data-external=&#34;1&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Day/night human rhythms are clearly seen, and there is an increase of activity in the evening/night before March 29th, which ended in the burst of RTs during that day. Moreover, using &lt;a href=&#34;http://en.wikipedia.org/wiki/Community_structure&#34;&gt;community-finding algorithms&lt;/a&gt; over the static (weighted) network of RTs we could assign each twitter account to one of the communities found. Analyzing the text of tweets within those communities we found the nature of the biggest groups: one is in favor of the economic motivations behind the strike, the other is not. Those communities fight close to dominate information propagation in Twitter even some days after the strike.&lt;/p&gt;
&lt;p&gt;This video highlights the importance of &lt;a href=&#34;http://arxiv.org/abs/1108.1780&#34;&gt;temporal networks&lt;/a&gt; in the analysis of information diffusion in online social networks.&lt;/p&gt;
&lt;p&gt;Technical details: the video was done using the amazing &lt;a href=&#34;http://igraph.sourceforge.net&#34;&gt;igraph&lt;/a&gt; package in R and encoded using ffmpeg. Thanks to everyone that contributes to those open-source projects for their work.&lt;/p&gt;
&lt;p&gt;Edit (11/9/2012): I have post a tutorial on how to make this kind of visualizations &lt;a href=&#34;http://estebanmoro.org/post/2012-11-10-temporal-networks-with-igraph-and-r-with-20-lines-of-code/&#34;&gt;here&lt;/a&gt;. Spread the word!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Algorithms and Management</title>
      <link>http://estebanmoro.org/2012/10/algorithms-and-management/</link>
      <pubDate>Wed, 24 Oct 2012 08:30:29 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2012/10/algorithms-and-management/</guid>
      <description>&lt;p&gt;Yesterday I gave a talk in the &lt;a href=&#34;http://blog.iic.uam.es/2012/08/algorithms-management-algorithm-engineering-in-business/&#34;&gt;6th IIC Technology Conference &lt;/a&gt;about how Social Contagion can be leveraged for marketing purposes. The motto of the conference was about the need of using Algorithms in nowadays business process. With the availability of more and more complex data the use of algorithms that can detect and reduce complexity is of paramount importance. &lt;em&gt;Big data&lt;/em&gt; is not only about volume (TeraBytes of data), it is about &lt;strong&gt;huge complex data&lt;/strong&gt; and reducing that complexity can only be achieved by modeling, simulating and analyzing the patterns we observe in the data. There are no black-boxes for Big Data, and only insight and the right approach to tame complexity is proven useful.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/ingiic-150x150.jpg&#34; alt=&#34;&#34;&gt;
Fernando Cordova presents the &amp;ldquo;giant component&amp;rdquo; of internal communication network&lt;/p&gt;
&lt;p&gt;In this direction my colleagues at &lt;a href=&#34;http://www.iic.uam.es/en/&#34;&gt;IIC&lt;/a&gt; presented their incredible work, algorithmic solutions and projects with companies in the Energy, Health, Banking sectors. In particular, in our group at IIC &lt;a href=&#34;http://www.linkedin.com/pub/jose-luis-iribarren/0/401/368&#34;&gt;José Luis Iribarren&lt;/a&gt; presented our approach to discover organizational groups and hierarchies within companies and its impact in the business process within a company and Fernando Córdova from INGDirect (Spain) showed how we have help them to unveil groups of collaborations, early adopters, etc. within the Bank using our &lt;a href=&#34;http://www.iic.uam.es/en/solutions-and-services/organizational-management/aros&#34;&gt;AROS&lt;/a&gt; tool.&lt;/p&gt;
&lt;p&gt;On my side, I present a recent collaboration we have done with a major telecomm company to use their CRM and CDR data to build a adoption model for new products/services. The &lt;a href=&#34;http://www.iic.uam.es/en/solutions-and-services/information-diffusion/adoption-models&#34;&gt;eContagion model&lt;/a&gt; (based on our MAAIS methodology) was built using our recent research on temporal networks, community finding and machine learning algorithms and was able to improve (several times) the best predictions of models based only on CRM data.&lt;/p&gt;
&lt;p&gt;You can find the talks and presentations in video format &lt;a href=&#34;http://www.iic.uam.es/es/prensa-y-eventos/eventos/227-videos-ponencias-6-jornada-tecnologica-iic-2012&#34;&gt;here&lt;/a&gt;, and below is my lecture (sorry, in spanish)&lt;/p&gt;
&lt;iframe src=&#34;https://www.youtube.com/embed/7Z5ZjadRM1E?start=&#34;
  style=&#34;position: absolute; top: 0; left: 0; width: 560; height: 315;&#34; allowfullscreen frameborder=&#34;0&#34; title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;Comments are welcome! If you want to find more info about our work on social networks and business process, visit our group page at &lt;a href=&#34;http://www.iic.uam.es/en/&#34;&gt;IIC&lt;/a&gt; and our &lt;a href=&#34;http://blog.iic.uam.es/&#34;&gt;blog&lt;/a&gt; about innovation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It was a delicious assignment, infinitely complicated</title>
      <link>http://estebanmoro.org/2012/08/it-was-a-delicious-assignment-infinitely-complicated/</link>
      <pubDate>Fri, 31 Aug 2012 16:41:25 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2012/08/it-was-a-delicious-assignment-infinitely-complicated/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/en/2/26/Shibumi.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I have just read an amazing book &amp;ldquo;&lt;a href=&#34;http://en.wikipedia.org/wiki/Shibumi_(novel)&#34;&gt;Shibumi&lt;/a&gt;&amp;rdquo; by Trevanian (a.k.a. &lt;a href=&#34;http://en.wikipedia.org/wiki/Rodney_William_Whitaker&#34;&gt;Rodney William Whitaker&lt;/a&gt;)  probably the best spy novel I have read so far. In the book, a big data computer (called Fat Boy) is operated by a &amp;ldquo;data scientist&amp;rdquo; (although is not called that way). I enjoyed very much the following paragraph, an analogy of the emptiness of big data without insight and also a musing about how difficult is to find relationships from activity data (the kind of research we do!)&lt;/p&gt;
&lt;blockquote&gt;“Order the list emotionally. Go for indices indicating love, friendship, trust—this sort of thing. Go from closest to most distant.”
&lt;p&gt;The First Assistant&amp;rsquo;s eyes shone as he took a deep breath and lightly rubbed his fingers together. This was a fine challenge demanding console virtuosity. Love, friendship, trust—these imprecisions and shadows could not be located through approaches resembling the Schliemann Back-bit and Non-bit Theory. No computer, not even Fat Boy, can respond to such rubrics directly. Questions have to be phrased in terms of nonfrequency counts and non sequitur exchange relationships. In its simplest form, actions performed for no measurable reason, or contrary to linear logic, might indicate such underlying motives as love or friendship or trust. But great care had to be exercised, because identical actions could derive from hate, insanity, or blackmail. Moreover, in the case of love, the nature of the action seldom helps to identify its motivational impulse. Particularly difficult is separating love from blackmail.&lt;/p&gt;
&lt;p&gt;It was a delicious assignment, infinitely complicated. As he began to insert the first probes into Fat Boy, the First Assistant&amp;rsquo;s shoulders twisted back and forth, as though he were guiding a pinball with body-english.&lt;/blockquote&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Which chart to use</title>
      <link>http://estebanmoro.org/2012/08/which-chart-to-use/</link>
      <pubDate>Thu, 02 Aug 2012 10:12:11 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2012/08/which-chart-to-use/</guid>
      <description>&lt;p&gt;In most of my talks I present quantitative evidence of patterns, data exploration or results. But which is the right way to show that evidence? Worry no more: the &lt;a href=&#34;http://www.extremepresentation.com/&#34;&gt;Extreme Presentation Method&lt;/a&gt; helps you to decide with this chart chooser (click &lt;a href=&#34;http://www.extremepresentation.com/uploads/documents/choosing_a_good_chart.pdf&#34;&gt;here&lt;/a&gt; to download the pdf)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://estebanmoro.org/wp-content/uploads/2012/08/choosing_a_good_chart-1.jpg&#34;&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/choosing-a-good-chart-1.jpg&#34; alt=&#34;&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My impression is that this chart chooser is good for small data. For big data some of the charts render useless. For example, read the insightfull post &lt;a href=&#34;http://www.chrisstucchio.com/blog/2012/dont_use_scatterplots.html&#34;&gt;Don&amp;rsquo;t use Scatterplots&lt;/a&gt; by Chris Stucchio on why is not a good idea to use scatterplots to show relationship between bivariate data when you have large amounts of data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Complex Dynamics of Human Interactions, September 14th 2011</title>
      <link>http://estebanmoro.org/2011/03/complex-dynamics-of-human-interactions-september-14th-2011/</link>
      <pubDate>Mon, 28 Mar 2011 14:51:50 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2011/03/complex-dynamics-of-human-interactions-september-14th-2011/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2011/03/cdhi11-150x150.jpg&#34; alt=&#34;cdhi11&#34;&gt;
We (together with Kimmo Kaski, Aalto University) are organizing the &lt;a href=&#34;http://www.eccs2011.eu/&#34;&gt;ECCS&#39;11&lt;/a&gt; Satellite conference &lt;strong&gt;&amp;ldquo;Complex Dynamics of Human Interactions&amp;rdquo;&lt;/strong&gt; to be held at Vienna, September 14th.&lt;/p&gt;
&lt;p&gt;You can find more info at &lt;a href=&#34;http://www.complexdynamics.org&#34;&gt;http://www.complexdynamics.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;It&amp;rsquo;s not enough to have a map of the structure. It is crucial to understand the dynamics of a process”&lt;/em&gt;, L. Barábasi&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scope&lt;/strong&gt;
The nature of human interaction has undergone a substantial change in the past years and the change does not seem to be over. Technologies like email, smart-phones, social networks like Facebook or broadcast technologies like Twitter transform the way people keep in touch and new trends of communication appear: individuals are continuously connected with each other, social activities are commonly shared by groups of people and people do not need to be geographically close to stay connected.&lt;/p&gt;
&lt;p&gt;The high availability of digital data about human activity given by these communication channels and their high detail has provided unprecedented understanding of the nature of humans interactions, that affect the very definition of social relationships, hubs, communities and their role on society. Particular important is the role that human dynamics has in processes that happen concurrently with the dynamics of interaction, like information/disease epidemics in social networks, opinion dynamics, coordination, etc.&lt;/p&gt;
&lt;p&gt;The aim of this meeting is to explore the dynamical structure of social and communication networks and the role of the human complex dynamics in realistic processes like information spreading, personal recommendation or &amp;ldquo;word-of-mouth&amp;rdquo;, etc.&lt;/p&gt;
&lt;p&gt;Specific topics of interest are (but not only):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * High Frequency analysis of communication and social networks
  * Causality and correlation in human communication patterns
  * Reality Mining, Face-to-Face interactions
  * Modeling dynamics of human interactions
  * Applications to viral marketing, infection spreading, opinion dynamics.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Relationship mining</title>
      <link>http://estebanmoro.org/2010/01/relationship-mining/</link>
      <pubDate>Mon, 11 Jan 2010 09:16:09 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2010/01/relationship-mining/</guid>
      <description>&lt;p&gt;Each day trillions of emails, phone calls, comments on blogs, twitter messages, exchanges in online social networks, etc. are done. Not only the number of communications has increased, but also each of these transactions leaves a digital trace that can be recorded to reconstruct our high-frequency human activity. It is not only the amount and variety of data that is recorded what is important. Also its high-frequency character and its comprehensive nature have allowed researchers, companies and agencies to investigate individual and group dynamics at an unprecedented level of detail and applied them to client modeling, organizational analysis or epidemic spreading [1].&lt;/p&gt;
&lt;p&gt;However, for technical or privacy reasons only the existence but not of the content of those exchanges is known. Thus we can quantify the intensity and frequency of the interaction but not its type. For decades, social science has measured relationships between individuals in the currency of tie strength, introduced by Granovetter [1]. Weak ties (loose acquaintances) can help to disseminate ideas and/or innovations between different groups, help to find a job or new information; while strong ties (family, trusted friends) hold together organizations and social groups and can affect emotional health. Despite its success to explain these phenomena, tie strength of human relationships is vaguely defined in most large-scale social empirical work. Specifically, relationships are generally quantified by the intensity or duration of communication, although they are known to have significant drawbacks as tie strength predictor [3,4]. Multiplexity, rhythm and depth of the communication seem to be better predictors of tie strength than intensity [4]. Incorporating those metrics in the data mining of online communication might improve the definition of relationships between individuals and in turn transform our understanding of individual dynamics and its impact in our lives, organizations and society [5]. The challenge is to unveil social relationships in social media and not just mere interactions between individuals, which in general over-represent the real structure of a social group [6] (see figure). And this is of paramount importance to understand the propagation of ideas, opinions, commercial messages, etc. in social networks, since most links declared in social networks might be meaningless from a relationship point of view.&lt;/p&gt;
&lt;p&gt;[caption id=&amp;ldquo;attachment_441&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;500&amp;rdquo; caption=&amp;ldquo;Undressing the social network: considering all e-mail interactions in a academic social network (left) yields to a highly dense and connected social network, while strong interactions (based on the individual relative frequency of communication) render the social group sparser and disconnected&amp;rdquo;]&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2010/01/undressing1.jpg&#34; alt=&#34;undressing1&#34;&gt;
[/caption]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  1. D. Lazer et al. _Computational Social Science_, Science **323**, 721 (2009)
  2. M. S. Granovetter, _The Strength of Weak Ties_, The American Journal of Sociology **78(6)**, 1360 (1973)
  3. P. V. Marsden, and K. E. Campbell _Measuring Tie Strength_ Social Forces **63(2)**, 482 (1990).
  4. E. Gilbert and K. Karahalios, _Predicting Tie Strength with Social Media_, presented in CHI 2009.
  5. C. T. Butts, _Revisting the Foundations of Network Analysis_, Science **325**, 414 (2009)
  6. B. A. Huberman, D. M. Romero, and F. Wu, _Social networks that matter_, First Monday **14(1)** (2009).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: This article appears in the Catalog of the exhibition &amp;ldquo;Culturas del Cambio: Átomos Sociales y Vidas Electrónicas&amp;rdquo; in the Center _&lt;a href=&#34;http://www.artssantamonica.cat/&#34;&gt;Arts Santa Mónica&lt;/a&gt;. _Thanks to  &lt;a href=&#34;http://www.ffn.ub.es/perello/&#34;&gt;Josep Perelló&lt;/a&gt; for his kind invitation to contribute&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>La ciencia española no necesita tijeras</title>
      <link>http://estebanmoro.org/2009/10/la-ciencia-espanola-no-necesita-tijeras/</link>
      <pubDate>Wed, 07 Oct 2009 06:00:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/10/la-ciencia-espanola-no-necesita-tijeras/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2009/10/3973473121_e76fde787c_o-300x300.jpg&#34; alt=&#34;3973473121_e76fde787c_o&#34;&gt;&lt;/p&gt;
&lt;p&gt;La crisis y su efecto en los presupuestos del año 2010 han servido para poner a prueba el compromiso del gobierno de cambiar de modelo productivo y aumentar el gasto en I+D+i. En especial, sufren recortes los gastos del ministerio de Ciencia e Innovación (hasta un 17%), el capítulo 7 (las subvenciones a investigadores) &lt;a href=&#34;http://www.elpais.com/articulo/sociedad/ciencia/victima/presupuesto/elpepusoc/20091004elpepisoc_3/Tes&#34;&gt;un 17%&lt;/a&gt; y los presupuestos de algunos OPIs dependientes del Ministerio con un &lt;a href=&#34;http://www.lavanguardia.es/ciudadanos/noticias/20090930/53794421041/preocupacion-entre-los-cientificos-ante-el-proyecto-de-presupuestos-del-estado-para-el-2010-idi-csic.html&#34;&gt;15% menos de media&lt;/a&gt;. La situación es tal que hasta los propios ministros del gobierno creen que la situación, de continuar, es cuando &lt;a href=&#34;http://www.elpais.com/articulo/sociedad/Gabilondo/cree/inquietantes/recortes/Ciencia/elpepusoc/20091001elpepusoc_11/Tes&#34;&gt;menos preocupante&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Pero la ciencia no necesita estas tijeras presupuestarias. La principal razón es que la ciencia en este país y en general el I+D+i es un tejido que todavía no está maduro. Llevamos creciendo a buen ritmo en los últimos años y no lo estamos haciendo mal, pero la inversión y los planes en ciencia deben de hacerse a largo plazo, en especial en la contratación de personas. Los que llevamos algún tiempo en esto sabemos que el dinero disponible no siempre es el mismo y podemos ajustarnos el cinturón como antes lo habremos hecho muchos de nosotros, pero como &lt;a href=&#34;http://www.elpais.com/articulo/sociedad/jovenes/cientificos/sufriran/elpepisoc/20091004elpepisoc_4/Tes&#34;&gt;dice Margarita Salas&lt;/a&gt;, quienes van a sufrir más este recorte de prespuesto es la gente joven. En definitiva, el futuro de la I+D+i. La gente que tiene que llegar y superarnos y hacerlo mucho mejor que nosotros. Si ya costaba convencer a alguien de que hiciera ciencia en este país, ¿cómo vamos a hacerlo ahora cuando leen en los periódicos que no hay dinero?&lt;/p&gt;
&lt;p&gt;Finalmente si el Gobierno y los partidos políticos han estado de acuerdo en hacer un Plan E de miles de millones de euros que nos ha llenado de bonitos carteles nuestra geografía y han mejorado tanto las rotondas de este país, ¿cómo es posible que no se pueda llegar a un acuerdo para crear un Plan I que garantize el crecimiento en I+D+i para llegar a los niveles europeos?&lt;/p&gt;
&lt;p&gt;Esta es mi contribución a la iniciativa &amp;ldquo;La Ciencia Española NO Necesita Tijeras&amp;rdquo;, promovida por &lt;a href=&#34;http://aldea-irreductible.blogspot.com/&#34;&gt;La Aldea Irreductible&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The speed and reach of forwarded emails, rumors, and hoaxes in electronic social networks</title>
      <link>http://estebanmoro.org/2009/08/the-speed-and-reach-of-forwarded-emails-rumors-and-hoaxes-in-electronic-social-networks/</link>
      <pubDate>Tue, 04 Aug 2009 11:23:36 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/08/the-speed-and-reach-of-forwarded-emails-rumors-and-hoaxes-in-electronic-social-networks/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2009/08/large_spain_5-300x300.png&#34; alt=&#34;large_spain_5&#34;&gt;
We have just published an &lt;a href=&#34;http://estebanmoro.org/2009/08/impact-of-human-activity-patterns-on-the-dynamics-of-information-diffusion/&#34;&gt;experimental/theoretical work&lt;/a&gt; on the speed of information diffusion in social networks in Physical Review Letters. Specifically we have studied the impact of the heterogeneity of human activity in propagation of emails, rumors, hoaxes, etc. Tracking email marketing campaigns, executed by IBM Corporation in 11 European countries, we were able to compare their viral propagation with our theory (see below the campaigns details).&lt;/p&gt;
&lt;p&gt;The results are very simple. Let me give you an example: the typical time between two emails sent by the same person is around 1 day. Traditional models of information diffusion will then yield to an infection speed of 1 day. However, some email computer viruses spread widely in a matter of hours (minutes, sometimes), while some viral propagation (for example the &lt;a href=&#34;http://www.nytimes.com/2001/06/25/technology/25HOAX.html&#34;&gt;Veuve-Clicquot hoax&lt;/a&gt;) last for years. How can that occur? The reason is that traditional models are not correct because they neglect the large heterogeneity in the frequency of human activity: the average time between emails (1 day) does not actually represent the collectivity. In fact, most of us respond very quickly to emails, but some take a lot of time to do it. This fact (known and discovered previously by others) has a profound consequence in the way information spreads:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  1. When information spreads &amp;quot;successfully&amp;quot;, in the sense that it propagates and reaches most of the collectivity (i.e. it surpasses the [tipping-point](http://en.wikipedia.org/wiki/The_Tipping_Point)), its propagation speed of is determined by the people that have higher activity.
  2. However, when information reaches just a small fraction of the population (below the tipping-point), its propagation is controlled by those who take a lot of time to respond/forward and the spreading is very slow.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This phenomenon, as explained in our paper, has consequences for viral marketing, fads and hoaxes diffusion or opinion dynamics because the speed of their messages propagation depends strongly on the size of the sub-communities of very active and not-so active people. For example, in our campaigns (which were below the tipping-point yet successful from a viral marketing perspective), endogenous propagation of the commercial message lasted for months while the average time between getting the message and forwarding was only 1 day. We also found that messages do not “go viral”: They are viral because of the diffusion mechanism they use, but their spreading success largely depends on the social network propensity and heterogeneous behavior.&lt;/p&gt;
&lt;p&gt;Finally, our work has some consequences for the way we model and understand human dynamics, since it shows that there is no such a thing as a typical time scale in the human dynamics. This is in sharp contrast with epidemic models, information diffusion models, etc. in which the heterogeneity in human activity and frequency is usually neglected, in favor of a more homogeneous picture of the activity of humans.&lt;/p&gt;
&lt;p&gt;About the empirical data: The viral marketing campaigns were conducted by IBM using the typical &amp;ldquo;refer-a-friend&amp;rdquo; mechanism which led to the endogenous diffusion of information. The campaigns’ offerings were promoted at the IBM. homepage where initial participants heard about them. Their primary marketing objective was to generate subscriptions to the company’s on-line newsletter. Subscriptions were entered through a form located in the campaign main web page (a.k.a. registration page). Additionally, a viral propagation mechanism accessible through a button located at the registration page was available to foster the message propagation. The button caption enticed visitors to recommend the page to friends and colleagues by offering, as additional incentive for people to forward the page, tickets for a prize draw to win a laptop computer. More technical details about the campaign can be found at Appendix D of the &lt;a href=&#34;http://arxiv.org/abs/0706.0641&#34;&gt;arXiv version &lt;/a&gt;of our paper&lt;/p&gt;
&lt;h3 id=&#34;press-coverage&#34;&gt;Press coverage:&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;* [&#39;Infectious&#39; people spread memes across the web](http://www.newscientist.com/article/dn17581-infectious-people-spread-memes-across-the-web.html), New Scientist (12/08/09)
* [Email hoaxes are like viruses](http://www.theinquirer.net/inquirer/news/1528754/email-hoaxes-viruses), The Inquirer (10/08/09)
* [The flow of viral video](http://abcnews.go.com/Technology/story?id=8278247&amp;amp;page=1), ABC News (8/08/09)
* [New model for social marketing campaigns details why some information &#39;goes viral&#39;](http://www.physorg.com/news168775247.html), PhysOrg (6/08/09)
* [Los perezosos frenan los rumores en Internet](http://www.abc.es/20090814/medios-redes-web/informacion-adictos-internet-200908131611.html), ABC.es (14/8/09)
* [Party people spread viral internet memes](http://www.computerweekly.com/Articles/2009/08/14/237327/party-people-spread-viral-internet-memes.htm), ComputerWeekly (14/8/09)
* [Desvelan las claves de la difusión de la información en las redes sociales](http://www.plataformasinc.es/index.php/esl/Noticias/Desvelan-las-claves-de-la-difusion-de-la-informacion-en-las-redes-sociales), PlataformaSINC.es (7/9/09)
* [Nuevas claves para la difusión de información en las redes sociales](http://www.madrimasd.org/informacionidi/noticias/noticia.asp?id=40574&amp;amp;tipo=g), Noticias Madri+d (7/9/09)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Giving a talk</title>
      <link>http://estebanmoro.org/2009/07/giving-a-talk/</link>
      <pubDate>Fri, 24 Jul 2009 09:06:46 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/07/giving-a-talk/</guid>
      <description>&lt;p&gt;Giving a good talk is not an easy task, but with time and practice you get to learn how to communicate (hopefully I&amp;rsquo;ve learned too!!). There are a number of places on the web with advices to give a good talk. But I like Paul N. Edwards&amp;rsquo;s &lt;a href=&#34;http://www.si.umich.edu/~pne/PDF/howtotalk.pdf&#34;&gt;short manual&lt;/a&gt; about how to give an academic talk. My experience as audience in many talks tell me that the most important things are (quoting Paul&amp;rsquo;s manual):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Presentation are not journal articles. Think of a talk as a series of 5 minutes presentations (one per transparency) with a general guideline.&lt;/li&gt;
&lt;li&gt;Each transparency is an idea unit. And the title of the transparency must be the summary of the idea&lt;/li&gt;
&lt;li&gt;Move, don&amp;rsquo;t stand still.&lt;/li&gt;
&lt;li&gt;Make eye contact, specially in the introduction, the key point of your talk and in the end of the talk.&lt;/li&gt;
&lt;li&gt;Focus on main points, skip technical details unless you are asked to give them.&lt;/li&gt;
&lt;li&gt;Do not put a lot of graphs per transparency. A graph is a lot of cryptic information for the audience and you must fully explain it, so more than a graph per transparency is too much for the audience.&lt;/li&gt;
&lt;li&gt;Do not write in the transparency what you are going to say. Transparencies are not to be read, but to complement your speak.&lt;/li&gt;
&lt;li&gt;Plan for disaster: have your presentation in different formats and in a usb thumb drive, a CD-ROM just in case.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Ph.D. offer... interested?</title>
      <link>http://estebanmoro.org/2009/06/phd-offer/</link>
      <pubDate>Fri, 05 Jun 2009 10:06:04 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/06/phd-offer/</guid>
      <description>&lt;p&gt;Our research group is looking for Ph.D. candidates. Here is the announcement&lt;/p&gt;
&lt;blockquote&gt;![mosaico](http://estebanmoro.org/wp-content/uploads/2009/06/mosaico.jpg)
We offer contracts to work for a Ph.D. within the project MOSAICO (Modelling, Analysis and Simulations of Complex Systems). Candidates must have a degree in physics, math or related disciplines with outstanding marks. Info on the research lines is available from [http://www.gisc.es](http://www.gisc.es) and work will be carried out at Universities Complutense or Carlos III de Madrid. Work will begin on October 1st, 2009.
Interested candidates must send a CV indicating expliciting their marks to [contratos.mosaico.2009@gmail.com](mailto:contratos.mosaico.2009@gmail.com) before July 15, 2009.&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>The probability of going through a bad patch</title>
      <link>http://estebanmoro.org/2009/04/the-probability-of-going-through-a-bad-patch/</link>
      <pubDate>Tue, 14 Apr 2009 11:37:02 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/04/the-probability-of-going-through-a-bad-patch/</guid>
      <description>&lt;p&gt;We&amp;rsquo;ve heard it: people that invest on the stock market or that gamble in lotteries, casinos, etc usually say &amp;ldquo;I&amp;rsquo;m going through a bad patch&amp;rdquo; (or bad spell). That is, they have been losing money for a while, but hey! better times are ahead and there&amp;rsquo;s no reason to quit. Are they sure? Are better times ahead? How close is &amp;ldquo;ahead&amp;rdquo; to today? Let&amp;rsquo;s work through a specific example to see how far is &amp;ldquo;ahead&amp;rdquo;. Suppose we play a fair game: we toss a coin and with probability 1/2 we get $1 (heads) and with probability 1/2 we lose $1 (tails). We play the game &lt;code&gt;\(n\)&lt;/code&gt; times and compute our capital &lt;code&gt;\(C(n)\)&lt;/code&gt; up to time &lt;code&gt;\(n\)&lt;/code&gt;. If our initial capital is zero, then we expect that our capital fluctuate around zero as the coin-tossing game goes on. Sometimes we will be in the &amp;ldquo;winning area&amp;rdquo;, where our capital is positive &lt;code&gt;\(C(n)\)&lt;/code&gt; &amp;gt; 0. However, we can also be in the &amp;ldquo;losing area&amp;rdquo; in which our capital is negative &lt;code&gt;\(C(n)\)&lt;/code&gt; &amp;lt; 0. If we are going through a bad patch (being in the losing area) we expect that waiting long enough we will recover and come back to the winning area.&lt;/p&gt;
&lt;p&gt;But this is incorrect. Let me show you why: let&amp;rsquo;s use some mathematics. Suppose that &lt;code&gt;\(x_i\)&lt;/code&gt; is the gain (+$1) or lose (-$1) in toss &lt;code&gt;\(i\)&lt;/code&gt; of the coin. Since our coin is fair, then &lt;code&gt;\(x_i\)&lt;/code&gt; is a random number which takes +1 or -1 with equal probability (1/2). Thus the capital up to time &lt;code&gt;\(n\)&lt;/code&gt; is the sum of those random numbers&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$C(n) = \sum_{i=1}^n x_i$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(C(n)\)&lt;/code&gt; is then the sum of &lt;code&gt;\(n\)&lt;/code&gt; equally distributed random numbers. In other contexts, &lt;code&gt;\(C(n)\)&lt;/code&gt; is also know as a &lt;a href=&#34;http://en.wikipedia.org/wiki/Random_walk&#34;&gt;random walk&lt;/a&gt;. We can apply the &lt;a href=&#34;http://en.wikipedia.org/wiki/Law_of_large_numbers&#34;&gt;law of large numbers&lt;/a&gt; and the &lt;a href=&#34;http://en.wikipedia.org/wiki/Central_limit_theorem&#34;&gt;central limit theorem&lt;/a&gt; to know something about &lt;code&gt;\(C(n)\)&lt;/code&gt;. For example, the expected value of &lt;code&gt;\(C(n)\)&lt;/code&gt; is&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\mathbb{E}[C(n)] = 0$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;as expected, since it is a fair game. Thus we have equal probability of being winning or losing at time &lt;code&gt;\(n\)&lt;/code&gt;. However, &lt;code&gt;\(C(n)\)&lt;/code&gt; fluctuates wildly around zero and in fact&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$Var[C(n)] = n$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Thus our capital at time &lt;code&gt;\(n\)&lt;/code&gt; is mostly in an interval of area &lt;code&gt;\(\sqrt{n}\)&lt;/code&gt; around zero, as shown in the next graph.&lt;/p&gt;
&lt;center&gt;
![](/img/posts/cn.jpg)&lt;/center&gt;
&lt;p&gt;The graphs shows 4 realizations of the game (colors) and the lines are the &lt;code&gt;\(\sqrt{n}\)&lt;/code&gt; areas in which our capital is mostly expected. As we can see in the &amp;ldquo;red&amp;rdquo; game, we starting losing money, but after a while we recover and went back to the &amp;ldquo;winning area&amp;rdquo;. Now the question is: what is the probability that we are in the winning area? Specifically, what is the probability &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; that we are in the winning area ($C(n)$ &amp;gt; 0) for a fraction &lt;code&gt;\(\alpha\)&lt;/code&gt; of the total &lt;code&gt;\(n\)&lt;/code&gt; turns? The naive reasoning in the introduction will tell us that since &lt;code&gt;\(C(n)\)&lt;/code&gt; is fluctuating around zero we expect that the probability will be peaked and 1/2 and thus half of the time we will be in a bad patch and half of the time we will be going through a good spell. Thus, if we are going through a bad patch, we have only to wait to come back to black numbers. However, this is not true. The probability &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; can be &lt;a href=&#34;http://math.berkeley.edu/~chr/teach/Lec14_2006.pdf&#34;&gt;worked out&lt;/a&gt; (although not trivially) to get&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$P(\alpha) = \frac{1}{\pi\sqrt{\alpha(1-\alpha)}}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/pdfa.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the limit &lt;code&gt;\(n\to \infty\)&lt;/code&gt;, which is known as the&lt;a href=&#34;http://www.math.unl.edu/~sdunbar1/Teaching/MathematicalFinance/Lessons/CoinTossing/ExcessHeads/excessheads.shtml&#34;&gt; arc-sine law&lt;/a&gt; (since the cumulative distribution of &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; is the arc-sin function). As the plot in the right shows the probability is peaked at 1 and 0 (actually, it diverges there!). Thus, for most of the realizations of the game we are most of the time in the winning area or in the losing area. This means that our naive reasoning above does not work: if you expect to recover from a bad patch, your chances are very small. This is obvious if we look at the colored figure above: the orange and black trajectories do not change from one winning/losing area to the other and, apart from the initial steps of the game, they remain in the winning/losing areas forever. The explanation for this behavior is that the &lt;a href=&#34;http://lib.stat.cmu.edu/~genovese/class/iprob-S06/notes/lec5-calcs.pdf&#34;&gt;first return time&lt;/a&gt; of &lt;code&gt;\(C(n)\)&lt;/code&gt; to zero is oftenly large. Actually, its expected time is infinite, which means that once you get into the positive/negative area you remain (mostly) there.&lt;/p&gt;
&lt;p&gt;Note however, that there is no paradox in what we have found and the fact that &lt;code&gt;\(\mathbb{E}[C(n)] = 0\)&lt;/code&gt;, since &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; is symmetric around &lt;code&gt;\(\alpha = 1/2\)&lt;/code&gt; and thus if we play the game a large number of times, on average, we have the same chances of winning and losing. But not for an individual game in which mostly we will be in a bad or good patch forever.&lt;/p&gt;
&lt;p&gt;What is the moral? Simple: if you get into a bad patch, leave the game. Because chances to recover from a bad patch are small.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Being part of &#34;best of 2008&#34;</title>
      <link>http://estebanmoro.org/2009/03/being-part-of-best-of-2008/</link>
      <pubDate>Mon, 30 Mar 2009 06:46:26 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/03/being-part-of-best-of-2008/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2009/03/njpbest2008-300x211.jpg&#34; alt=&#34;njpbest2008&#34;&gt;
I got wonderful news today. Our paper &amp;ldquo;Specialization and herding behavior of trading firms in a financial market&amp;rdquo; (&lt;a href=&#34;http://estebanmoro.org/2007/07/specialization-of-strategies-and-herding-behavior-of-trading-firms-in-a-financial-market/&#34;&gt;pdf&lt;/a&gt;) has been selected by the Editorial Board of New Journal of Physics as part of the Journal&amp;rsquo;s &lt;a href=&#34;http://www.iop.org/EJ/journal/-page=extra.bestof2008/1367-2630&#34;&gt;Best of 2008&lt;/a&gt;. According to their site, &amp;ldquo;Best of 2008&amp;rdquo; is a compilation of articles selected by the Editorial Board and staff team on the basis of criteria including referee endorsements, readership and citation levels and simple broad appeal. All articles are permanently free to read.&lt;/p&gt;
&lt;p&gt;Thanks to NJP for this boost and congrats to their editorial board and staff for their work. Hope to make it to 2009 too.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The use of statistics</title>
      <link>http://estebanmoro.org/2009/02/the-use-of-statistics/</link>
      <pubDate>Tue, 24 Feb 2009 08:58:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/02/the-use-of-statistics/</guid>
      <description>&lt;blockquote&gt;Mark Twain (1924) probably had politicians in mind when he reiterated Disraeli’s famous remark (&#34;There are three kinds of lies: lies, damned lies and statistics&#34;). Scientists, we hope, would never use data in such a selective manner to suit their own ends. But, alas, the analysis of data is often the source of some exasperation even in an academic context. On hearing comments like ‘the result of this experiment was inconclusive, so we had to use statistics’, we are frequently left wondering as to what strange tricks have been played on the data.&lt;/blockquote&gt;
&lt;p&gt;D. S. Sivia in &lt;em&gt;&lt;a href=&#34;http://www.amazon.com/Data-Analysis-Bayesian-Tutorial-Publications/dp/0198518897&#34;&gt;Data Analysis: A bayesian Tutorial&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Itô calculus for the rest of us</title>
      <link>http://estebanmoro.org/post/2009-02-12-ito-calculus-for-the-rest-of-us/</link>
      <pubDate>Thu, 12 Feb 2009 08:21:42 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2009-02-12-ito-calculus-for-the-rest-of-us/</guid>
      <description>&lt;p&gt;One of the areas of my research is stochastic differential equations (SDE). I posted about it &lt;a href=&#34;http://estebanmoro.org/2008/12/introduction-to-stochastic-differential-equations/&#34;&gt;several&lt;/a&gt; &lt;a href=&#34;http://estebanmoro.org/2008/11/kiyoshi-ito-93-dies/&#34;&gt;times&lt;/a&gt; &lt;a href=&#34;http://estebanmoro.org/2006/03/writing-bad-letters-of-recommendation-the-story-of-bachelier-and-levy/&#34;&gt;before&lt;/a&gt;. One of the things students and collaborators keep asking me about SDEs is the weird stochastic &lt;a href=&#34;http://en.wikipedia.org/wiki/Ito_stochastic_calculus&#34;&gt;Itô Calculus&lt;/a&gt;. Itô Calculus is different from what you learn in 101 calculus. In particular, the chain rule is not longer valid. Let me explain it with an example. Suppose you have the following equation&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$dX = a dW(t)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;\(W(t)\)&lt;/code&gt; is the Wiener stochastic process: it is a process in which &lt;code&gt;\(W(0) = 0\)&lt;/code&gt; and with Gaussian independent increments &lt;code&gt;\(W(t)-W(s) \sim {\cal N}(0,t-s)\)&lt;/code&gt;, where &lt;code&gt;\({\cal N}(\mu,\sigma^2)\)&lt;/code&gt; are Gaussian random numbers with mean &lt;code&gt;\(\mu\)&lt;/code&gt; and variance &lt;code&gt;\(\sigma^2\)&lt;/code&gt;. This equation is the simplest SDE and its solution is (obviously),&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$X(t) = a W(t)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;But there is a different way to look at SDEs. Since they describe the trayectory of &lt;code&gt;\(X(t)\)&lt;/code&gt; subject to &lt;code&gt;\(W(t)\)&lt;/code&gt; we can instead ask ourselves what is the probability to find that &lt;code&gt;\(X(t) = x\)&lt;/code&gt; in average, i.e. after many different runs of &lt;code&gt;\(W(t)\)&lt;/code&gt;. Let&amp;rsquo;s call &lt;code&gt;\(P(x,t)\)&lt;/code&gt;that probability which is known to satisfy the &lt;a href=&#34;http://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation&#34;&gt;Fokker-Planck equation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\frac{dP}{dt}=a\frac{d^2P}{dx^2}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which is the simple diffusion equation. The following figure shows the relationship between &lt;code&gt;\(X(t)\)&lt;/code&gt; and &lt;code&gt;\(P(x,t)\)&lt;/code&gt;. While &lt;code&gt;\(X(t)\)&lt;/code&gt; is a simple trayectory (for a given &lt;code&gt;\(W(t)\)&lt;/code&gt; realization), &lt;code&gt;\(P(x,t)\)&lt;/code&gt; is the probability to find &lt;code&gt;\(X(t) = x\)&lt;/code&gt; over all possible realizations of &lt;code&gt;\(W(t)\)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/pdf1.jpg&#34; alt=&#34;pdf1&#34;&gt;&lt;/p&gt;
&lt;p&gt;The relationship between &lt;code&gt;\(X(t)\)&lt;/code&gt; and &lt;code&gt;\(P(x,t)\)&lt;/code&gt; is more general than for the example used here. In general, if we have the SDE&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$dX(t) = f(X,t)dt + g(X,t) dW(t)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;in the Itô sense, then &lt;code&gt;\(P(x,t)\)&lt;/code&gt; is the solution of&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\frac{\partial P}{\partial t}= - \frac{\partial}{\partial x}\left[f(x,t)P(x,t)\right] + \frac{\partial^2}{\partial x^2}\left[g^2(x,t)P(x,t)\right]$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The term &lt;code&gt;\(f(x,t)\)&lt;/code&gt; is usually know as the drift and &lt;code&gt;\(g(x,t)\)&lt;/code&gt; is the diffusion term.&lt;/p&gt;
&lt;p&gt;Once the relationship between the Fokker-Planck equation and its SDE is given, it is very easy to understand Itô Calculus. For example, given the above SDE &lt;code&gt;\(dX = a dW(t)\)&lt;/code&gt;, what is the SDE that will satisfy &lt;code&gt;\(Y(t) = X^2(t)\)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;Instead of using Itô&amp;rsquo;s lemma,  we will use the Fokker Planck equation and traditional calculus. Thus &lt;code&gt;\(\partial/\partial x = 2 \sqrt{y} \partial/\partial y\)&lt;/code&gt;. We also have that &lt;code&gt;\(P(x,t) dx = P(y,t) dy\)&lt;/code&gt; or &lt;code&gt;\(P(x,t) = 2 \sqrt{y} P(y,t)\)&lt;/code&gt;. Putting all these things together we get&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\frac{\partial}{\partial t}2\sqrt{y}P(y,t) = \frac{a^2}{2}\left\{2\frac{\partial}{\partial y}+4y\frac{\partial^2}{\partial y^2}\right\}2\sqrt{y} P(y,t)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;and with a little bit of algebra we get&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\frac{\partial P}{\partial t}=-\frac{\partial}{\partial y}[a^2 P(y,t)] + \frac{a^2}{2}\frac{\partial^2}{\partial y^2}[4yP(y,t)]$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which, according to the general relationship between Fokker-Planck equation and SDE, corresponds to the following SDE&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$dY = a^2 dt + 2a \sqrt{Y} dW(t)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;as the Itô&amp;rsquo;s lemma says. Obviously, this way to get the Itô lemma is painful in general, so you’d better use it directly on the SDE instead of the method shown here which goes through the Fokker-Planck equation. However, it is interesting to see that you can recover it from the Fokker-Planck equation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing citation networks</title>
      <link>http://estebanmoro.org/2009/02/visualizing-citation-networks/</link>
      <pubDate>Mon, 09 Feb 2009 17:51:25 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/02/visualizing-citation-networks/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://eigenfactor.org/&#34;&gt;Eigenfactor Project&lt;/a&gt; and &lt;a href=&#34;http://well-formed-data.net/&#34;&gt;Moritz Stefaner&lt;/a&gt; join efforts to &lt;a href=&#34;http://well-formed.eigenfactor.org/&#34;&gt;visualize the citation network&lt;/a&gt; between different journals belonging to different research fields. It is amazing and a wonderful way to explore patterns in citation networks&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2009/02/radial_01bhvntsv7lrcoksgsgs0ossswc8td8r2s3w1cs4kksc4okksgg8th.jpeg&#34; alt=&#34;radial_01bhvntsv7lrcoksgsgs0ossswc8td8r2s3w1cs4kksc4okksgg8th&#34;&gt;&lt;/p&gt;
&lt;p&gt;Found via &lt;a href=&#34;http://flowingdata.com/2009/02/06/ranking-and-mapping-scientific-knowledge-eigenfactor/&#34;&gt;FlowingData&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Waiting for the bus</title>
      <link>http://estebanmoro.org/post/2009-01-28-waiting-for-the-bus/</link>
      <pubDate>Wed, 28 Jan 2009 10:54:22 +0000</pubDate>
      
      <guid>http://estebanmoro.org/post/2009-01-28-waiting-for-the-bus/</guid>
      <description>&lt;p&gt;Although the public transportation system in Madrid is very good, I don&amp;rsquo;t usually take the bus or the train to move around. But sometimes my car decides I should take public transportation (bus or train). One of things I always found intriguing is that I always wait way more for the bus than what is expected according to the frequency quoted by the transportation companies at the bus or train stop. For example: if the frequency of the buses is 4 per hour, you should expect a bus each 15 minutes on average, although fluctuations around this value may occur due to traffic conditions. Thus, arriving at the bus stop at random will get you an average of 15/2 = 7.5 minutes of wait. I have the impression I always wait 15 minutes instead. How can this be? Is it that I am so unlucky I always arrive at the bus stop when the previous bus has just left?&lt;/p&gt;
&lt;p&gt;The answer to this question is the famous &lt;a href=&#34;http://mahalanobis.twoday.net/stories/3486587/&#34;&gt;waiting time paradox&lt;/a&gt; in &lt;a href=&#34;http://en.wikipedia.org/wiki/Queueing_theory&#34;&gt;queueing theory&lt;/a&gt;: in short, let&amp;rsquo;s assume that the times between two buses are given by the variable &lt;code&gt;\(T\)&lt;/code&gt;. In the ideal world, &lt;code&gt;\(T\)&lt;/code&gt; will be a deterministic variable. In the example above, &lt;code&gt;\(T = 15\)&lt;/code&gt; minutes. However, due to traffic conditions and other variables, &lt;code&gt;\(T\)&lt;/code&gt; is distributed around 15 minutes. For example, the following graphic shows the &amp;ldquo;lateness&amp;quot;of non-frequent buses in Great Britain, extracted from the &lt;a href=&#34;http://www.dft.gov.uk/pgr/statistics/datatablespublications/public/buspunctuality/buspunctuality07&#34;&gt;Bus Punctuality Statistics GB 2007 report&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/lateness1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;As we can see, although most of the buses were late only less than a couple of minutes, but there is an significant fraction of them that were late more than 5 minutes. And even some of them came earlier than expected! Assuming that our buses come at times &lt;code&gt;\(T\)&lt;/code&gt;drawn from the above distribution, let&amp;rsquo;s see how a day will look like from the bus stop:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/diabus.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Buses arrived at the bus stop (vertical lines) with time between them given by &lt;code&gt;\(T_i\)&lt;/code&gt;. After my car breaks down, I arrive at the bus stop at the time given by the vertical arrow. Thus I have to wait a time &lt;code&gt;\(\tau\)&lt;/code&gt;. The question is: what is the average value of &lt;code&gt;\(\tau\)&lt;/code&gt;? Given that my car breaks at random, I can assume that my arrival time is completely at random, uncorrelated with bus time tables. However, if the time I get to the bus stop is random, I have more probability to get to the bus stop in an interval in which the time between buses &lt;code&gt;\(T\)&lt;/code&gt; is bigger. Specifically, the probability that I arrive at an interval with time between buses &lt;code&gt;\(T\)&lt;/code&gt; is &lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\frac{T P(T)}{\overline{T}}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;\(\overline{T}\)&lt;/code&gt; is the average value of time between buses. Given the interval &lt;code&gt;\(T\)&lt;/code&gt;, the waiting time &lt;code&gt;\(\tau\)&lt;/code&gt; is equally distributed (since my arrival is random), and thus we have to multiply the above probability by &lt;code&gt;\(1/T\)&lt;/code&gt;. Finally, we average over all possible &lt;code&gt;\(\tau \leq T\)&lt;/code&gt;, giving
&lt;code&gt;$$Q(\tau) = \int_\tau^\infty \frac{TP(T)}{\overline T} \frac{1}{T}dT = \frac{1}{\overline T}\int_\tau^\infty P(T) dT$$&lt;/code&gt;
which give us the distribution of waiting times. The average value of &lt;code&gt;\(\tau\)&lt;/code&gt;is the given by
$$\overline \tau = \int_0^\infty \tau Q(\tau) d\tau = \frac{\overline{T^2}}{2\overline T^2} = \frac{\overline T}{2}\left(1 + \frac{\sigma_T^2}{\overline{T}^2}\right) $$
where &lt;code&gt;\(\sigma_T^2\)&lt;/code&gt; is the variance of the times between buses. This equation is the main result. It says:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If buses come at perfect and regular time intervals, then &lt;code&gt;\(\sigma_T = 0\)&lt;/code&gt; and the waiting time is what we expect: &lt;code&gt;\(\overline{\tau} = \overline{T}/2\)&lt;/code&gt;. That is if we expect a bus each 15 minutes, I will wait (in average) 7.5 minutes.&lt;/li&gt;
&lt;li&gt;However, in real world, buses do not arrive at perfect times and then &lt;code&gt;\(\sigma_T &amp;gt; 0\)&lt;/code&gt;. Thus, waiting time is always greater than &lt;code&gt;\(\overline{T}/2\)&lt;/code&gt;. In fact, the distribution of lateness above shows that there is a large fraction of buses with long delays and then &lt;code&gt;\(\sigma_T\)&lt;/code&gt; could be very big, controlling the waiting time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In fact, the GB Bus Punctuality Report shows that in average, waiting time exceeds 40% the expected time &lt;code&gt;\(\overline{T}/2\)&lt;/code&gt;. That is: due to the variance in times between buses, you (and me) end up waiting a time greater than the average time between buses. And that is my feeling: if trains/buses come each 15 minutes, I end up waiting 15 minutes, not 7.5.&lt;/p&gt;
&lt;p&gt;In a ideal world, bus timetables would quote both the frequency of the buses &lt;code&gt;\(\overline{T}\)&lt;/code&gt; and their variance &lt;code&gt;\(\sigma_T\)&lt;/code&gt;, so we can estimate the waiting time. Unfortunately, they just tell us part of the story&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Referee Reports</title>
      <link>http://estebanmoro.org/2009/01/referee-reports/</link>
      <pubDate>Wed, 21 Jan 2009 10:39:43 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/01/referee-reports/</guid>
      <description>&lt;p&gt;I found an &lt;a href=&#34;http://cm.physics.tamu.edu/cmseminars/cm_talks/2006_02_01_Mitra_S.pdf&#34;&gt;interesting presentation&lt;/a&gt; by Sami Mitra, associate editor of Physical Review Letters, about the editorial office and the editorial process at PRL. Among some interesting figures about the journal and also about the procedure of selecting potential referees, I enjoyed very much the quotes from some of the referee communications with the editorial office. Here they are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I cannot review this paper as it is wrong and I did it first.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Did he/she make it first and wrong too? Here is another one:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This paper should be rejected for the following reasons&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;No one cares about this anymore&lt;/li&gt;
&lt;li&gt;Anyone who could referee it is probably dead&lt;/li&gt;
&lt;li&gt;All who read it will wish they were&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kind of rude, isn&amp;rsquo;t it? Anyway, I think he made his point. Next:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I apologize for the delay in reviewing this paper. I inherited a 127 student electrical and computer engineering course plus lab this January because the professor assigned to teach it unexpected passed away. My department head attends every lecture to make sure I do a good job.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My god! Poor guy, what a department!! Next:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I beg your pardon. My office was painted and repaired a couple of weeks ago and that involved moving out more or less entirely. I have no idea where this manuscript is, or if I received it. For what it is worth, the title does sound slightly familiar.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Did they buy this excuse? It&amp;rsquo;s kind of childish. At least my excuses are better. Now I know.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t miss also the authors&#39; communications with the editor in Sami&amp;rsquo;s talk. Priceless.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publish and... perish</title>
      <link>http://estebanmoro.org/2009/01/publish-and-perish/</link>
      <pubDate>Mon, 12 Jan 2009 08:08:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/01/publish-and-perish/</guid>
      <description>&lt;p&gt;In the old days, research quality was measured by the number of papers you published. Publishing was a hard process and only few scientists were able to publish several papers per year. However, with the bloom of new journals, the appearance of electronic editorial process, and the specialization of research fields, the number of publications per year has grow exponentially during the last decades. Thus publishing is not longer a good measure of the quality of research. As an example if this I recently attended a talk by &lt;a href=&#34;http://physics.bu.edu/~redner/&#34;&gt;Sid Redner&lt;/a&gt; in which he showed the following data extracted from the Physical Review citation data of 353000 papers:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * Only 11 papers got more than 1000 citations
  * 245000 got less than 10 citations
  * 100000 got one or none citations
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For me it is amazing to see that roughly 1/3 of the papers published got almost no citations at all. It is a publish and perish process in which 1/3 of the papers are lost.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2009/01/long-tail-300x225.png&#34; alt=&#34;long-tail&#34;&gt;
The situation is similar to what has been &lt;a href=&#34;http://www.mcps-prs-alliance.co.uk/monline/research/Documents/Will%20Page%20%282008%29%20The%20Long%20Tail%20Interrogated%20Part%202.pdf&#34;&gt;found recently &lt;/a&gt;in the music industry.  Out of 13 million sons available to buy online, 10 million of them have never been bought. As Will Page put it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * Only 20% of the tracks in their sample are &#39;active&#39;, that is to say they sold at least one copy, and hence, 80% of the tracks sold nothing
  * 80% of the revenue came from around 3% of the active tracks
  * Only 4 tracks sold more than 100000 copies
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This led Will Page to question the &lt;a href=&#34;http://en.wikipedia.org/wiki/The_Long_Tail&#34;&gt;Long-Tail theory&lt;/a&gt; by &lt;a href=&#34;http://longtail.typepad.com/the_long_tail/&#34;&gt;Chris Anderson&lt;/a&gt; which states that the market share of low demanded items can be bigger than that of best-sellers. To put it in mathematical terms, the mass of the distribution in the tail of can be bigger than the mass around the peak of the distribution. This happens mostly with Pareto-law distributions and thus the name &amp;ldquo;long-tail&amp;rdquo;. But Will Page&amp;rsquo;s data seems to suggest that there is not even such a tail and planning your business in the long tail is risky: if you center your business plan in trying to sell the tail of the distribution, most probably you won&amp;rsquo;t succeed. As Andrew Bud (Executive Chairman from Mblox) put it: &amp;ldquo;in this tail, you starve&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The same can happen to a journal if it lives in the long-tail: what is the fraction of perishable papers a editor of a journal is willing to accept? What is the &amp;ldquo;citation model&amp;rdquo; the journal is intending to have? We all know about the impact factor of a journal, which is only giving us information about (mostly) regular-cited papers. A better information will be also the zero-index of a journal (or a researcher), i.e. the fraction of papers that never get cited at all. An idea I am working on recently&amp;hellip; Stay tuned&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The best job in 2008 was ... mathematician!</title>
      <link>http://estebanmoro.org/2009/01/the-best-job-in-2008-is-mathematician/</link>
      <pubDate>Thu, 08 Jan 2009 10:46:40 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2009/01/the-best-job-in-2008-is-mathematician/</guid>
      <description>&lt;p&gt;Good news to fans of the &amp;ldquo;language of Nature&amp;rdquo;, mathematics. Wall Street Journal is running &lt;a href=&#34;http://online.wsj.com/article/SB123119236117055127.html&#34;&gt;an article &lt;/a&gt;on what are the best jobs in 2008. The ranking is done &amp;ldquo;evaluating 200 professions to determine the best and worst according to five criteria inherent to every job: environment, income, employment outlook, physical demands and stress.&amp;rdquo; And which one do you think ranks first? Here is the list of the first ten:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  1. Mathematician
  2. Actuary
  3. Statistician
  4. Biologist
  5. Software Engineer
  6. Computer Systems Analyst
  7. Historian
  8. Sociologist
  9. Industrial Designer
  10. Accountant
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mathematicians are not just in academia. This is the only reason WSJ found the average annual income of a mathematician is $94,160.&lt;/p&gt;
&lt;p&gt;Found via &lt;a href=&#34;http://arturadib.blogspot.com/&#34;&gt;Artur Adib Blog &lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brown&#39;s observations on Brownian motion </title>
      <link>http://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/</link>
      <pubDate>Thu, 18 Dec 2008 09:27:47 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/</guid>
      <description>&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Robert_Brown_%28young_-_larousse%29.jpg/397px-Robert_Brown_%28young_-_larousse%29.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;In 1828, Robert Brown published the manuscript entitled &amp;ldquo;A brief account of microscopical observations made in the months of June, July and August 1827, on the particles contained in the pollen of plants; and on the general existence of active molecules in organic and inorganic bodies&amp;rdquo; in the Edinburgh new Philosophical Journal [download it in pdf format &lt;a href=&#34;http://sciweb.nybg.org/science2/pdfs/dws/Brownian.pdf&#34;&gt;here&lt;/a&gt;]. He suspended some of the pollen grains of the species &lt;a href=&#34;http://www.robsplants.com/plants/ClarkPulch.php&#34;&gt;Clarkia pulchella&lt;/a&gt; in water and examined them closely, only to see them &amp;ldquo;filled with particles&amp;rdquo; of around 5 µm diameter that were &amp;ldquo;very evidently in motion&amp;rdquo;. He was soon satisfied that the movement &amp;ldquo;arose neither from currents in the fluid nor form its gradual evaporation, but belonged to the particle itself&amp;rdquo;. Brown&amp;rsquo;s work was the first comprehensive observation of a phenomena called &lt;a href=&#34;http://en.wikipedia.org/wiki/Brownian_motion&#34;&gt;Brownian motion&lt;/a&gt; which remained unexplained until the beginning of the 20th century by Bachelier and most notably by Einstein in his famous paper in 1905. Brownian motion is the most basic description of the dynamics of a particle, price, etc. under the influence of external noise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/microscopio-brown-150x150.jpg&#34; alt=&#34;Microscope used by Brown&#34;&gt;Microscope used by Brown&lt;/p&gt;
&lt;p&gt;A typical mistake found in books, encyclopedias and articles (even in the Nature journal and even by the great &lt;a href=&#34;http://www.nature.com/nature/journal/v433/n7023/full/433221a.html&#34;&gt;Giorgio Parisi&lt;/a&gt;) is that Brown observed the motion of the pollen grains themselves. This might be the most clear example of a propagated mistake in the scientific literature, since it is obvious from the very title that the particles he observed were &amp;ldquo;in the pollen grains&amp;rdquo;. In fact, using the explanation of the motion by Einstein is easy to convince ourselves that the pollen grains were too big to wander around enough to be observable: Einstein in 1905 published a paper (original &lt;a href=&#34;http://www.physik.uni-augsburg.de/theo1/hanggi/History/Einstein1906BMII.pdf&#34;&gt;in german&lt;/a&gt;) in which he derived the famous &lt;a href=&#34;http://en.wikipedia.org/wiki/Einstein_relation_(kinetic_theory)&#34;&gt;Einstein relation&lt;/a&gt; in kinetic theory&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$D = \frac{k_B T}{6 \pi \eta r}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which relates the diffusion constant of the Brownian motion of a particle &lt;code&gt;\(D\)&lt;/code&gt; with the radius of the particle &lt;code&gt;\(r\)&lt;/code&gt; and the viscosity of the medium in which the particle is moving &lt;code&gt;\(\eta\)&lt;/code&gt;. The diffusion constant &lt;code&gt;\(D\)&lt;/code&gt; is also proportional to the temperature &lt;code&gt;\(T\)&lt;/code&gt; and &lt;code&gt;\(k_B\)&lt;/code&gt; is the Boltzmann constant. In order to observe the motion by eye, the particle should move considerably in a matter of seconds. We can evaluate the size of the movement by looking at the root-mean-square fluctuations in the position which are given by&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\langle x^2(t)\rangle = D t$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For a pollen grain the radius is around &lt;code&gt;\(\simeq 100 \mu m\)&lt;/code&gt; and in water at &lt;code&gt;\(T =\)&lt;/code&gt; 25ºC we get that &lt;code&gt;\(\langle x^2(t)\rangle = 19 \mu m\)&lt;/code&gt; in &amp;hellip; one day!! This slow pace motion is hard to observe with today optical microscopes by eye, not to say with the microscope used by Brown (see the above picture).&lt;/p&gt;
&lt;p&gt;To observe the Brownian motion by eye, the particles should be smaller. If we assume that the radius should be small enough so that the RMS fluctuations in one second are greater or of the order of the particle size, we get that&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$r \leq 1 \mu m$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;that is, of the same length of the particles observed by Brown inside the pollen grain. In the following video you can see this molecular motion in an experiment made a research group in the Universidad Complutense de Madrid (Luis Dinis, &lt;a href=&#34;http://www.ucm.es/info/goptic/&#34;&gt;Julio Serna&lt;/a&gt;, Rodrigo Soto and Ricardo Brito) using polystyrene spheres of &lt;code&gt;\(0.75-0.89\mu m\)&lt;/code&gt; diameter in water. The observations are made with an optical microscope using a 60x objective. The Brownian motion is evident.&lt;/p&gt;
&lt;video width=&#34;600&#34; controls&gt;
  &lt;source src=&#34;http://estebanmoro.org/img/posts/bmhq1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p&gt;More information about Brown&amp;rsquo;s observations and related work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ee.adfa.edu.au/staff/hrp/Literature/articles/karel3Avogadro.pdf&#34;&gt;Brownian motion and molecular size: counting and sizing molecules&lt;/a&gt;_, a Literature Study by K.L. Planken&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nature.com/nature/journal/v434/n7030/full/434137c.html&#34;&gt;Brown knew particles were smaller than pollen&lt;/a&gt; by D. M. Wilkinson, Nature (2005). A nice note about the repetition of the mistake mentioned above.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.microscopy-uk.org.uk/dww/home/hombrown.htm&#34;&gt;An exploration of your house in close-up: studying Brownian motion&lt;/a&gt;, by Dave Walker. Dave shows how to repeat the experiment using the fat droplets suspended in milk (cool)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: Julio Serna (thanks) sent me this interesting reference:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.brianjford.com/wbbrowna.htm&#34;&gt;BROWNIAN MOVEMENT IN CLARKIA POLLEN: A REPRISE OF THE FIRST OBSERVATIONS&lt;/a&gt;, by Brian J Ford, The Microscope, &lt;strong&gt;40&lt;/strong&gt;(4): 235-241, 1992. in which he repeated the experiment by Brown and settle the question of whether Brown was able or not to observe the Brownian motion with his microscope.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Science is the only news</title>
      <link>http://estebanmoro.org/2008/12/science-is-the-only-news/</link>
      <pubDate>Thu, 11 Dec 2008 08:19:12 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/science-is-the-only-news/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Science is the only news. When you scan through a newspaper or magazine, all the human interest stuff is the same old he-said-she-said, the politics and economics the same sorry cyclic dramas, the fashions a pathetic illusion of newness, and even the technology is predictable if you know the science. Human nature doesn’t change much; science does, and the change accrues, altering the world irreversibly. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A famous quote by &lt;a href=&#34;http://en.wikipedia.org/wiki/Stewart_Brand&#34;&gt;Stewart Brand&lt;/a&gt;, that appear in John Brockman&amp;rsquo;s essay (and book) &lt;a href=&#34;http://www.edge.org/3rd_culture/&#34;&gt;The Third Culture&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New section in the arXiv: Quantitative Finance</title>
      <link>http://estebanmoro.org/2008/12/new-section-in-the-arxiv-quantitative-finance/</link>
      <pubDate>Tue, 09 Dec 2008 09:05:42 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/new-section-in-the-arxiv-quantitative-finance/</guid>
      <description>&lt;p&gt;News from the &lt;a href=&#34;http://arxiv.org/&#34;&gt;arXiv&lt;/a&gt;: a new section has been created to host preprints about Quantitative Finance. The section (as stated in the &lt;a href=&#34;http://arxiv.org/new/q-fin_announcement.html&#34;&gt;press release&lt;/a&gt;) intends to fix a problem with existing pre-print repositories. One one hand, social sciences repositories like SSRN, RepEC/IDEAS and others are too academic for practitioners, while on the other hand sites like defaultrisk.com or wilmott.com have not attracted many academic contributors. The new category in the arXiv would be a gathering point for both practitioners and academic people working in this important research field&lt;/p&gt;
&lt;p&gt;The new sub-categories of the new q-fin category are:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * q-fin.PR - Pricing of Securities
  * q-fin.RM - Risk Management
  * q-fin.PM - Portfolio Management
  * q-fin.TR - Trading and Microstructure
  * q-fin.ST - Statistical Finance
  * q-fin.CP - Computational Finance
  * q-fin.GN - General Finance
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The arXiv editors have already identified a large number of submissions to the repository which already fit in the q-fin category. These preprints have been re-classified and can be already found in the new category.&lt;/p&gt;
&lt;p&gt;I like this move by arXiv. In the last years, the arXiv has been growing steadily and it is now one of the biggest scientific electronic repositories. It offers a good service to publish electronically your preprints. It improves the visibility of your preprints and it has a bunch of handy tools for authors and researchers, like RSS feeds, trackbacks from blogs, Citebase (preprint citations), etc. &lt;a href=&#34;http://arxiv.org/abs/cs/0603056&#34;&gt;Recent studies&lt;/a&gt;, for example, have shown that posting your preprints to the arXiv lead to higher number of citations for mathematics articles. &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Although it started as a Physics repository, new disciplines (an subdisciplines) have been incorporated in the last years:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * Physics (started in 1991 as a bulletin with only one section: hep-th)
  * Nonlinear (created in 1993 and installed on xyz.lanl.gov)
  * Mathematics (created in 1998)
  * Computer Science (created in 1998)
  * Quantitative Biology (created in 2003)
  * Statistics (created in 2007)
  * Quantitative Finance (created in 2008)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to stochastic differential equations</title>
      <link>http://estebanmoro.org/2008/12/introduction-to-stochastic-differential-equations/</link>
      <pubDate>Thu, 04 Dec 2008 16:45:32 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/introduction-to-stochastic-differential-equations/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Stochastic_differential_equation&#34;&gt;Stochastic differential equations&lt;/a&gt; (SDEs) are basically &lt;em&gt;inhomogenous ordinary differential equations that depend on an external stochastic process&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Typically, that stochastic process is &lt;a href=&#34;http://en.wikipedia.org/wiki/White_noise&#34;&gt;white noise&lt;/a&gt;, which is the mathematical idealization of the noise found in nature. This idealization is handy, because it simplifies the mathematical description. However, this idealization comes at some cost: traditional calculus is no longer valid and you have to use the so-call &lt;a href=&#34;http://en.wikipedia.org/wiki/Ito_stochastic_calculus&#34;&gt;Itô calculus&lt;/a&gt;. This introduces some non intuitive changes. For example, instead of the usual chain rule of calculus, the Itô formula should be used. Here is an example, the Itô integral of the Wiener process (or Brownian Motion) is&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/itocalculus.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note the last term in the right-hand-side (!).&lt;/p&gt;
&lt;p&gt;If you are interested to learn more on SDEs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I prepared a long time ago &lt;a href=&#34;http://estebanmoro.org/img/ps/introtosde.pdf&#34;&gt;some notes&lt;/a&gt; about SDEs in Spanish&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;http://math.berkeley.edu/~evans/SDE.course.pdf&#34;&gt;nicer introduction&lt;/a&gt; to SDEs by Prof. Evans&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Percentages and absolute numbers</title>
      <link>http://estebanmoro.org/2008/12/percentages-and-absolute-numbers/</link>
      <pubDate>Tue, 02 Dec 2008 09:47:23 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/percentages-and-absolute-numbers/</guid>
      <description>&lt;p&gt;Percentage of active users in the Internet 2.0 is tiny. &lt;a href=&#34;http://www.useit.com/alertbox/participation_inequality.html&#34;&gt;Fractions go from&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * only 1% of Wikipedia&#39;s users contribute to making it better
  * only 0.1% of users upload their own videos to Youtube
  * only 3% of people with weblogs post on a daily basis
  * only 1% of Amazon.com customers contribute with reviews
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The numbers are tiny. But not uncommon. Typical return rates of marketing campaigns or surveys are around 2-5% (see &lt;a href=&#34;http://www.the-dma.org/cgi/disppressrelease?article=1008&#34;&gt;report&lt;/a&gt; by the Direct Marketing Association). In our experiments of &lt;a href=&#34;http://estebanmoro.org/?p=100&#34;&gt;viral marketing campaigns&lt;/a&gt; we got up to 8% by triggering the action of clients using a prize contest.&lt;/p&gt;
&lt;p&gt;So, how do all these business survive? The reason is absolute numbers. Percentages are small, but absolute numbers are huge:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * 70000 active contributors maintain the Wikipedia
  * 65000 videos are uploaded daily to Youtube
  * 1.6 million of posts are created daily according to Technorati
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even for the dubious business of email spam, absolute numbers matter: tens/hundreds of people usually answer email spam campaigns. Out of hundreds of millions of emails sent, yielding a &lt;a href=&#34;http://www.icsi.berkeley.edu/pubs/networking/2008-ccs-spamalytics.pdf&#34;&gt;0.0001% response rate [pdf]&lt;/a&gt;. But this low response rate does not matter, since sending email spam is &lt;a href=&#34;http://www.longtail.com/the_long_tail/2008/11/the-miraculous.html&#34;&gt;a freemium business&lt;/a&gt; which uses the near-zero marginal cost of online distribution&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is Game Theory a scientific theory?</title>
      <link>http://estebanmoro.org/2008/12/is-game-theory-a-scientific-theory/</link>
      <pubDate>Mon, 01 Dec 2008 07:40:05 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/12/is-game-theory-a-scientific-theory/</guid>
      <description>&lt;p&gt;A wonderful quote about the nature of Game Theory&lt;/p&gt;
&lt;blockquote&gt;Game theory is no doubt wonderful for telling stories. However, it flunks the main test of any scientific theory: The ability to make empirically testable predictions. In most real-life situations, many different outcomes -- from full cooperation to near-disastrous conflict -- are consistent with the game-theory version of rationality. &lt;/blockquote&gt;
&lt;p&gt;by Michael Mandel, on &lt;a href=&#34;http://www.businessweek.com/bwdaily/dnflash/oct2005/nf20051011_3028_db084.htm&#34;&gt;Kahneman and Smith 2002 Nobel Prize in Economics&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Interestingly enough, as of Dec. 1st 2008, google finds 3 million pages about &amp;ldquo;game theory&amp;rdquo;, half of them containing criticisms about it. Mostly about the abuse of the &amp;ldquo;rationality assumption&amp;rdquo; but also about the confusion about using it as a normative theory (i.e. a theory of how humans must behave) instead of descriptive picture (i.e. a mathematical way to explain how humans could behave). More on normative vs. descriptive analysis in the &lt;a href=&#34;http://en.wikipedia.org/wiki/Game_theory&#34;&gt;wikipedia&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kiyoshi Itô, 93, dies</title>
      <link>http://estebanmoro.org/2008/11/kiyoshi-ito-93-dies/</link>
      <pubDate>Sun, 30 Nov 2008 22:17:18 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/11/kiyoshi-ito-93-dies/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://estebanmoro.org/wp-content/uploads/2008/11/ito.jpeg&#34;&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2008/11/ito-242x300.jpg&#34; alt=&#34;&#34;&gt;
&lt;/a&gt;November was a rather sad month in the world of stochastic differential equations. In the 26th we were suppose to be celebrating the birth of one of the best mathematicians in history, &lt;a href=&#34;http://en.wikipedia.org/wiki/Norbert_Wiener&#34;&gt;Norbert Wiener&lt;/a&gt;, who gives name to the Wiener process, usually denoted W(t). However, in the 10th, &lt;a href=&#34;en.wikipedia.org/wiki/Kiyoshi_It%C5%8D&#34;&gt;Kiyoshi Itô&lt;/a&gt;, the father of stochastic differential equations, &lt;a href=&#34;http://www.nytimes.com/2008/11/24/business/24ito.html?_r=1&amp;amp;ref=obituaries&#34;&gt;passed away&lt;/a&gt;. Interestingly both are present in a simple stochastic differential equation like this&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://estebanmoro.org/wp-content/uploads/2008/11/sdejpeg.jpg&#34;&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2008/11/sdejpeg-300x22.jpg&#34; alt=&#34;&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;which serves as a tribute to both giants. More information:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * [Mathematical work of Norbert Wiener](www.ams.org/notices/199506/mandrekar.pdf)
  * [Kiyoshi Itô biography](http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Ito.html)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Individuals and groups</title>
      <link>http://estebanmoro.org/2008/11/individuals-and-groups/</link>
      <pubDate>Wed, 26 Nov 2008 15:03:29 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2008/11/individuals-and-groups/</guid>
      <description>&lt;blockquote&gt;While the individual man is an insoluble puzzle, in the aggregate he becomes a mathematical certainty. You can, for example, never foretell what any one man will do, but you can say with precision what an average number will be up to. Individuals vary, but percentages remain constant. So says the statistician&lt;/blockquote&gt;
&lt;p&gt;Sherlock Holmes in &amp;ldquo;The Sign of Four&amp;rdquo;. Via &lt;a href=&#34;http://gaussianos.com/%C2%A1exacto/&#34;&gt;Gaussianos&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Proofs and pictures </title>
      <link>http://estebanmoro.org/2007/11/proofs-and-pictures/</link>
      <pubDate>Fri, 30 Nov 2007 20:18:05 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2007/11/proofs-and-pictures/</guid>
      <description>&lt;p&gt;A picture is worth a thousand lines of equations&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/neatproofs.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.chass.utoronto.ca/~jrbrown/&#34;&gt;By James Robert Brown&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Editor de la sección &#34;Física y Computación&#34;</title>
      <link>http://estebanmoro.org/2006/10/editor-de-la-seccion-fisica-y-computacion/</link>
      <pubDate>Mon, 30 Oct 2006 20:21:13 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/10/editor-de-la-seccion-fisica-y-computacion/</guid>
      <description>&lt;p&gt;Hola a todos.&lt;/p&gt;
&lt;p&gt;Este es mi primer post en español en este blog (aunque incluyo la traducción al inglés más abajo). Y lo hago para anunciar que soy el editor desde el número de Diciembre de la sección &amp;ldquo;Física y Computación&amp;rdquo; de la &lt;a href=&#34;http://www.ucm.es/info/rsef/revista_espanola.html&#34;&gt;revista&lt;/a&gt; de la &lt;a href=&#34;http://www.rsef.es/&#34;&gt;Real Sociedad Española de Física&lt;/a&gt;. Para seguir las novedades y noticias de dicha sección he montado un &lt;a href=&#34;http://gisc.uc3m.es/fisica_y_computacion&#34;&gt;blog&lt;/a&gt; (distinto a este) en el que podeis ver los nuevos artículos de la sección, así como el archivo de los artículos ya publicados. Por supuesto, animo a todos a mandar una contribución a la sección en la que se valora especialmente el trabajo de simulación y computación en el entendimiento de problemas en física.&lt;/p&gt;
&lt;p&gt;Un saludo &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Hi all.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;This is my first post in spanish (you are reading the english translation of the paragraph above). I&amp;rsquo;m doing this to announce that I will be the editor of the &amp;ldquo;Physics and Computation&amp;rdquo; section of the &lt;a href=&#34;http://www.ucm.es/info/rsef/revista_espanola.html&#34;&gt;Journal&lt;/a&gt; of &lt;a href=&#34;http://www.rsef.es/&#34;&gt;Real Sociedad Española de Física&lt;/a&gt; (Spanish Royal Society of Physics). If you want to keep yourself updated with the section, please, visit the &lt;a href=&#34;http://gisc.uc3m.es/fisica_y_computacion&#34;&gt;blog&lt;/a&gt; I have created in which you can check the new contributions to the sections and browse through the archive of already published contributions as well. Of course, I encourage all of you to contribute to the section in which we give special emphasis to those problems in physics in which simulation or computational work has had a special relevant place.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Superconductivy Live!</title>
      <link>http://estebanmoro.org/2006/10/superconductivy-live/</link>
      <pubDate>Mon, 09 Oct 2006 08:09:49 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/10/superconductivy-live/</guid>
      <description>&lt;p&gt;It is always amazing to browse through &lt;a href=&#34;http://www.youtube.com/&#34;&gt;YouTube&lt;/a&gt;, specially if you are looking for science material. Here is an example of superconductivity: take a superconductor and a magnet at room temperature. Nothing happens. Now cool down the superconductor using liquid nitrogen. The superconductor starts &amp;ldquo;superconducting&amp;rdquo; and boom! here comes in the &lt;a href=&#34;http://en.wikipedia.org/wiki/Meissner_effect&#34;&gt;Meissner effect&lt;/a&gt;. As always, a picture (movie) is better than a page of equations to show how wonderful physics is.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The theory of nothing</title>
      <link>http://estebanmoro.org/2006/10/the-theory-of-nothing/</link>
      <pubDate>Wed, 04 Oct 2006 07:24:25 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/10/the-theory-of-nothing/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://stratonovich.uc3m.es/images/stories/notevenwrong.jpg&#34; alt=&#34;Image&#34;&gt;
Two New York newspapers (&lt;a href=&#34;http://www.nytimes.com/2006/09/17/books/review/Siegfried.t.html&#34;&gt;The New York Times&lt;/a&gt; and the &lt;a href=&#34;http://www.newyorker.com/critics/atlarge/articles/061002crat_atlarge&#34;&gt;New Yorker&lt;/a&gt;) are running stories about whether string theory is a theory of anything or not. Specifically, both articles are reviews of a couple of very critic books on string theory:  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;http://www.math.columbia.edu/~woit/wordpress/&#34;&gt;NOT EVEN WRONG : The Failure of String Theory and the Search for Unity in Physical Law&lt;/a&gt;. By Peter Woit.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;http://www.thetroublewithphysics.com/&#34;&gt;THE TROUBLE WITH PHYSICS The Rise of String Theory, the Fall of a Science, and What Comes Next&lt;/a&gt;. By Lee Smolin.&lt;/p&gt;
&lt;p&gt;Their criticisms are very interesting and pertain to any scientific discipline: if after 20 years of making calculations, there is not a clear-cut definition of the theory, different theories yield to the same results and there is not a single prediction made by string theory to be tested, is string theory really a theory? Are zillions of PhDs in string theory worth the effort? Or it is just &amp;ldquo;new version of medieval theology&amp;rdquo; as Sheldon Glashow put it? While the NYT article is very critic with both books above, the &lt;a href=&#34;http://www.newyorker.com/critics/atlarge/articles/061002crat_atlarge&#34;&gt;New Yorker article&lt;/a&gt; rises some points which I find intriguing in this discussion: is the search for beauty in the mathematical description of the universe enough reason for this exuberance of dimensions? And if so, how comes that thousands of different versions of the theory yield to the same result? The books are also very critic with the cultlike scientific community and atmosphere surrounding string theory. This is exemplified by the following anecdote: &amp;ldquo;The most hilarious recent symptom of string theory’s lack of rigor is the so-called Bogdanov Affair, in which French twin brothers, Igor and Grichka Bogdanov, managed to publish egregiously nonsensical articles on string theory in five peer-reviewed physics journals. Was it a reverse Sokal hoax? (In 1996, the physicist Alan Sokal fooled the editors of the postmodern journal Social Text into publishing an artful bit of drivel on the “hermeneutics of quantum gravity.”) The Bogdanov brothers have indignantly denied it, but even the Harvard string-theory group was said to be unsure, alternating between laughter at the obviousness of the fraud and hesitant concession that the authors might have been sincere.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The marketing of breaking laws of physics</title>
      <link>http://estebanmoro.org/2006/10/the-marketing-of-breaking-laws-of-physics/</link>
      <pubDate>Tue, 03 Oct 2006 08:12:00 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/10/the-marketing-of-breaking-laws-of-physics/</guid>
      <description>&lt;p&gt;Apparently, a company in Ireland named &lt;a href=&#34;http://www.steorn.net/frontpage/default.aspx&#34;&gt;Steorn&lt;/a&gt; has found the killer marketing campaign for their products:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  1. Get a law of physics: the first law of thermodynamics, for example, and claim you have a technology that can break it. Cool!
  2. Get a good flashy marketing campaign by publishing in The Economist a &amp;quot;show us wrong&amp;quot; announcement to the scientific community. 
  3. Hide the details of your technology and delay its public announcement by creating a &amp;quot;challenge&amp;quot; to the scientific community.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is it!. Nothing more than that and you get talked about in blogs, newspapers, etc. However, this seems to be just another case of &lt;a href=&#34;http://en.wikipedia.org/wiki/Cold_fusion&#34;&gt;cold fusion&lt;/a&gt;. Just reading their &amp;ldquo;about our products&amp;rdquo; web page shows how incredible (and irreal) their technology is: not only they promise that energy is totally conserved and not degradated in heat (100% performance of their technology) but&amp;hellip; they create energy out of the blue!!! Yes, you read it right, they get more than 100% performance! Dude, that is impressive. I hope they will start selling laptop batteries with their technology so they can recharged themselves forever.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kiyoshi Itô wins the Gauss Prize</title>
      <link>http://estebanmoro.org/2006/09/kiyoshi-ito-wins-the-gauss-prize/</link>
      <pubDate>Wed, 06 Sep 2006 08:13:26 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/09/kiyoshi-ito-wins-the-gauss-prize/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2008/11/ito-242x300.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Kiyoshi Itô (90), professor emeritus at kyoto University, has become the first winner of the Gauss Prize. This prize is to honor scientist whose mathematical research has had an impact outside mathematics. Ito&amp;rsquo;s work, mainly in establishing a well defined calculus (named Ito&amp;rsquo;s calculus) to treat high irregular noise functions has got widespread application in describing several stochastic processes across fields like economics, biology, chemistry, physics, etc. Ito&amp;rsquo;s calculus is behind the pricing of options introduced by Black, Scholes and Merton (which got them a Nobel price). It is also the mathematical theory behind the formal description (Langevin equation) of the Brownian motion studied previously by Bachelier or Einstein: basically, Itô&amp;rsquo;s contribution was to give mathematical basis to the continuum time description (in terms of a differential equation) for the motion of a particle under random, uncorrelated kicks from other particles. The solution of this equation is a function of time which is nowhere differentiable but still continuous. Itô&amp;rsquo;s give precise way to handle with those solutions by what is known as stochastic calculus. Specifically, he is well known for the Itô&amp;rsquo;s lemma, which is a modification of the standard chain rule of normal calculus when the function that we are dealing with is either that stochastic path or a function of it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Seven Warning Signs of Bogus Science</title>
      <link>http://estebanmoro.org/2006/04/the-seven-warning-signs-of-bogus-science/</link>
      <pubDate>Thu, 06 Apr 2006 08:15:39 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/04/the-seven-warning-signs-of-bogus-science/</guid>
      <description>&lt;p&gt;We all are aware of recent cases of fraud in science. The case of cloning in South Korea is the most recent one, but not the first or the last to happen. Identifying those cases is hard, since most of the times the verification of the claims is a long time-consuming process. Very recently, Robert L. Park has identified &lt;a href=&#34;http://chronicle.com/free/v49/i21/21b02001.htm&#34;&gt;some warning signs about a scientific discovery&lt;/a&gt;that can make us doubt about the scientific soundness of it, since they indicate that a scientific claim lies well outside the bounds of rational scientific discourse: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * The discoverer pitches the claim directly to the media 
  * The discoverer says that a powerful establishment is trying to suppress his or her work
  * The scientific effect involved is always at the very limit of detection
  * Evidence for a discovery is anecdotal
  * The discoverer says a belief is credible because it has endured for centuries
  * The discoverer has worked in isolation
  * The discoverer must propose new laws of nature to explain an observation
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Several examples with all or several of these red lights come to my mind. And I have the feeling that they are more frequent nowadays.&lt;/p&gt;
&lt;p&gt;Note: Robert L. Park is a professor of Physics at University of Maryland and the director of public information for the American Physical Society.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The future of the science might be wiki</title>
      <link>http://estebanmoro.org/2006/03/the-future-of-the-science-might-be-wiki/</link>
      <pubDate>Tue, 21 Mar 2006 08:17:20 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/03/the-future-of-the-science-might-be-wiki/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.edge.org/&#34;&gt;The Edge&lt;/a&gt; has a &lt;a href=&#34;http://www.edge.org/3rd_culture/kelly06/kelly06_index.html&#34;&gt;summary-article&lt;/a&gt; on a Kevin Kelly’s talk on &lt;em&gt;The Next 100 Years of Science: Long-term Trends in the Scientific Method&lt;/em&gt;. &lt;a href=&#34;http://www.kk.org/&#34;&gt;Kevin Kelly&lt;/a&gt; helped launch &lt;a href=&#34;http://www.wired.com/&#34;&gt;Wired&lt;/a&gt;magazine in 1993 and has published several books and articles in publications such as The Economist, The New York Times, Time, etc. He rises some interesting points about what’s next in science for this century. Specifically:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.wired.com/&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * There will be more change in the next 50 years of science than in the last 400 years.
  * This is the century of biology. It is the domain with the most scientists, the most new results, the most economic value, the most ethical importance, and the most to learn.
  * Computers will be not just a tool in science, but they will start to test hypothesis and run combinatorial simulations through possibility spaces.
  * New ways of knowing will emerge. From “wikiscience” in which hundreds of authors cooperate to the zero-author paper generated wholly by computers.
  * Science will create new levels of meaning.  The Internet already is made of one quintillion transistors, a trillion links, a million emails per second, 20 exabytes of memory.  It is approaching the level of the human brain and is doubling every year, while the brain is not.  It is all becoming effectively one machine.  And we are the machine.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although some of these predictions are rather speculative, I find the wikiscience part especially interesting. The ages in which a research is done by a sole author (or a small collaboration team) are bound to die. Results of a research will be communicated using wikipapers, which will be open to anybody and which could be modified by peers, changing the way we understand publication quality and peer-review. After all, the wiki is a publication environment in which material is added and reviewed by peers, just like a science publication should be. For example, I found particularly cumbersome the way referees and authors interact in scientific peer-review. A more flexible editorial environment like the wikipaper will have a profound impact in the way information is exchanged between editors, referees and authors. Another issue concerning the wikipaper would be the accountability of the research (important for each researcher’s cv) and the commercial part of the editorial process.&lt;/p&gt;
&lt;p&gt;How far are we from the future? Well, maybe not that far away, since there are are already &lt;a href=&#34;http://en.wikibooks.org/wiki/Main_Page&#34;&gt;Wikibooks &lt;/a&gt;and &lt;a href=&#34;http://en.wikibooks.org/wiki/Wikiversity&#34;&gt;Wikiversity&lt;/a&gt;open courses to be used and modified within a collaborative wiki environment. There is even an ongoing discussion about&lt;a href=&#34;http://www.usemod.com/cgi-bin/mb.pl?WikiAsScience&#34;&gt;wiki as science&lt;/a&gt; and about how &lt;a href=&#34;http://meta.wikimedia.org/wiki/Wiki_Scholarly_Journals&#34;&gt;Wiki Scholarly Journals&lt;/a&gt; should be.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing bad letters of recommendation: the story of Bachelier and Lévy</title>
      <link>http://estebanmoro.org/2006/03/writing-bad-letters-of-recommendation-the-story-of-bachelier-and-levy/</link>
      <pubDate>Wed, 15 Mar 2006 08:25:04 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/03/writing-bad-letters-of-recommendation-the-story-of-bachelier-and-levy/</guid>
      <description>&lt;p&gt;Take a coin and toss it a number &lt;code&gt;\(N\)&lt;/code&gt; of times in a time interval of duration &lt;code&gt;\(T\)&lt;/code&gt;. Suppose that every time you get head you win &lt;code&gt;\(a\)&lt;/code&gt; euros and that you lose the same amount of money when you get tail. Then your capital is a random process with ups and dows like this:&lt;/p&gt;
&lt;center&gt;
![](/img/posts/figurebachelier.jpg)&lt;/center&gt;
&lt;p&gt;This process is a stochastic process usually called &amp;ldquo;Random Walk&amp;rdquo; and its properties depend on the parameters $N, a $ and &lt;code&gt;\(T\)&lt;/code&gt;. For example: if we play this game several times, the average mean value of the capital obtained after a time &lt;code&gt;\(T\)&lt;/code&gt; is zero! This is simple to realize since the probability to get either head or tails is the same. The problem comes when you analyze the fluctuations around this zero gain: the variance of the deviations from this zero mean behavior go like&lt;/p&gt;
&lt;p&gt;$$ Var(N) = N a^2 $$&lt;/p&gt;
&lt;p&gt;which brings the sad conclusion that the more times you play the game the higher the fluctuations are. If you are risk-averse, this is the worst situation since, although in average you don&amp;rsquo;t lose or win, the uncertanty of what quantity you will get in one shot of the game is growing in time.&lt;/p&gt;
&lt;p&gt;We now ask the following question: do the properties of this game change if we play &lt;code&gt;\(M &amp;gt; N\)&lt;/code&gt; times in the same time &lt;code&gt;\(T\)&lt;/code&gt; with a smaller payoff &lt;code&gt;\(b&amp;lt;a\)&lt;/code&gt;? Of course the stochastic process change, but some of the properties remain unchanged under proper choices of &lt;code&gt;\(a\)&lt;/code&gt; and &lt;code&gt;\(b\)&lt;/code&gt;. Obviously the average gain of this new game is also zero. What about the RMS? Note that if we take &lt;code&gt;\(a^2=T/N\)&lt;/code&gt; or &lt;code&gt;\(b^2 = T/M\)&lt;/code&gt; then we have&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(Var(N) = N a^2 = T\)&lt;/code&gt; for the first game&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(Var(M)  =M b^2 = T\)&lt;/code&gt; for the second game&lt;/p&gt;
&lt;p&gt;which is independent of the payoff. This fact led some mathematicians early last century to study the asymptotic case &lt;code&gt;\(a\to 0\)&lt;/code&gt; and &lt;code&gt;\(N \to \infty\)&lt;/code&gt;, BUT taking&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$a^2 N = T = constant \qquad (1)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which usually called Brownian Motion. The name &amp;ldquo;Brownian&amp;rdquo; comes from the botanist Brown who observed how particles of (probably) &lt;a href=&#34;http://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/&#34;&gt;clay moved in water under the kicks of the molecules of water&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/louis_bachellier.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Bachelier (1870-1946 right) was the first one to study the Brownian motion in his PhD thesis at the Sorbonne in Paris and applied it as a possible model for the stock market. He was well ahead of his time not only for its application to the stock market, but also because he derived a lot of the properties of this stochastic process. Unfortunately his notation was a little bit sloppy. In particular, the dependence of &lt;code&gt;\(a^2\)&lt;/code&gt; with &lt;code&gt;\(N\)&lt;/code&gt; and &lt;code&gt;\(T\)&lt;/code&gt; [given by equation (1) above] in the limit &lt;code&gt;\(N\to\infty\)&lt;/code&gt; was omitted in most of his books and papers but always assumed by Bachelier. This &amp;ldquo;minor&amp;rdquo; omission and a careless reading of Bachelier&amp;rsquo;s work was the origin of Paul Lévy&amp;rsquo;s strong criticism to his work. It was so strong, that Levy wrote a very critical and negative report about Bachelier&amp;rsquo;s work when the latter was trying to get an appointment at Dijon. Bachelier of course didn&amp;rsquo;t get the position and moved then to a small university at Besançon and kept on working without much impact in the field.&lt;/p&gt;
&lt;p&gt;It was after Kolmogorov&amp;rsquo;s 1931 citation of Bachelier work that Lévy went back to his work and realized that he made a misjudgment of Bachelier&amp;rsquo;s work. Apparently Levy didn&amp;rsquo;t even read Bachelier&amp;rsquo;s papers and books in the very first place and, even so, he disregarded Bachelier&amp;rsquo;s findings as erroneous. Quite a strange behavior for one of the best mathematicians of all times. After that, in 1931, Lévy wrote to Bachelier a letter apologizing for his behavior. It was a little bit late since Bachelier retired in 1937 although Bachelier was quite happy to receive Lévy&amp;rsquo;s letter. At last his work was read by someone, and by the best!&lt;/p&gt;
&lt;p&gt;More information
&lt;a href=&#34;http://www-groups.dcs.st-and.ac.uk/%7Ehistory/Mathematicians/Bachelier.html&#34;&gt;Biography of Bachelier&lt;/a&gt;
&lt;a href=&#34;http://math.bu.edu/individual/murad/pub/bachelier-english43-fin-posted.pdf&#34;&gt;Bachelier and his times: A conversation with Bernard Bru&lt;/a&gt;, an article by M.S. Taqqu, published in Mathematical Finance - Bachelier Congress 2000&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Humans are superdiffusive</title>
      <link>http://estebanmoro.org/2006/02/humans-are-superdiffusive/</link>
      <pubDate>Thu, 09 Feb 2006 07:31:36 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/02/humans-are-superdiffusive/</guid>
      <description>&lt;p&gt;When tea is poured in a cup of hot water, we observe a phenomenon called &lt;a href=&#34;http://en.wikipedia.org/wiki/Diffusion&#34;&gt;diffusion&lt;/a&gt;: in the end particles of tea spread evenly throughout the mass of water and we enjoy our cup of tea. Diffusion occurs as a result of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Second_Law_of_Thermodynamics&#34;&gt;second law of thermodynamics&lt;/a&gt; (increase of entropy) and can be modeled quantitatively using the diffusion equation (or heat equation). This is a funny equation, since it establishes that the velocity of spreading is infinite while the mean root square fluctuations of the position of the particles grows in time as&lt;/p&gt;
&lt;p&gt;$$ \langle x^2 \rangle  = 2 D t$$&lt;/p&gt;
&lt;p&gt;Specifically, this means that the typical volume covered by the particles of tea in the cup grows like the square root of time, while there is always a chance to find a particle anywhere in the cup. The coefficient &lt;em&gt;D&lt;/em&gt; is called the diffusion constant and depends on thermodynamical properties of the liquid. It was &lt;a href=&#34;http://en.wikipedia.org/wiki/Albert_Einstein&#34;&gt;Einstein&lt;/a&gt; in his miraculous year (1905) who found the &lt;a href=&#34;http://en.wikipedia.org/wiki/Einstein_relation&#34;&gt;relationship with temperature&lt;/a&gt; and mobility of particles in the liquid which is named after him. There are numerous examples of diffusion processes (also known as Brownian motions) from the erratic motion of particles in water found by the botanist Brown in 1827 to the description of price fluctuations in stock markets made by &lt;a href=&#34;http://en.wikipedia.org/wiki/Louis_Bachelier&#34;&gt;Bachelier&lt;/a&gt; in 1900.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/baggage.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Of course, not everything in nature is diffusive. Actually, diffusive behavior is related to the &lt;a href=&#34;http://mathworld.wolfram.com/CentralLimitTheorem.html&#34;&gt;Central Limit Theory&lt;/a&gt; and the fact that the mean root square fluctuations is growing linearly in time is telling us that the sum of the kicks than a particle of coffee suffers in the cup add like random numbers to get the CLT result: the variance grows linearly in time. The ubiquity of diffusive behavior is related to the fact that convergence in CLT does not depend on the microscopic details of the random numbers that are summed.&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&#34;http://www.nature.com/nature/journal/v439/n7075/full/nature04292.html&#34;&gt;recent study published in Nature&lt;/a&gt; and made by D. Brockmann, L. Hufnagel and T. Geisel, these researchers have obtained quantitative assessment of the displacements of humans by analyzing the circulation of bank notes in the United States obtained in the &lt;a href=&#34;http://www.wheresgeorge.com/&#34;&gt;Where is George?&lt;/a&gt; website. They observe that human travel is somehow a random process governed by super-diffusive jumps to get&lt;/p&gt;
&lt;p&gt;$$\langle x^2 \rangle = 2 D_1 t$$&lt;/p&gt;
&lt;p&gt;which says that the typical area covered by humans when traveling is linear in time. This behavior is nothing unexpected, since humans tend to mix short travels around their neighborhood with business or holiday travels. The authors study several statistical properties of the travel of humans to find that it can be described by a &lt;a href=&#34;http://www.weizmann.ac.il/ESER/People/Brian/CTRW/&#34;&gt;Continuous Time Random Walk &lt;/a&gt;(CTRW). Their study can be relevant to any other thing carried by humans, like viruses or diseases and thus it pertains to epidemiology.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cum hoc ergo propter hoc</title>
      <link>http://estebanmoro.org/2006/01/cum-hoc-ergo-propter-hoc/</link>
      <pubDate>Wed, 25 Jan 2006 08:22:56 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2006/01/cum-hoc-ergo-propter-hoc/</guid>
      <description>&lt;p&gt;Or… Correlation implies causality. This is a &lt;a href=&#34;http://en.wikipedia.org/wiki/Correlation_implies_causation_%28logical_fallacy%29&#34;&gt;logical fallacy&lt;/a&gt;. Keep this in mind when analyzing data. There are numerous cases of how people use this logical fallacy nowadays (most typically in newspapers). For example, the following graph&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/fsm_pirates.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;shows a correlation between global warming and the number of remaining pirates. But this does not imply (of course), any causality between them.&lt;/p&gt;
&lt;p&gt;By the way, this graph appears in a Bobby Henderson’s clever parody of the type of arguments in Intelligent Design. Bobby Henderson’s parody is a joke religion also known as &lt;a href=&#34;http://en.wikipedia.org/wiki/Flying_Spaghetti_Monster&#34;&gt;Pastafarianism&lt;/a&gt;. Caution: if you read the last link, you could be touched by the Flying Spaghetti Monster noodly appendage…&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Meet the glaciers</title>
      <link>http://estebanmoro.org/2005/12/meet-the-glaciers/</link>
      <pubDate>Wed, 21 Dec 2005 07:35:08 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2005/12/meet-the-glaciers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://estebanmoro.org/img/posts/glacier.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I have been on holidays during the last two weeks visiting Argentina. The picture above was taken on top of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Perito_Moreno_Glacier&#34;&gt;Perito Moreno glacier&lt;/a&gt;, which is amazing. Most glaciers we found where blueish, including the icebergs found floating in the rivers. The reason for that is that the thicker the ice or snow layer is, the better red colors are absorbed by the layer and only the blue colors are reflected (see a more detailed explanation &lt;a href=&#34;http://webexhibits.org/causesofcolor/5C.html&#34;&gt;here&lt;/a&gt;). Ice in the freezer looks transparent or white because its thickness is small enough to make the absorption of the red colors negligible.&lt;/p&gt;
&lt;p&gt;Perito Moreno glacier is one of the few glaciers in equilibrium: neither advancing nor retreating. Unfortunately, due to global warming, &lt;a href=&#34;http://www.geo.unizh.ch/wgms/mbb/mb04/sum04.html&#34;&gt;retreating is the norm&lt;/a&gt; and numerous glaciers have disappeared in recent years. Another unusual characteristic is that the glacier front is close to a peninsula. From time to time the glacier front touches the peninsula and both sides of the lake the glacier empties into get disconnected. The unbalance of the water levels at both sides of the lake makes the water to percolate underneath the front creating a ice bridge between the peninsula and the glacier front. This bridge inevitably collapse in a phenomenon name “la ruptura” (rupture). The last to happen was in March 2004 and &lt;a href=&#34;http://dude.uibk.ac.at/Projects/Patagonia/LakeDamming/&#34;&gt;it is a spectacular sight&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Folding paper</title>
      <link>http://estebanmoro.org/2005/11/folding-paper/</link>
      <pubDate>Tue, 22 Nov 2005 08:26:34 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2005/11/folding-paper/</guid>
      <description>&lt;p&gt;You can’t fold a paper more than seven or eight times. Don’t believe me? Then try it. Thinner paper? Longer paper? It doesn’t matter; you just can’t do it. I used to play this game with my friends which were always amazed and asked for an explanation. Is there any physical or mathematical constrain to do it? Nope: it is simply a matter of scale. If you have a paper of length &lt;em&gt;L&lt;/em&gt; and you fold it, the length now is &lt;em&gt;L/2&lt;/em&gt;. Do it again and it goes down to L/22. In general, if you fold it n times, the remaining length is&lt;/p&gt;
&lt;p&gt;&lt;em&gt;ln=L/2n&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Obviously, this folding can be repeated until the remaining length of the paper is approximatelly the width of the paper. Thus, the maximum number of times you can fold a piece of paper of length L and width d is given by&lt;/p&gt;
&lt;p&gt;_d=L/2n =&amp;gt; n = Log[L/d]/Log[2] _&lt;/p&gt;
&lt;p&gt;Now get a piece of paper (an A4 sheet for example), which is 297mm long and more or less 0.1mm of width. Thus _n = 11 _which is much larger than the 7 or 8 times expected. The explanation for this miscalculation is that when folding paper, the remaining length of the paper is not given by simply dividing by 2 the previous lenght (see figure).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://estebanmoro.org/wp-content/uploads/2008/12/paperfolding1.jpg&#34;&gt;&lt;img src=&#34;http://estebanmoro.org/wp-content/uploads/2008/12/paperfolding1-300x155.jpg&#34; alt=&#34;&#34;&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Paper folding after two iterations. Note that the remaining
length &lt;em&gt;l2&lt;/em&gt; is not equal to &lt;em&gt;L/22&lt;/em&gt; due to the paper lenght
“used” in the arcs&lt;/p&gt;
&lt;p&gt;One should account for the paper in the arcs conecting different layers and the series of remaining lengths was calculated&lt;a href=&#34;http://pomonahistorical.org/12times.htm&#34;&gt;by high school student Britney Gallivan&lt;/a&gt; in December of 2001 (&lt;a href=&#34;http://www.math.princeton.edu/%7Ewwong/blog/blog200511170411.shtml&#34;&gt;see a detailed explanation here&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;&lt;em&gt;ln = 6L/[pi (2n+4)(2n-1)]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In this case we get&lt;/p&gt;
&lt;p&gt;_n = 1/2 Log[6L/pi d]/Log[2] _&lt;/p&gt;
&lt;p&gt;which gives &lt;em&gt;n = 6&lt;/em&gt; for a A4 sheet of paper, as expected. In fact, longer paper can be folded more times: the same Britney Gallivan &lt;a href=&#34;http://pomonahistorical.org/12times.htm&#34;&gt;has recently folded 12 times&lt;/a&gt; a piece of paper, which accordingly to the equations above, was of (at least) length 879 meters.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why I didn’t answer your email</title>
      <link>http://estebanmoro.org/2005/11/why-i-didnt-answer-your-email/</link>
      <pubDate>Wed, 16 Nov 2005 07:36:34 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2005/11/why-i-didnt-answer-your-email/</guid>
      <description>&lt;p&gt;In a recent &lt;a href=&#34;http://www.nature.com/nature/journal/v437/n7063/full/4371251a.html;jsessionid=565D6C403BDF1384DF5AA2DEEDFE5030&#34;&gt;Nature&lt;/a&gt; &lt;a href=&#34;http://www.nd.edu/%7Enetworks/Publication%20Categories/03%20Journal%20Articles/Social%20Science/CorrespondencePatterns_Nature%20437,%201251%20%2827Oct05%29.pdf&#34;&gt;article&lt;/a&gt;, &lt;a href=&#34;http://www.nd.edu/%7Ealb/&#34;&gt;Albert-Lászlo Barabási&lt;/a&gt; and João Gama Oliveira, have found the perfect excuse for lazy people not answering some emails in their inbox: they analyzed the time response of emails and found that they follow a power law probability distribution of the form P(t) = 1/t. In particular this implies that not even the mean response time is finite. Hey! why should you then expect me to answer your emails within my lifetime period! The &lt;a href=&#34;http://www.newscientist.com/article.ns?id=dn8214&#34;&gt;usual&lt;/a&gt; &lt;a href=&#34;http://physicsweb.org/articles/news/9/10/15/1&#34;&gt;buzz&lt;/a&gt; after the publication in Nature reach other scientific and &lt;a href=&#34;http://www.msnbc.msn.com/id/9827337/&#34;&gt;non-scientific&lt;/a&gt; publications.&lt;/p&gt;
&lt;p&gt;Unfortunately for lazy people like me, Barabási and Oliveira analysis of the data is wrong and the power law observed is an artifact of a bad analysis of the data, which is immensely better described by a log-normal distribution as shown in a &lt;a href=&#34;http://arxiv.org/abs/physics/0510216&#34;&gt;recent comment&lt;/a&gt; by Stouffer, Malmgrem and Amaral also submitted to Nature. The inconsistency of Barabási’s analysis is shown in different ways, but their main points are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In the data considered by Barabási and Oliveira, the most frequent time interval between emails for some specific users is smaller than a second. This means that some people answer more than 60 emails per minute. Wow! that is fast and, unfortunately unrealistic.&lt;/li&gt;
&lt;li&gt;If P(t) is a power-law with exponent -1, when plotting the P(s) where s = ln(t) we should observe a uniform probability distribution (P(s) = const.). However, Stouffer et al. found that it is far from uniform and it looks more like a Gaussian (which correspond to assume that P(t) is a log-normal distribution).&lt;/li&gt;
&lt;li&gt;Stouffer et al. use Bayesian model selection analysis to find that the log-normal distribution is the one describing the data with probability one.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Moreover, the authors do also criticized the model proposed by Barabási and Oliveira to explain the data. &lt;a href=&#34;http://geomblog.blogspot.com/2005/10/darwins-and-einsteins-email.html&#34;&gt;Some&lt;/a&gt; &lt;a href=&#34;http://cscs.umich.edu/%7Ecrshalizi/weblog/2005/10/28#390&#34;&gt;other&lt;/a&gt; &lt;a href=&#34;http://cs.unm.edu/%7Eaaron/blog/archives/2005/10/links_links_lin.htm&#34;&gt;people&lt;/a&gt; comment on this flawed analysis of Barabási and Oliveira in their blogs.&lt;/p&gt;
&lt;p&gt;Finally, it is interesting to find in the comment by Stouffer et al. the following sentence:&lt;/p&gt;
&lt;blockquote&gt;Barabási analyzed the email communication patterns of a subset of users [2] in a database containing the email usage records of 3188 individuals using a university e-mail server over an 83-day period [3]. Upon examining the same data, we find a number of significant deficiencies in his analysis. These deficiencies were communicated to Barabási well in advance of publication [4].&lt;/blockquote&gt;
&lt;p&gt;If Barabási and Oliveira were right, they should not expect an answer to this communication in finite time!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A number to rank them all</title>
      <link>http://estebanmoro.org/2005/11/a-number-to-rank-them-all/</link>
      <pubDate>Sun, 13 Nov 2005 07:37:57 +0000</pubDate>
      
      <guid>http://estebanmoro.org/2005/11/a-number-to-rank-them-all/</guid>
      <description>&lt;p&gt;UCSD physicist &lt;a href=&#34;http://physics.ucsd.edu/%7Ejorge/jh.html&#34;&gt;Jorge E. Hirsch&lt;/a&gt; has propose a quick-and-dirty way to measure quality of academic scientist’s output. His method is explained and studied in a &lt;a href=&#34;http://arxiv.org/abs/physics/0508025&#34;&gt;paper to be published&lt;/a&gt; in the November 15 issue of PNAS. The idea is very simple and it is called the h-index. This number relies on the number of citations our papers have. In particular the h-index is the maximum number &lt;em&gt;h&lt;/em&gt; that verifies the following: at least h of papers of an author have h citations each. The method to calculate the number is fast (via the &lt;a href=&#34;http://isiknowledge.com/&#34;&gt;Thomson ISI Web of Science database&lt;/a&gt;) and he claims can tell apart good professional careers from a lifetime of mediocre work skewed by one or two highly cite papers. Let’s run the numbers to see how some people in the statistical physics community does:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  * **P.G. de Gennes**, 83, a Noble laureate. The paper by Hirsch miscalculates his h-index, probably because de Gennes appears as PG deGennes, PGD Gennes and PG de Gennes in the list of authors.
  * **H.E. Stanley**, 79. Boltzman medal. impressive.
  * **G. Parisi**, 74. The famous Kardar-Parisi-Zhang paper gets 1980 citations! G. Parisi have quite a lot of papers in high-energy with a lot of citations each as well
  * **J.L. Lebowitz**, 65. Boltzman medal
  * B. Widom, 41
  * J-P. Bouchaud, 40
  * A.L. Barabasi, 39
  * M. Kardar, 39. Boltzman medal
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note however that the h-index obviously depends on the numbers of years of scientific career. I forecast that part of the success of the h-index will be that is publicly available and thus scientists can compare themselves to their collegues. However, different scientific fields have different publication frequencies and different average number of citations, making the comparison a little bit difficult even across subdisciplines.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>