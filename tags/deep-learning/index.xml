<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on </title>
    <link>https://estebanmoro.org/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 31 Jan 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://estebanmoro.org/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Generating synthetic mobility data for a realistic population with RNNs to improve utility and privacy</title>
      <link>https://estebanmoro.org/post/2022-01-31-generating-synthetic-mobility-data-for-a-realistic-population-with-rnns-to-improve-utility-and-privacy/</link>
      <pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://estebanmoro.org/post/2022-01-31-generating-synthetic-mobility-data-for-a-realistic-population-with-rnns-to-improve-utility-and-privacy/</guid>
      <description>
&lt;script src=&#34;https://estebanmoro.org/post/2022-01-31-generating-synthetic-mobility-data-for-a-realistic-population-with-rnns-to-improve-utility-and-privacy/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;em&gt;Authors&lt;/em&gt;: Alex Berke, Ronan Doorley, Kent Larson, Esteban Moro&lt;br&gt;
&lt;em&gt;Publication&lt;/em&gt;: arXiv preprint arXiv:2201.01139 (2022). &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.01139&#34;&gt;Link&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Location data collected from mobile devices represent mobility behaviors at individual and societal levels. These data have important applications ranging from transportation planning to epidemic modeling. However, issues must be overcome to best serve these use cases: The data often represent a limited sample of the population and use of the data jeopardizes privacy.
To address these issues, we present and evaluate a system for generating synthetic mobility data using a deep recurrent neural network (RNN) which is trained on real location data. The system takes a population distribution as input and generates mobility traces for a corresponding synthetic population.
Related generative approaches have not solved the challenges of capturing both the patterns and variability in individuals’ mobility behaviors over longer time periods, while also balancing the generation of realistic data with privacy. Our system leverages RNNs’ ability to generate complex and novel sequences while retaining patterns from training data. Also, the model introduces randomness used to calibrate the variation between the synthetic and real data at the individual level. This is to both capture variability in human mobility, and protect user privacy.
Location based services (LBS) data from more than 22,700 mobile devices were used in an experimental evaluation across utility and privacy metrics. We show the generated mobility data retain the characteristics of the real data, while varying from the real data at the individual level, and where this amount of variation matches the variation within the real data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Organize your Deep Reinforcement Learning Agents: The Importance of Communication Topology</title>
      <link>https://estebanmoro.org/post/2018-12-14-how-to-organize-your-deep-reinforcement-learning-agents-the-importance-of-communication-topology/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://estebanmoro.org/post/2018-12-14-how-to-organize-your-deep-reinforcement-learning-agents-the-importance-of-communication-topology/</guid>
      <description>&lt;p&gt;&lt;em&gt;Authors&lt;/em&gt;: Dhaval Adjodah, Dan Calacci, Abhimanyu Dubey, Peter Krafft, Esteban Moro, Alex `Sandy&amp;rsquo; Pentland&lt;br&gt;
&lt;em&gt;Journal&lt;/em&gt;: Preprint (2018). &lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.12556&#34;&gt;arXiv&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; In this empirical paper, we investigate how learning agents can be arranged in more efficient communication topologies for improved learning. This is an important problem because a common technique to improve speed and robustness of learning in deep reinforcement learning and many other machine learning algorithms is to run multiple learning agents in parallel. The standard communication architecture typically involves all agents intermittently communicating with each other (fully connected topology) or with a centralized server (star topology). Unfortunately, optimizing the topology of communication over the space of all possible graphs is a hard problem, so we borrow results from the networked optimization and collective intelligence literatures which suggest that certain families of network topologies can lead to strong improvements over fully-connected networks. We start by introducing alternative network topologies to DRL benchmark tasks under the Evolution Strategies paradigm which we call Network Evolution Strategies. We explore the relative performance of the four main graph families and observe that one such family (Erdos-Renyi random graphs) empirically outperforms all other families, including the de facto fully-connected communication topologies. Additionally, the use of alternative network topologies has a multiplicative performance effect: we observe that when 1000 learning agents are arranged in a carefully designed communication topology, they can compete with 3000 agents arranged in the de facto fully-connected topology. Overall, our work suggests that distributed machine learning algorithms would learn more efficiently if the communication topology between learning agents was optimized.&lt;/p&gt;
&lt;div data-badge-popover=&#34;right&#34; data-badge-type=&#34;donut&#34; data-arxiv-id=&#34;1811.12556&#34; data-hide-less-than=&#34;0&#34; class=&#34;altmetric-embed&#34;&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>MemeSequencer: Sparse Matching for Embedding Image Macros</title>
      <link>https://estebanmoro.org/post/2018-04-24-memesequencer-sparse-matching-for-embedding-image-macros/</link>
      <pubDate>Tue, 24 Apr 2018 11:20:47 +0000</pubDate>
      
      <guid>https://estebanmoro.org/post/2018-04-24-memesequencer-sparse-matching-for-embedding-image-macros/</guid>
      <description>&lt;p&gt;&lt;em&gt;Authors&lt;/em&gt;: Abhimanyu Dubey, Esteban Moro, Manuel Cebrian, Iyad Rahwan&lt;br&gt;
&lt;em&gt;Journal&lt;/em&gt;: WWW&#39;18 Proceedings of the Web Conference 2018 &lt;strong&gt;&lt;a href=&#34;http://delivery.acm.org/10.1145/3190000/3186021/p1225-trovato.html&#34;&gt;LINK&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;  The analysis of the creation, mutation, and propagation of social media content on the Internet is an essential problem in computational social science, affecting areas ranging from marketing to political mobilization. A first step towards understanding the evolution of images online is the analysis of rapidly modifying and propagating memetic imagery or ‘memes’. However, a pitfall in proceeding with such an investigation is the current incapability to produce a robust semantic space for such imagery, capable of understanding differences in Image Macros. In this study, we provide a first step in the systematic study of image evolution on the Internet, by proposing an algorithm based on sparse representations and deep learning to decouple various types of content in such images and produce a rich semantic embedding. We demonstrate the benefits of our approach on a variety of tasks pertaining to memes and Image Macros, such as image clustering, image retrieval, topic prediction and virality prediction, surpassing the existing methods on each. In addition to its utility on quantitative tasks, our method opens up the possibility of obtaining the first large-scale understanding of the evolution and propagation of memetic imagery.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>