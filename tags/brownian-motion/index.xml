<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Brownian Motion on </title>
    <link>https://estebanmoro.org/tags/brownian-motion/</link>
    <description>Recent content in Brownian Motion on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Tue, 14 Apr 2009 11:37:02 +0000</lastBuildDate>
    
        <atom:link href="https://estebanmoro.org/tags/brownian-motion/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The probability of going through a bad patch</title>
      <link>https://estebanmoro.org/2009/04/the-probability-of-going-through-a-bad-patch/</link>
      <pubDate>Tue, 14 Apr 2009 11:37:02 +0000</pubDate>
      
      <guid>https://estebanmoro.org/2009/04/the-probability-of-going-through-a-bad-patch/</guid>
      <description>&lt;p&gt;We&amp;rsquo;ve heard it: people that invest on the stock market or that gamble in lotteries, casinos, etc usually say &amp;ldquo;I&amp;rsquo;m going through a bad patch&amp;rdquo; (or bad spell). That is, they have been losing money for a while, but hey! better times are ahead and there&amp;rsquo;s no reason to quit. Are they sure? Are better times ahead? How close is &amp;ldquo;ahead&amp;rdquo; to today? Let&amp;rsquo;s work through a specific example to see how far is &amp;ldquo;ahead&amp;rdquo;. Suppose we play a fair game: we toss a coin and with probability 1/2 we get $1 (heads) and with probability 1/2 we lose $1 (tails). We play the game &lt;code&gt;\(n\)&lt;/code&gt; times and compute our capital &lt;code&gt;\(C(n)\)&lt;/code&gt; up to time &lt;code&gt;\(n\)&lt;/code&gt;. If our initial capital is zero, then we expect that our capital fluctuate around zero as the coin-tossing game goes on. Sometimes we will be in the &amp;ldquo;winning area&amp;rdquo;, where our capital is positive &lt;code&gt;\(C(n)\)&lt;/code&gt; &amp;gt; 0. However, we can also be in the &amp;ldquo;losing area&amp;rdquo; in which our capital is negative &lt;code&gt;\(C(n)\)&lt;/code&gt; &amp;lt; 0. If we are going through a bad patch (being in the losing area) we expect that waiting long enough we will recover and come back to the winning area.&lt;/p&gt;
&lt;p&gt;But this is incorrect. Let me show you why: let&amp;rsquo;s use some mathematics. Suppose that &lt;code&gt;\(x_i\)&lt;/code&gt; is the gain (+$1) or lose (-$1) in toss &lt;code&gt;\(i\)&lt;/code&gt; of the coin. Since our coin is fair, then &lt;code&gt;\(x_i\)&lt;/code&gt; is a random number which takes +1 or -1 with equal probability (1/2). Thus the capital up to time &lt;code&gt;\(n\)&lt;/code&gt; is the sum of those random numbers&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$C(n) = \sum_{i=1}^n x_i$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(C(n)\)&lt;/code&gt; is then the sum of &lt;code&gt;\(n\)&lt;/code&gt; equally distributed random numbers. In other contexts, &lt;code&gt;\(C(n)\)&lt;/code&gt; is also know as a &lt;a href=&#34;http://en.wikipedia.org/wiki/Random_walk&#34;&gt;random walk&lt;/a&gt;. We can apply the &lt;a href=&#34;http://en.wikipedia.org/wiki/Law_of_large_numbers&#34;&gt;law of large numbers&lt;/a&gt; and the &lt;a href=&#34;http://en.wikipedia.org/wiki/Central_limit_theorem&#34;&gt;central limit theorem&lt;/a&gt; to know something about &lt;code&gt;\(C(n)\)&lt;/code&gt;. For example, the expected value of &lt;code&gt;\(C(n)\)&lt;/code&gt; is&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\mathbb{E}[C(n)] = 0$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;as expected, since it is a fair game. Thus we have equal probability of being winning or losing at time &lt;code&gt;\(n\)&lt;/code&gt;. However, &lt;code&gt;\(C(n)\)&lt;/code&gt; fluctuates wildly around zero and in fact&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$Var[C(n)] = n$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Thus our capital at time &lt;code&gt;\(n\)&lt;/code&gt; is mostly in an interval of area &lt;code&gt;\(\sqrt{n}\)&lt;/code&gt; around zero, as shown in the next graph.&lt;/p&gt;
&lt;center&gt;
![](/img/posts/cn.jpg)&lt;/center&gt;
&lt;p&gt;The graphs shows 4 realizations of the game (colors) and the lines are the &lt;code&gt;\(\sqrt{n}\)&lt;/code&gt; areas in which our capital is mostly expected. As we can see in the &amp;ldquo;red&amp;rdquo; game, we starting losing money, but after a while we recover and went back to the &amp;ldquo;winning area&amp;rdquo;. Now the question is: what is the probability that we are in the winning area? Specifically, what is the probability &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; that we are in the winning area ($C(n)$ &amp;gt; 0) for a fraction &lt;code&gt;\(\alpha\)&lt;/code&gt; of the total &lt;code&gt;\(n\)&lt;/code&gt; turns? The naive reasoning in the introduction will tell us that since &lt;code&gt;\(C(n)\)&lt;/code&gt; is fluctuating around zero we expect that the probability will be peaked and 1/2 and thus half of the time we will be in a bad patch and half of the time we will be going through a good spell. Thus, if we are going through a bad patch, we have only to wait to come back to black numbers. However, this is not true. The probability &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; can be &lt;a href=&#34;http://math.berkeley.edu/~chr/teach/Lec14_2006.pdf&#34;&gt;worked out&lt;/a&gt; (although not trivially) to get&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$P(\alpha) = \frac{1}{\pi\sqrt{\alpha(1-\alpha)}}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://estebanmoro.org/img/posts/pdfa.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the limit &lt;code&gt;\(n\to \infty\)&lt;/code&gt;, which is known as the&lt;a href=&#34;http://www.math.unl.edu/~sdunbar1/Teaching/MathematicalFinance/Lessons/CoinTossing/ExcessHeads/excessheads.shtml&#34;&gt; arc-sine law&lt;/a&gt; (since the cumulative distribution of &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; is the arc-sin function). As the plot in the right shows the probability is peaked at 1 and 0 (actually, it diverges there!). Thus, for most of the realizations of the game we are most of the time in the winning area or in the losing area. This means that our naive reasoning above does not work: if you expect to recover from a bad patch, your chances are very small. This is obvious if we look at the colored figure above: the orange and black trajectories do not change from one winning/losing area to the other and, apart from the initial steps of the game, they remain in the winning/losing areas forever. The explanation for this behavior is that the &lt;a href=&#34;http://lib.stat.cmu.edu/~genovese/class/iprob-S06/notes/lec5-calcs.pdf&#34;&gt;first return time&lt;/a&gt; of &lt;code&gt;\(C(n)\)&lt;/code&gt; to zero is oftenly large. Actually, its expected time is infinite, which means that once you get into the positive/negative area you remain (mostly) there.&lt;/p&gt;
&lt;p&gt;Note however, that there is no paradox in what we have found and the fact that &lt;code&gt;\(\mathbb{E}[C(n)] = 0\)&lt;/code&gt;, since &lt;code&gt;\(P(\alpha)\)&lt;/code&gt; is symmetric around &lt;code&gt;\(\alpha = 1/2\)&lt;/code&gt; and thus if we play the game a large number of times, on average, we have the same chances of winning and losing. But not for an individual game in which mostly we will be in a bad or good patch forever.&lt;/p&gt;
&lt;p&gt;What is the moral? Simple: if you get into a bad patch, leave the game. Because chances to recover from a bad patch are small.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Brown&#39;s observations on Brownian motion </title>
      <link>https://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/</link>
      <pubDate>Thu, 18 Dec 2008 09:27:47 +0000</pubDate>
      
      <guid>https://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/</guid>
      <description>&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Robert_Brown_%28young_-_larousse%29.jpg/397px-Robert_Brown_%28young_-_larousse%29.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;In 1828, Robert Brown published the manuscript entitled &amp;ldquo;A brief account of microscopical observations made in the months of June, July and August 1827, on the particles contained in the pollen of plants; and on the general existence of active molecules in organic and inorganic bodies&amp;rdquo; in the Edinburgh new Philosophical Journal [download it in pdf format &lt;a href=&#34;http://sciweb.nybg.org/science2/pdfs/dws/Brownian.pdf&#34;&gt;here&lt;/a&gt;]. He suspended some of the pollen grains of the species &lt;a href=&#34;http://www.robsplants.com/plants/ClarkPulch.php&#34;&gt;Clarkia pulchella&lt;/a&gt; in water and examined them closely, only to see them &amp;ldquo;filled with particles&amp;rdquo; of around 5 Âµm diameter that were &amp;ldquo;very evidently in motion&amp;rdquo;. He was soon satisfied that the movement &amp;ldquo;arose neither from currents in the fluid nor form its gradual evaporation, but belonged to the particle itself&amp;rdquo;. Brown&amp;rsquo;s work was the first comprehensive observation of a phenomena called &lt;a href=&#34;http://en.wikipedia.org/wiki/Brownian_motion&#34;&gt;Brownian motion&lt;/a&gt; which remained unexplained until the beginning of the 20th century by Bachelier and most notably by Einstein in his famous paper in 1905. Brownian motion is the most basic description of the dynamics of a particle, price, etc. under the influence of external noise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://estebanmoro.org/img/posts/microscopio-brown-150x150.jpg&#34; alt=&#34;Microscope used by Brown&#34;&gt;Microscope used by Brown&lt;/p&gt;
&lt;p&gt;A typical mistake found in books, encyclopedias and articles (even in the Nature journal and even by the great &lt;a href=&#34;http://www.nature.com/nature/journal/v433/n7023/full/433221a.html&#34;&gt;Giorgio Parisi&lt;/a&gt;) is that Brown observed the motion of the pollen grains themselves. This might be the most clear example of a propagated mistake in the scientific literature, since it is obvious from the very title that the particles he observed were &amp;ldquo;in the pollen grains&amp;rdquo;. In fact, using the explanation of the motion by Einstein is easy to convince ourselves that the pollen grains were too big to wander around enough to be observable: Einstein in 1905 published a paper (original &lt;a href=&#34;http://www.physik.uni-augsburg.de/theo1/hanggi/History/Einstein1906BMII.pdf&#34;&gt;in german&lt;/a&gt;) in which he derived the famous &lt;a href=&#34;http://en.wikipedia.org/wiki/Einstein_relation_(kinetic_theory)&#34;&gt;Einstein relation&lt;/a&gt; in kinetic theory&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$D = \frac{k_B T}{6 \pi \eta r}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which relates the diffusion constant of the Brownian motion of a particle &lt;code&gt;\(D\)&lt;/code&gt; with the radius of the particle &lt;code&gt;\(r\)&lt;/code&gt; and the viscosity of the medium in which the particle is moving &lt;code&gt;\(\eta\)&lt;/code&gt;. The diffusion constant &lt;code&gt;\(D\)&lt;/code&gt; is also proportional to the temperature &lt;code&gt;\(T\)&lt;/code&gt; and &lt;code&gt;\(k_B\)&lt;/code&gt; is the Boltzmann constant. In order to observe the motion by eye, the particle should move considerably in a matter of seconds. We can evaluate the size of the movement by looking at the root-mean-square fluctuations in the position which are given by&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\langle x^2(t)\rangle = D t$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For a pollen grain the radius is around &lt;code&gt;\(\simeq 100 \mu m\)&lt;/code&gt; and in water at &lt;code&gt;\(T =\)&lt;/code&gt; 25ÂºC we get that &lt;code&gt;\(\langle x^2(t)\rangle = 19 \mu m\)&lt;/code&gt; in &amp;hellip; one day!! This slow pace motion is hard to observe with today optical microscopes by eye, not to say with the microscope used by Brown (see the above picture).&lt;/p&gt;
&lt;p&gt;To observe the Brownian motion by eye, the particles should be smaller. If we assume that the radius should be small enough so that the RMS fluctuations in one second are greater or of the order of the particle size, we get that&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$r \leq 1 \mu m$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;that is, of the same length of the particles observed by Brown inside the pollen grain. In the following video you can see this molecular motion in an experiment made a research group in the Universidad Complutense de Madrid (Luis Dinis, &lt;a href=&#34;http://www.ucm.es/info/goptic/&#34;&gt;Julio Serna&lt;/a&gt;, Rodrigo Soto and Ricardo Brito) using polystyreneÂ spheres of &lt;code&gt;\(0.75-0.89\mu m\)&lt;/code&gt; diameter in water. The observations are made with an optical microscope using a 60x objective. The Brownian motion is evident.&lt;/p&gt;
&lt;video width=&#34;600&#34; controls&gt;
  &lt;source src=&#34;https://estebanmoro.org/img/posts/bmhq1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p&gt;More information about Brown&amp;rsquo;s observations and related work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ee.adfa.edu.au/staff/hrp/Literature/articles/karel3Avogadro.pdf&#34;&gt;Brownian motion and molecular size: counting and sizing molecules&lt;/a&gt;_, a Literature Study by K.L. Planken&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nature.com/nature/journal/v434/n7030/full/434137c.html&#34;&gt;Brown knew particles were smaller than pollen&lt;/a&gt; by D. M. Wilkinson, Nature (2005). A nice note about the repetition of the mistake mentioned above.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.microscopy-uk.org.uk/dww/home/hombrown.htm&#34;&gt;An exploration of your house in close-up: studying Brownian motion&lt;/a&gt;, by Dave Walker. Dave shows how to repeat the experiment using the fat droplets suspended in milk (cool)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: Julio Serna (thanks) sent me this interesting reference:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.brianjford.com/wbbrowna.htm&#34;&gt;BROWNIAN MOVEMENT IN CLARKIA POLLEN: A REPRISE OF THE FIRST OBSERVATIONS&lt;/a&gt;, by Brian J Ford, The Microscope, &lt;strong&gt;40&lt;/strong&gt;(4): 235-241, 1992. in which he repeated the experiment by Brown and settle the question of whether Brown was able or not to observe the Brownian motion with his microscope.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to stochastic differential equations</title>
      <link>https://estebanmoro.org/2008/12/introduction-to-stochastic-differential-equations/</link>
      <pubDate>Thu, 04 Dec 2008 16:45:32 +0000</pubDate>
      
      <guid>https://estebanmoro.org/2008/12/introduction-to-stochastic-differential-equations/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Stochastic_differential_equation&#34;&gt;Stochastic differential equations&lt;/a&gt; (SDEs) are basically &lt;em&gt;inhomogenous ordinary differential equations that depend on an external stochastic process&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Typically, that stochastic process is &lt;a href=&#34;http://en.wikipedia.org/wiki/White_noise&#34;&gt;white noise&lt;/a&gt;, which is the mathematical idealization of the noise found in nature. This idealization is handy, because it simplifies the mathematical description. However, this idealization comes at some cost: traditional calculus is no longer valid and you have to use the so-call &lt;a href=&#34;http://en.wikipedia.org/wiki/Ito_stochastic_calculus&#34;&gt;ItÃ´ calculus&lt;/a&gt;. This introduces some non intuitive changes. For example, instead of the usual chain rule of calculus, the ItÃ´ formula should be used. Here is an example, the ItÃ´ integral of the Wiener process (or Brownian Motion) is&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://estebanmoro.org/img/posts/itocalculus.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note the last term in the right-hand-side (!).&lt;/p&gt;
&lt;p&gt;If you are interested to learn more on SDEs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I prepared a long time ago &lt;a href=&#34;https://estebanmoro.org/img/ps/introtosde.pdf&#34;&gt;some notes&lt;/a&gt; about SDEs in Spanish&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;http://math.berkeley.edu/~evans/SDE.course.pdf&#34;&gt;nicer introduction&lt;/a&gt; to SDEs by Prof. Evans&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Writing bad letters of recommendation: the story of Bachelier and LÃ©vy</title>
      <link>https://estebanmoro.org/2006/03/writing-bad-letters-of-recommendation-the-story-of-bachelier-and-levy/</link>
      <pubDate>Wed, 15 Mar 2006 08:25:04 +0000</pubDate>
      
      <guid>https://estebanmoro.org/2006/03/writing-bad-letters-of-recommendation-the-story-of-bachelier-and-levy/</guid>
      <description>&lt;p&gt;Take a coin and toss it a number &lt;code&gt;\(N\)&lt;/code&gt; of times in a time interval of duration &lt;code&gt;\(T\)&lt;/code&gt;. Suppose that every time you get head you win &lt;code&gt;\(a\)&lt;/code&gt; euros and that you lose the same amount of money when you get tail. Then your capital is a random process with ups and dows like this:&lt;/p&gt;
&lt;center&gt;
![](/img/posts/figurebachelier.jpg)&lt;/center&gt;
&lt;p&gt;This process is a stochastic process usually called &amp;ldquo;Random Walk&amp;rdquo; and its properties depend on the parameters $N, a $ and &lt;code&gt;\(T\)&lt;/code&gt;. For example: if we play this game several times, the average mean value of the capital obtained after a time &lt;code&gt;\(T\)&lt;/code&gt; is zero! This is simple to realize since the probability to get either head or tails is the same. The problem comes when you analyze the fluctuations around this zero gain: the variance of the deviations from this zero mean behavior go like&lt;/p&gt;
&lt;p&gt;$$ Var(N) = N a^2 $$&lt;/p&gt;
&lt;p&gt;which brings the sad conclusion that the more times you play the game the higher the fluctuations are. If you are risk-averse, this is the worst situation since, although in average you don&amp;rsquo;t lose or win, the uncertanty of what quantity you will get in one shot of the game is growing in time.&lt;/p&gt;
&lt;p&gt;We now ask the following question: do the properties of this game change if we play &lt;code&gt;\(M &amp;gt; N\)&lt;/code&gt; times in the same time &lt;code&gt;\(T\)&lt;/code&gt; with a smaller payoff &lt;code&gt;\(b&amp;lt;a\)&lt;/code&gt;? Of course the stochastic process change, but some of the properties remain unchanged under proper choices of &lt;code&gt;\(a\)&lt;/code&gt; and &lt;code&gt;\(b\)&lt;/code&gt;. Obviously the average gain of this new game is also zero. What about the RMS? Note that if we take &lt;code&gt;\(a^2=T/N\)&lt;/code&gt; or &lt;code&gt;\(b^2 = T/M\)&lt;/code&gt; then we have&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(Var(N) = N a^2 = T\)&lt;/code&gt; for the first game&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(Var(M)  =M b^2 = T\)&lt;/code&gt; for the second game&lt;/p&gt;
&lt;p&gt;which is independent of the payoff. This fact led some mathematicians early last century to study the asymptotic case &lt;code&gt;\(a\to 0\)&lt;/code&gt; and &lt;code&gt;\(N \to \infty\)&lt;/code&gt;, BUT taking&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$a^2 N = T = constant \qquad (1)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;which usually called Brownian Motion. The name &amp;ldquo;Brownian&amp;rdquo; comes from the botanist Brown who observed how particles of (probably) &lt;a href=&#34;https://estebanmoro.org/2008/12/browns-observations-on-brownian-motion/&#34;&gt;clay moved in water under the kicks of the molecules of water&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://estebanmoro.org/img/posts/louis_bachellier.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Bachelier (1870-1946 right) was the first one to study the Brownian motion in his PhD thesis at the Sorbonne in Paris and applied it as a possible model for the stock market. He was well ahead of his time not only for its application to the stock market, but also because he derived a lot of the properties of this stochastic process. Unfortunately his notation was a little bit sloppy. In particular, the dependence of &lt;code&gt;\(a^2\)&lt;/code&gt; with &lt;code&gt;\(N\)&lt;/code&gt; and &lt;code&gt;\(T\)&lt;/code&gt; [given by equation (1) above] in the limit &lt;code&gt;\(N\to\infty\)&lt;/code&gt; was omitted in most of his books and papers but always assumed by Bachelier. This &amp;ldquo;minor&amp;rdquo; omission and a careless reading of Bachelier&amp;rsquo;s work was the origin of Paul LÃ©vy&amp;rsquo;s strong criticism to his work. It was so strong, that Levy wrote a very critical and negative report about Bachelier&amp;rsquo;s work when the latter was trying to get an appointment at Dijon. Bachelier of course didn&amp;rsquo;t get the position and moved then to a small university at BesanÃ§on and kept on working without much impact in the field.&lt;/p&gt;
&lt;p&gt;It was after Kolmogorov&amp;rsquo;s 1931 citation of Bachelier work that LÃ©vy went back to his work and realized that he made a misjudgment of Bachelier&amp;rsquo;s work. Apparently Levy didn&amp;rsquo;t even read Bachelier&amp;rsquo;s papers and books in the very first place and, even so, he disregarded Bachelier&amp;rsquo;s findings as erroneous. Quite a strange behavior for one of the best mathematicians of all times. After that, in 1931, LÃ©vy wrote to Bachelier a letter apologizing for his behavior. It was a little bit late since Bachelier retired in 1937 although Bachelier was quite happy to receive LÃ©vy&amp;rsquo;s letter. At last his work was read by someone, and by the best!&lt;/p&gt;
&lt;p&gt;More information
&lt;a href=&#34;http://www-groups.dcs.st-and.ac.uk/%7Ehistory/Mathematicians/Bachelier.html&#34;&gt;Biography of Bachelier&lt;/a&gt;
&lt;a href=&#34;http://math.bu.edu/individual/murad/pub/bachelier-english43-fin-posted.pdf&#34;&gt;Bachelier and his times: A conversation with Bernard Bru&lt;/a&gt;, an article by M.S. Taqqu, published in Mathematical Finance - Bachelier Congress 2000&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Humans are superdiffusive</title>
      <link>https://estebanmoro.org/2006/02/humans-are-superdiffusive/</link>
      <pubDate>Thu, 09 Feb 2006 07:31:36 +0000</pubDate>
      
      <guid>https://estebanmoro.org/2006/02/humans-are-superdiffusive/</guid>
      <description>&lt;p&gt;When tea is poured in a cup of hot water, we observe a phenomenon called &lt;a href=&#34;http://en.wikipedia.org/wiki/Diffusion&#34;&gt;diffusion&lt;/a&gt;: in the end particles of tea spread evenly throughout the mass of water and we enjoy our cup of tea. Diffusion occurs as a result of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Second_Law_of_Thermodynamics&#34;&gt;second law of thermodynamics&lt;/a&gt;Â (increase of entropy) and can be modeled quantitatively using the diffusion equation (or heat equation). This is a funny equation, since it establishes that the velocity of spreading is infinite while the mean root square fluctuations of the position of the particles grows in time as&lt;/p&gt;
&lt;p&gt;$$ \langle x^2 \rangle  = 2 D t$$&lt;/p&gt;
&lt;p&gt;Specifically, this means that the typical volume covered by the particles of tea in the cup grows like the square root of time, while there is always a chance to find a particle anywhere in the cup. The coefficientÂ &lt;em&gt;D&lt;/em&gt;Â is called the diffusion constant and depends on thermodynamical properties of the liquid. It wasÂ &lt;a href=&#34;http://en.wikipedia.org/wiki/Albert_Einstein&#34;&gt;Einstein&lt;/a&gt;Â in his miraculous year (1905) who found theÂ &lt;a href=&#34;http://en.wikipedia.org/wiki/Einstein_relation&#34;&gt;relationship with temperature&lt;/a&gt;Â and mobility of particles in the liquid which is named after him. There are numerous examples of diffusion processes (also known as Brownian motions) from the erratic motion of particles in water found by the botanist Brown in 1827 to the description of price fluctuations in stock markets made byÂ &lt;a href=&#34;http://en.wikipedia.org/wiki/Louis_Bachelier&#34;&gt;Bachelier&lt;/a&gt;Â in 1900.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://estebanmoro.org/img/posts/baggage.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Of course, not everything in nature is diffusive. Actually, diffusive behavior is related to theÂ &lt;a href=&#34;http://mathworld.wolfram.com/CentralLimitTheorem.html&#34;&gt;Central Limit Theory&lt;/a&gt;Â and the fact that the mean root square fluctuations is growing linearly in time is telling us that the sum of the kicks than a particle of coffee suffers in the cup add like random numbers to get the CLT result: the variance grows linearly in time. The ubiquity of diffusive behavior is related to the fact that convergence in CLT does not depend on the microscopic details of the random numbers that are summed.&lt;/p&gt;
&lt;p&gt;In aÂ &lt;a href=&#34;http://www.nature.com/nature/journal/v439/n7075/full/nature04292.html&#34;&gt;recent study published in Nature&lt;/a&gt;Â and made byÂ D. Brockmann, L. Hufnagel and T. Geisel, these researchers have obtained quantitative assessment of the displacements of humans by analyzingÂ the circulation of bank notes in the United States obtained in theÂ &lt;a href=&#34;http://www.wheresgeorge.com/&#34;&gt;Where is George?&lt;/a&gt;Â website. They observe that human travel is somehow a random process governed by super-diffusive jumps to get&lt;/p&gt;
&lt;p&gt;$$\langle x^2 \rangle = 2 D_1 t$$&lt;/p&gt;
&lt;p&gt;which says that the typical area covered by humans when traveling is linear in time. This behavior is nothing unexpected, since humans tend to mix short travels around their neighborhood with business or holiday travels. The authors study several statistical properties of the travel of humans to find that it can be described by aÂ &lt;a href=&#34;http://www.weizmann.ac.il/ESER/People/Brian/CTRW/&#34;&gt;Continuous Time Random WalkÂ &lt;/a&gt;(CTRW). Their study can be relevant to any other thing carried by humans, like viruses or diseases and thus it pertains to epidemiology.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>